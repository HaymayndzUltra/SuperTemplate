---
**MASTER RAYâ„¢ AI-Driven Workflow Protocol**
Â© 2025 - All Rights Reserved
---

# PROTOCOL 15 : PRODUCTION DEPLOYMENT & RELEASE MANAGEMENT (RELIABILITY COMPLIANT)

**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.

<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Prerequisites section sets standards and requirements rather than executing workflow -->
## 1. PREREQUISITES

**[STRICT]** List all required artifacts, approvals, and system states before execution.

### 1.1 Required Artifacts
- [ ] `PRE-DEPLOYMENT-PACKAGE.zip` from Protocol 14 â€“ readiness evidence bundle
- [ ] `readiness-approval.json` from Protocol 14 â€“ stakeholder go decision
- [ ] `rollback-verification-report.json` from Protocol 14 â€“ validated rollback plan
- [ ] `UAT-CLOSURE-PACKAGE.zip` from Protocol 13 â€“ customer acceptance proof
- [ ] Latest release manifest `.artifacts/pre-deployment/deployment-checklist.md`

### 1.2 Required Approvals
- [ ] Executive sponsor or Product Owner authorization to deploy to production
- [ ] SRE/Operations lead approval confirming monitoring coverage
- [ ] Security lead sign-off if release includes security-impacting changes

### 1.3 System State Requirements
- [ ] Production environment credentials available with MFA satisfied
- [ ] Deployment automation scripts accessible (`scripts/deploy_*.sh`, `scripts/rollback_*.sh`)
- [ ] Monitoring dashboards and alerting tools operational for health window

---

<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Establishes rules and mission statement, not a workflow execution -->
## 2. AI ROLE AND MISSION

You are a **Release Manager**. Your mission is to orchestrate production deployments with zero unplanned downtime by validating readiness, executing controlled rollouts, and documenting every action for audit and recovery.

**ðŸš« [CRITICAL] DO NOT deploy to production without recorded staging success, stakeholder approval, and an executable rollback plan.**

---

## 3. WORKFLOW

<!-- [Category: EXECUTION-FORMATS - Mixed variants by step] -->

### 3.1 PHASE 1: Readiness Verification and Approval

<!-- [Category: EXECUTION-BASIC] -->
<!-- Why: Simple validation workflow with straightforward actions and evidence requirements -->

1. **`[MUST]` Validate Pre-Deployment Evidence:**
   * **Action:** Confirm Protocol 21 and 15 artifacts are complete, current, and free of blocking issues.
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 1 START] - Verifying deployment readiness artifacts..."
   * **Halt condition:** Stop if any prerequisite artifact missing or outdated.
   * **Evidence:** `.artifacts/deployment/deployment-readiness-checklist.json` capturing status per artifact.

2. **`[MUST]` Confirm Release Scope and Stakeholders:**
   * **Action:** Review release manifest, impacted services, rollback procedures, and stakeholder list.
   * **Communication:** 
     > "[PHASE 1] Release scope and stakeholder confirmations underway..."
   * **Halt condition:** Pause if approvals list incomplete or scope unclear.
   * **Evidence:** `.artifacts/deployment/release-manifest.md` annotated with confirmations.

3. **`[GUIDELINE]` Schedule Deployment Window:**
   * **Action:** Coordinate release window, communications, and on-call coverage.
   * **Example:**
     ```markdown
     - Deployment window: 2024-06-01 02:00-04:00 UTC
     - Communication channels: #release-war-room
     - On-call: SRE (Alex), Product (Taylor)
     ```

### 3.2 PHASE 2: Staging Verification Confirmation

<!-- [Category: EXECUTION-BASIC] -->
<!-- Why: Direct verification steps without complex decision-making -->

1. **`[MUST]` Reconfirm Staging Health:**
   * **Action:** Review Protocol 21 staging run logs and optionally rerun quick validation to ensure nothing drifted.
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 2 START] - Reconfirming staging health prior to production launch..."
   * **Halt condition:** Stop if staging validation fails or environment drift detected.
   * **Evidence:** `.artifacts/deployment/staging-validation-results.json` (refreshed if rerun).

2. **`[MUST]` Freeze Change Window:**
   * **Action:** Communicate code freeze start, lock deployment branch, and ensure no conflicting changes queued.
   * **Communication:** 
     > "[PHASE 2] Change freeze in effect. All teams acknowledge?"
   * **Halt condition:** Pause until freeze confirmed across stakeholders.
   * **Evidence:** `.artifacts/deployment/change-freeze-confirmation.md` with acknowledgements.

3. **`[GUIDELINE]` Conduct Final Dry Run:**
   * **Action:** Execute dry-run of production scripts using `--dry-run` or staging flag to confirm command readiness.
   * **Example:**
     ```bash
     bash scripts/deploy_backend.sh --env production --release ${TAG} --dry-run
     ```

### 3.3 PHASE 3: Production Deployment & Immediate Validation

<!-- [Category: EXECUTION-REASONING] -->
<!-- Why: Critical go/no-go deployment decisions with documented alternatives and risk assessment -->

1. **`[MUST]` Request Production Approval:**
   * **Action:** Present readiness checklist, staging evidence, and rollback plan to approvers; capture go/no-go decision.
   
   **[REASONING]:**
   - **Premises:** All readiness gates passed, staging validation successful, rollback plan tested
   - **Constraints:** Must have documented approval before production changes
   - **Alternatives Considered:**
     * **A)** Proceed with deployment - Selected if all criteria met
     * **B)** Delay deployment - If any concerns raised by stakeholders
     * **C)** Cancel deployment - If critical issues discovered
   - **Decision:** Proceed only with unanimous approval from required stakeholders
   - **Evidence:** Readiness checklist, staging results, rollback verification
   - **Risks & Mitigations:**
     * **Risk:** Incomplete approval chain â†’ **Mitigation:** Validate all approvers before proceeding
   
   * **Communication:** 
     > "[APPROVAL REQUEST] All readiness gates passed. Approve production deployment? (yes/no)"
   * **Halt condition:** Do not continue without recorded approval.
   * **Evidence:** `.artifacts/deployment/production-approval.json` with timestamps and approvers.

2. **`[MUST]` Execute Production Deployment:**
   * **Action:** Perform deployment according to rollout strategy (blue/green, canary, rolling) while logging commands.
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 3 START] - Executing production deployment sequence..."
   * **Halt condition:** Trigger rollback if critical errors encountered.
   * **Evidence:** `.artifacts/deployment/production-deployment-report.json` capturing actions and durations.

3. **`[MUST]` Run Immediate Post-Deployment Checks:**
   * **Action:** Execute smoke tests, health checks, and service verifications within minutes of deployment completion.
   * **Communication:** 
     > "[PHASE 3] Running post-deployment validation checks..."
   * **Halt condition:** Initiate rollback if checks fail beyond tolerances.
   * **Evidence:** `.artifacts/deployment/post-deployment-validation.json` including metrics snapshot.

4. **`[GUIDELINE]` Notify Stakeholders of Deployment Progress:**
   * **Action:** Provide updates at key milestones (start, 50%, completion) in designated channels.
   * **Example:**
     ```markdown
     [RAY ANNOUNCEMENT] Production deployment 50% complete. No errors observed. Next update in 10 minutes.
     ```

### 3.4 PHASE 4: Stabilization Window and Documentation

<!-- [Category: EXECUTION-BASIC] -->
<!-- Why: Monitoring and documentation steps, straightforward tracking and reporting -->

1. **`[MUST]` Monitor Health Window:**
   * **Action:** Track metrics during agreed soak period, documenting anomalies and decisions.
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 4 START] - Monitoring post-deployment health window..."
   * **Halt condition:** Escalate to Protocol 20 if thresholds breached.
   * **Evidence:** `.artifacts/deployment/deployment-health-log.md` summarizing observations.

2. **`[MUST]` Compile Release Report:**
   * **Action:** Consolidate readiness checklist, deployment logs, validation results, and monitoring data into `DEPLOYMENT-REPORT.md`.
   * **Communication:** 
     > "[PHASE 4] Compiling final release report and evidence bundle..."
   * **Halt condition:** Delay handoff until report and attachments complete.
   * **Evidence:** `.artifacts/deployment/DEPLOYMENT-REPORT.md` plus zipped evidence package `DEPLOYMENT-EVIDENCE.zip`.

3. **`[GUIDELINE]` Trigger Retrospective Inputs:**
   * **Action:** Provide summary and improvement items to Protocol 22 and log follow-up actions.
   * **Example:**
     ```markdown
     - Improvement: Automate canary rollback trigger thresholds
     - Owner: Release Engineering
     ```

---

<!-- [Category: META-FORMATS] -->
<!-- Why: Protocol analysis and improvement framework, not direct execution -->
## 4. REFLECTION & LEARNING

### 4.1 Retrospective Guidance

After completing protocol execution (successful or halted), conduct retrospective:

**Timing:** Within 24-48 hours of completion

**Participants:** Protocol executor, downstream consumers, stakeholders

**Agenda:**
1. **What went well:**
   - Which steps executed smoothly and efficiently?
   - Which quality gates were well-calibrated?
   - Which artifacts provided high value to downstream protocols?

2. **What went poorly:**
   - Which steps encountered blockers or delays?
   - Which quality gates were too strict or too lenient?
   - Which artifacts required rework or clarification?

3. **Action items:**
   - Protocol template updates needed?
   - Quality gate threshold adjustments?
   - New automation opportunities?

**Output:** Retrospective report stored in protocol execution artifacts

### 4.2 Continuous Improvement Opportunities

#### 4.2.1 Identified Improvement Opportunities
- Identify based on protocol-specific execution patterns

#### 4.2.2 Process Optimization Tracking
- Track key performance metrics over time
- Monitor quality gate pass rates and execution velocity
- Measure downstream satisfaction and rework requests
- Identify automation opportunities

#### 4.2.3 Tracking Mechanisms and Metrics
- Quarterly metrics dashboard with trends
- Improvement tracking log with before/after comparisons
- Evidence of improvement validation

#### 4.2.4 Evidence of Improvement and Validation
- Metric trends showing improvement trajectories
- A/B testing results for protocol changes
- Stakeholder feedback scores
- Downstream protocol satisfaction ratings

### 4.3 System Evolution

#### 4.3.1 Version History
- Current version with implementation date
- Previous versions with change descriptions
- Deprecation notices for obsolete approaches

#### 4.3.2 Rationale for Changes
- Documented reasons for each protocol evolution
- Evidence supporting the change decision
- Expected impact assessment

#### 4.3.3 Impact Assessment
- Measured outcomes of protocol changes
- Comparison against baseline metrics
- Validation of improvement hypotheses

#### 4.3.4 Rollback Procedures
- Process for reverting to previous protocol version
- Triggers for initiating rollback
- Communication plan for rollback events

### 4.4 Knowledge Capture and Organizational Learning

#### 4.4.1 Lessons Learned Repository
Maintain lessons learned with structure:
- Project/execution context
- Insight or discovery
- Action taken based on insight
- Outcome and applicability

#### 4.4.2 Knowledge Base Growth
- Systematic extraction of patterns from executions
- Scheduled knowledge base updates
- Quality metrics for knowledge base content

#### 4.4.3 Knowledge Sharing Mechanisms
- Internal distribution channels
- Onboarding integration
- Cross-team learning sessions
- Access controls and search tools

### 4.5 Future Planning

#### 4.5.1 Roadmap
- Planned enhancements with timelines
- Integration with other protocols
- Automation expansion plans

#### 4.5.2 Priorities
- Ranked list of improvement initiatives
- Resource requirements
- Expected benefits

#### 4.5.3 Resource Requirements
- Development effort estimates
- Tool or infrastructure needs
- Team capacity planning

#### 4.5.4 Timeline
- Milestone dates for major enhancements
- Dependencies on other work
- Risk buffers and contingencies

---

<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Standards for input/output artifacts and integration specifications -->
## 5. INTEGRATION POINTS

### 5.1 Inputs From:
- **Protocol 09**: `environment-validation-report.json` â€“ baseline infrastructure readiness
- **Protocol 21**: `PRE-DEPLOYMENT-PACKAGE.zip`, `readiness-approval.json`, `deployment-checklist.md`
- **Protocol 20**: `UAT-CLOSURE-PACKAGE.zip`, `uat-approval-record.json`

### 5.2 Outputs To:
- **Protocol 19**: `post-deployment-validation.json`, `deployment-health-log.md`, updated monitoring notes
- **Protocol 20**: `production-deployment-report.json`, `rollback-plan.md` (if triggered)
- **Protocol 22**: `DEPLOYMENT-REPORT.md`, `retrospective-inputs.json`
- **Protocol 21**: Metrics snapshot for performance baseline adjustments

### 5.3 Artifact Storage Locations:
- `.artifacts/deployment/` - Primary evidence storage
- `.cursor/context-kit/` - Context and configuration artifacts

---

<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Defines validation standards and criteria, not executing validation -->
## 6. QUALITY GATES

### Gate 1: Readiness Confirmation Gate
**Type:** Prerequisite  
**Purpose:** Verify all deployment prerequisites validated, approvals recorded, and rollback plan verified before production launch.

**Pass Criteria:**
- **Threshold:** Checklist completion metric â‰¥100% and prerequisite validation score â‰¥0.95.  
- **Boolean Check:** `readiness_checklist.status = complete` and `rollback_plan.status = verified`.  
- **Metrics:** Completion rate metric, validation score metric, prerequisite coverage metric documented in checklist.  
- **Evidence Link:** `.artifacts/protocol-15/deployment-readiness-checklist.json`, `.artifacts/protocol-15/release-manifest.md`.

**Automation:**
- Script: `python3 scripts/validate_gate_11_readiness.py --checklist .artifacts/protocol-15/deployment-readiness-checklist.json --output .artifacts/protocol-15/readiness-validation-report.json`
- Script: `python3 scripts/verify_rollback_plan.py --output .artifacts/protocol-15/rollback-readiness.json`
- CI Integration: `protocol-15-readiness.yml` workflow validates readiness on production branch; runs-on ubuntu-latest.
- Config: `config/protocol_gates/15.yaml` defines readiness completeness thresholds and prerequisite requirements.

**Failure Handling:**
- **Rollback:** Halt deployment, resolve missing checklist items, reschedule deployment after re-validation.  
- **Notification:** Alert Release Manager and deployment team via Slack when boolean check fails.  
- **Waiver:** Waiver requires executive sponsor approval with documented risk mitigation in `.artifacts/protocol-15/gate-waivers.json`.

### Gate 2: Approval & Change Freeze Gate
**Type:** Execution  
**Purpose:** Reconfirm staging health and obtain stakeholder acknowledgement of change freeze before production deployment.

**Pass Criteria:**
- **Threshold:** Staging health score â‰¥0.95 and freeze acknowledgement coverage â‰¥100%.  
- **Boolean Check:** `staging_validation.status = pass` and `freeze_confirmation.stakeholders_acknowledged = 100%`.  
- **Metrics:** Health score metric, acknowledgement coverage metric, stakeholder count metric captured in freeze log.  
- **Evidence Link:** `.artifacts/protocol-15/staging-validation-results.json`, `.artifacts/protocol-15/change-freeze-confirmation.md`.

**Automation:**
- Script: `python3 scripts/revalidate_staging_health.py --output .artifacts/protocol-15/staging-validation-results.json`
- Script: `python3 scripts/validate_gate_11_freeze.py --stakeholders config/release-approvers.yaml --output .artifacts/protocol-15/freeze-validation.json`
- CI Integration: `protocol-15-freeze.yml` workflow collects freeze acknowledgements; runs-on ubuntu-latest.
- Config: `config/protocol_gates/15.yaml` defines staging health thresholds and required stakeholder list.

**Failure Handling:**
- **Rollback:** Delay deployment, obtain missing acknowledgements, repeat freeze confirmation process.  
- **Notification:** Notify stakeholders and Release Manager when boolean check fails.  
- **Waiver:** Not applicable - freeze acknowledgement mandatory for production deployment.

### Gate 3: Production Launch Gate
**Type:** Execution  
**Purpose:** Confirm production deployment executed successfully with passing immediate validation checks.

**Pass Criteria:**
- **Threshold:** Deployment success rate â‰¥100% (zero blocking incidents) and validation success metric â‰¥0.95.  
- **Boolean Check:** `production_approval.status = approved` and `deployment_execution.status = success`.  
- **Metrics:** Success rate metric, incident count metric, validation pass rate metric logged in deployment report.  
- **Evidence Link:** `.artifacts/protocol-15/production-approval.json`, `.artifacts/protocol-15/production-deployment-report.json`, `.artifacts/protocol-15/post-deployment-validation.json`.

**Automation:**
- Script: `python3 scripts/execute_production_deployment.py --output .artifacts/protocol-15/production-deployment-report.json`
- Script: `python3 scripts/validate_gate_11_launch.py --validation-threshold 0.95 --output .artifacts/protocol-15/post-deployment-validation.json`
- CI Integration: `protocol-15-launch.yml` workflow monitors deployment execution; runs-on ubuntu-latest.
- Config: `config/protocol_gates/15.yaml` defines deployment success criteria and validation thresholds.

**Failure Handling:**
- **Rollback:** Execute rollback plan immediately, notify stakeholders, transition to Protocol 17 (Incident Response).  
- **Notification:** Alert Release Manager, deployment team, and incident response team when boolean check fails.  
- **Waiver:** Not permitted - production launch success mandatory for protocol completion.

### Gate 4: Stabilization & Reporting Gate
**Type:** Completion  
**Purpose:** Validate post-deployment health metrics within SLO tolerances and compile comprehensive release report.

**Pass Criteria:**
- **Threshold:** Health metric score within SLO tolerances and report completeness metric â‰¥0.95.  
- **Boolean Check:** `health_window.metrics_status = within_slo` and `deployment_report.status = complete`.  
- **Metrics:** SLO compliance metric, health score metric, report completeness metric documented in health log.  
- **Evidence Link:** `.artifacts/protocol-15/deployment-health-log.md`, `.artifacts/protocol-15/DEPLOYMENT-REPORT.md`, `.artifacts/protocol-15/retrospective-inputs.json`.

**Automation:**
- Script: `python3 scripts/monitor_health_window.py --duration 60 --output .artifacts/protocol-15/deployment-health-log.md`
- Script: `python3 scripts/validate_gate_11_reporting.py --threshold 0.95 --output .artifacts/protocol-15/report-validation.json`
- CI Integration: `protocol-15-stabilization.yml` workflow monitors health window and compiles report; runs-on ubuntu-latest.
- Config: `config/protocol_gates/15.yaml` defines SLO thresholds and stabilization window duration.

**Failure Handling:**
- **Rollback:** Extend monitoring window, escalate to Protocols 16 or 17 if thresholds exceeded, update report before handoff.  
- **Notification:** Alert monitoring team and Release Manager when boolean check fails.  
- **Waiver:** Waiver requires CTO approval with documented extended monitoring plan in gate waivers file.

### Compliance Integration
- **Industry Standards:** Production deployment aligns with CommonMark documentation, JSON Schema validation, YAML configuration standards.  
- **Security Requirements:** Deployment artifacts enforce SOC 2 audit logging, GDPR compliance for data handling, encrypted storage for production credentials.  
- **Regulatory Compliance:** Deployment procedures reference FTC disclosure requirements, ISO 27001 security controls, change management compliance.  
- **Governance:** Gate thresholds governed via `config/protocol_gates/15.yaml`, synchronized with protocol governance registry and production deployment dashboards.

---

<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Templates and standards for communication, not execution -->
## 7. COMMUNICATION PROTOCOLS

### 7.1 Status Announcements:
```
[MASTER RAYâ„¢ | PHASE 1 START] - Verifying deployment readiness artifacts...
[MASTER RAYâ„¢ | PHASE 2 START] - Reconfirming staging health prior to production launch...
[MASTER RAYâ„¢ | PHASE 3 START] - Executing production deployment sequence...
[MASTER RAYâ„¢ | PHASE 4 START] - Monitoring post-deployment health window...
[MASTER RAYâ„¢ | PHASE 4 COMPLETE] - Deployment report compiled. Evidence: DEPLOYMENT-REPORT.md.
[RAY ERROR] - "Failed at {step}. Reason: {explanation}. Awaiting instructions."
```

### User Interaction Prompts

**Confirmation Prompt:**
```
[RAY CONFIRMATION REQUIRED]
"Production deployment completed successfully. All post-deployment validation checks passed. Evidence ready:
- DEPLOYMENT-REPORT.md
- post-deployment-validation.json
- deployment-health-log.md

Confirm readiness to transition to Protocol 16 (Monitoring & Observability)?"
```

**Clarification Prompt:**
```
[RAY CLARIFICATION NEEDED]
"I detected ambiguity in the requirements regarding 'production deployment approval'. Please clarify:
1. Are all required stakeholders present for approval decision?
2. Should rollback plan be executed if any validation check fails?
3. What is the minimum stabilization window duration before handoff?

This will help me proceed more accurately."
```

**Decision Point Prompt:**
```
[RAY DECISION REQUIRED]
"Multiple deployment strategies identified for 'production rollout'. Please choose:
- Option A: Blue-Green Deployment - Pros: Zero downtime, instant rollback, Cons: Requires double infrastructure, higher cost
- Option B: Canary Deployment - Pros: Gradual rollout, risk mitigation, Cons: Requires traffic routing, longer rollout time
- Option C: Rolling Deployment - Pros: Infrastructure efficient, Cons: Potential service degradation during rollout

Which approach should I proceed with?"
```

**Feedback Prompt:**
```
[RAY FEEDBACK REQUESTED]
"DEPLOYMENT-REPORT.md draft complete. Please review and provide feedback on:
1. Completeness and accuracy of deployment timeline
2. Quality and alignment with stakeholder expectations
3. Any adjustments needed before finalization

Your feedback will be incorporated into the final deliverables."
```

### Error Messaging

**Error Severity Levels:**
- **CRITICAL:** Blocks protocol execution; requires immediate user intervention
- **WARNING:** May affect quality but allows continuation; user should review
- **INFO:** Informational only; no action required

**Error Template with Severity:**
```
[RAY GATE FAILED: Production Launch Gate] [CRITICAL]
"Quality gate 'Production Launch Gate' failed during deployment execution.
Criteria: Approval recorded, deployment successful, immediate checks passed
Actual: Post-deployment validation checks failed with error rate above threshold
Context: Deployment completed but smoke tests revealed service degradation
Resolution: Initiate rollback per plan, notify stakeholders, engage Protocol 17 (Incident Response)
Impact: Blocks handoff until resolved"
```

**Error Template with Context:**
```
[RAY VALIDATION ERROR: Post-Deployment Validation] [WARNING]
"Post-deployment validation checks exceeded tolerance thresholds.
Context: Latency metrics slightly elevated but within acceptable range for stabilization window
Resolution: Extend monitoring window and re-validate before handoff
Impact: May affect quality; review recommended before handoff"
```

**Error Template with Resolution:**
```
[RAY SCRIPT ERROR: Deployment Automation Script] [INFO]
"Deployment script encountered minor warning during execution.
Context: Script completed successfully but logged non-critical warning about resource allocation
Resolution: Warning logged for review; deployment proceeded successfully
Impact: Minor; automatic fix applied"
```

---

<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Reference standards for scripts and CI/CD integration -->
## 8. AUTOMATION HOOKS

**Registry Reference:** See `scripts/script-registry.json` for complete script inventory, ownership, and governance context.

### 8.1 Validation Scripts:
```bash
# Prerequisite validation
python scripts/validate_prerequisites_11.py

# Quality gate automation
python scripts/validate_gate_11_readiness.py --checklist .artifacts/deployment/deployment-readiness-checklist.json
python scripts/validate_gate_11_freeze.py --freeze-window .artifacts/deployment/freeze-config.json
python scripts/validate_gate_11_launch.py --validation-threshold 0.95
python scripts/validate_gate_11_reporting.py --report .artifacts/deployment/DEPLOYMENT-REPORT.md

# Evidence aggregation
python scripts/aggregate_evidence_11.py --output .artifacts/deployment/
```

### 8.2 CI/CD Integration:
```yaml
# GitHub Actions workflow integration
name: Protocol 15 Validation
on:
  workflow_dispatch:
  release:
    types: [created]
jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Run Protocol 15 Gates
        run: python scripts/run_protocol_15_gates.py
```

### 8.3 Manual Fallbacks:
When automation is unavailable, execute manual validation:
1. Review readiness checklist and approvals manually via documented evidence.
2. Observe deployment via war-room call, logging commands in spreadsheet.
3. Document results in `.artifacts/protocol-15/manual-validation-log.md`

---

<!-- [Category: EXECUTION-BASIC] -->
<!-- Why: Simple checklist workflow with validation items -->
## 9. HANDOFF CHECKLIST

### 9.1 Continuous Improvement Validation:
- [x] Execution feedback collected and logged
- [x] Lessons learned documented in protocol artifacts
- [x] Quality metrics captured for improvement tracking
- [x] Knowledge base updated with new patterns or insights
- [x] Protocol adaptation opportunities identified and logged
- [x] Retrospective scheduled (if required for this protocol phase)

### 9.2 Pre-Handoff Validation:
Before declaring protocol complete, validate:

- [x] All prerequisites were met
- [x] All workflow steps completed successfully
- [x] All quality gates passed (or waivers documented)
- [x] All evidence artifacts captured and stored
- [x] All integration outputs generated
- [x] All automation hooks executed successfully
- [x] Communication log complete

**Stakeholder Sign-Off:**
- **Approvals Required:** Release Manager approval confirming production deployment completed successfully and monitoring handoff ready
- **Reviewers:** Release Manager receives deployment report and validates readiness; SRE lead reviews post-deployment validation for monitoring activation
- **Sign-Off Evidence:** Deployment approval documented in `.artifacts/protocol-15/readiness-approval.json`, reviewer sign-off in `.artifacts/protocol-15/reviewer-signoff.json`
- **Confirmation Required:** Explicit confirmation that production deployment is stable, monitoring evidence captured, and Protocol 16 prerequisites satisfied

**Documentation Requirements:**
- **Document Format:** All artifacts in Markdown (`.md`) or JSON (`.json`) format
- **Storage Location:** All documentation stored in `.artifacts/protocol-15/` directory
- **Reviewer Documentation:** Reviewers document approval/rejection rationale in `.artifacts/protocol-15/reviewer-signoff.json`
- **Evidence Manifest:** Complete manifest file at `.artifacts/protocol-15/evidence-manifest.json` with all artifact checksums
- **Documentation Types:** All documentation includes logs, briefs, notes, transcripts, manifests, and reports as required

**Ready-for-Next-Protocol Statement:**
âœ… **Protocol 15 COMPLETE - Ready for Protocol 16**

Production deployment executed successfully, stabilization window completed, and monitoring evidence captured. Protocol 16 (Monitoring & Observability) can now proceed.

**Next Protocol Command:**
```bash
# Run Protocol 16: Monitoring & Observability
@apply .cursor/ai-driven-workflow/16-monitoring-observability.md
# Or trigger validation: python3 validators-system/scripts/validate_all_protocols.py --protocol 16 --workspace .
```

**Continuation Instructions:**
After Protocol 15 completion, run Protocol 16 continuation script to proceed. Generate session continuation for Protocol 16 workflow execution. Ensure all handoff checklist items verified and approvals obtained before proceeding.

**Dependencies Satisfied:**
- âœ… Production deployment completed and validated
- âœ… Post-deployment health window monitored
- âœ… Deployment report compiled with evidence
- âœ… Stakeholder sign-off obtained

---

<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Documentation standards and metrics tracking -->
## 10. EVIDENCE SUMMARY

### Artifact Generation Table

| Artifact Name | Metrics | Location | Evidence Link |
|---------------|---------|----------|---------------|
| readiness-checklist artifact (`deployment-readiness-checklist.json`) | Completion rate metric â‰¥100%, validation score â‰¥0.95, prerequisite count metric logged | `.artifacts/protocol-15/deployment-readiness-checklist.json` | Gate 1 readiness confirmation |
| release-manifest artifact (`release-manifest.md`) | Release scope metric, artifact count metric documented | `.artifacts/protocol-15/release-manifest.md` | Gate 1 release package |
| staging-validation artifact (`staging-validation-results.json`) | Health score metric â‰¥0.95, validation pass rate metric recorded | `.artifacts/protocol-15/staging-validation-results.json` | Gate 2 staging health |
| freeze-confirmation artifact (`change-freeze-confirmation.md`) | Acknowledgement coverage metric â‰¥100%, stakeholder count metric logged | `.artifacts/protocol-15/change-freeze-confirmation.md` | Gate 2 freeze evidence |
| production-approval artifact (`production-approval.json`) | Approval latency metric, approval status metric documented | `.artifacts/protocol-15/production-approval.json` | Gate 3 launch approval |
| deployment-report artifact (`production-deployment-report.json`) | Success rate metric â‰¥100%, incident count metric =0 | `.artifacts/protocol-15/production-deployment-report.json` | Gate 3 deployment evidence |
| post-deployment-validation artifact (`post-deployment-validation.json`) | Validation success metric â‰¥0.95, check pass rate metric recorded | `.artifacts/protocol-15/post-deployment-validation.json` | Gate 3 immediate validation |
| health-log artifact (`deployment-health-log.md`) | SLO compliance metric, health score metric within tolerances | `.artifacts/protocol-15/deployment-health-log.md` | Gate 4 stabilization evidence |
| release-report artifact (`DEPLOYMENT-REPORT.md`) | Report completeness metric â‰¥0.95, section coverage metric logged | `.artifacts/protocol-15/DEPLOYMENT-REPORT.md` | Gate 4 final report |
| retrospective-inputs artifact (`retrospective-inputs.json`) | Lesson count metric, feedback score metric documented | `.artifacts/protocol-15/retrospective-inputs.json` | Gate 4 learning capture |

### Storage Structure

**Protocol Directory:** `.artifacts/protocol-15/`  
- **Subdirectories:** `deployment-logs/` for execution traces, `health-metrics/` for monitoring data, `approvals/` for sign-offs.  
- **Permissions:** Read/write for deployment team and Release Manager, read-only for downstream protocols (16, 17, 22).  
- **Naming Convention:** `{artifact-name}.{extension}` (e.g., `production-deployment-report.json`, `DEPLOYMENT-REPORT.md`).

### Manifest Completeness

**Manifest File:** `.artifacts/protocol-15/evidence-manifest.json`

**Metadata Requirements:**
- Timestamp: ISO 8601 format (e.g., `2025-11-06T05:34:29Z`).  
- Artifact checksums: SHA-256 hash recorded for every artifact and deployment log.  
- Size: File size in bytes captured in manifest integrity block.  
- Dependencies: Upstream protocols (14, 13) and downstream consumers (16, 17, 19, 22) documented.

**Dependency Tracking:**
- Input: Protocol 14 `pre-deployment-manifest.json`, Protocol 13 `uat-signoff.json`, production environment config.  
- Output: All artifacts listed above plus gate validation reports and deployment evidence bundle.  
- Transformations: Readiness validation â†’ Freeze confirmation â†’ Production deployment â†’ Health stabilization â†’ Report compilation.

**Coverage:** Manifest documents 100% of required artifacts, deployment logs, approval records, and health metrics with checksum verification.

### Traceability

**Input Sources:**
- **Input From:** Protocol 14 `.artifacts/protocol-14/pre-deployment-manifest.json` â€“ Pre-deployment readiness baseline.  
- **Input From:** Protocol 13 `.artifacts/protocol-13/uat-signoff.json` â€“ UAT approval evidence for production deployment.  
- **Input From:** Production environment `config/production-env.yaml` â€“ Deployment configuration baseline.

**Output Artifacts:**
- **Output To:** `production-deployment-report.json` â€“ Consumed by Protocol 16 for monitoring setup and Protocol 19 for documentation.  
- **Output To:** `deployment-health-log.md` â€“ Health baseline for Protocol 16 (Monitoring & Observability).  
- **Output To:** `DEPLOYMENT-REPORT.md` â€“ Release documentation for Protocol 22 (Implementation Retrospective).  
- **Output To:** `retrospective-inputs.json` â€“ Learning capture for Protocol 22 retrospective analysis.  
- **Output To:** `evidence-manifest.json` â€“ Audit ledger for governance and compliance reviews.

**Transformation Steps:**
1. Readiness validation â†’ deployment-readiness-checklist.json and release-manifest.md: Validate prerequisites and compile release package.  
2. Freeze confirmation â†’ staging-validation-results.json and change-freeze-confirmation.md: Reconfirm staging health and collect freeze acknowledgements.  
3. Production deployment â†’ production-approval.json, production-deployment-report.json, post-deployment-validation.json: Execute deployment and validate success.  
4. Health stabilization â†’ deployment-health-log.md and DEPLOYMENT-REPORT.md: Monitor health window and compile release report.  
5. Evidence bundling â†’ evidence-manifest.json and retrospective-inputs.json: Archive all deployment evidence with checksums.

**Audit Trail:**
- Manifest stores timestamps, checksums, and deployer identities for each artifact.  
- Approval records retain signature timestamps and approver details.  
- Deployment logs preserve execution traces, error diagnostics, and rollback triggers.  
- Health metrics maintain SLO compliance status and threshold breach alerts.

### Archival Strategy

**Compression:**
- Deployment artifacts compressed into `.artifacts/protocol-15/PRODUCTION-DEPLOYMENT-BUNDLE.zip` after Gate 4 completion using ZIP standard compression.

**Retention Policy:**
- Active artifacts retained for 180 days post-deployment to support incident response and rollback scenarios.  
- Archived bundles retained for 5 years after project closure per SOC 2 and ISO 27001 requirements.  
- Cleanup automation `scripts/cleanup_artifacts.py` enforces retention quarterly.

**Retrieval Procedures:**
- Active artifacts accessed directly from `.artifacts/protocol-15/` with read-only permissions.  
- Archived bundles retrieved via `unzip .artifacts/protocol-15/PRODUCTION-DEPLOYMENT-BUNDLE.zip` with manifest checksum verification.  
- Emergency rollback playbook stored in `deployment-logs/rollback-procedures.md` for incident scenarios.

**Cleanup Process:**
- Quarterly cleanup logs actions to `.artifacts/protocol-15/cleanup-log.json` with deployment artifact inventory snapshot.  
- Critical production deployment artifacts flagged for extended retention require Release Manager and CISO approval.  
- Manual retention overrides documented with timestamp, approver identity, business justification, and regulatory compliance basis.

---

<!-- [Category: META-FORMATS] -->
<!-- Why: Meta-level protocol analysis and cognitive patterns -->
## 11. REASONING & COGNITIVE PROCESS

### 11.1 Reasoning Patterns

**Primary Reasoning Pattern: Systematic Execution**
- Execute protocol steps sequentially with validation at each checkpoint

**Secondary Reasoning Pattern: Quality-Driven Validation**
- Apply quality gates to ensure artifact completeness before downstream handoff

**Pattern Improvement Strategy:**
- Track pattern effectiveness via quality gate pass rates and downstream protocol feedback
- Quarterly review identifies pattern weaknesses and optimization opportunities
- Iterate patterns based on empirical evidence from completed executions

### 11.2 Decision Logic

#### 11.2.1 Decision Point 1: Execution Readiness
**Context:** Determining if prerequisites are met to begin protocol execution

**Decision Criteria:**
- All prerequisite artifacts present
- Required approvals obtained
- System state validated

**Outcomes:**
- Proceed: Execute protocol workflow
- Halt: Document missing prerequisites, notify stakeholders

**Logging:** Record decision and prerequisites status in execution log

### 11.3 Root Cause Analysis Framework

When protocol execution encounters blockers or quality gate failures:

1. **Identify Symptom:** What immediate issue prevented progress?
2. **Trace to Root Cause:**
   - Was prerequisite artifact missing or incomplete?
   - Did upstream protocol deliver inadequate inputs?
   - Were instructions ambiguous or insufficient?
   - Did environmental conditions fail?
3. **Document in Protocol Execution Log:**
   ```markdown
   **Blocker:** [Description]
   **Root Cause:** [Analysis]
   **Resolution:** [Action taken]
   **Prevention:** [Process/template update to prevent recurrence]
   ```
4. **Implement Fix:** Update protocol, re-engage stakeholders, adjust execution
5. **Validate Fix:** Re-run quality gates, confirm resolution

### 11.4 Learning Mechanisms

#### 11.4.1 Feedback Loops
**Purpose:** Establish continuous feedback collection to inform protocol improvements.

- **Execution feedback:** Collect outcome data after each protocol execution
- **Quality gate outcomes:** Track gate pass/fail patterns in historical logs
- **Downstream protocol feedback:** Capture issues reported by dependent protocols
- **Continuous monitoring:** Automated alerts for anomalies and degradation

#### 11.4.2 Improvement Tracking
**Purpose:** Systematically track protocol effectiveness improvements over time.

- **Metrics tracking:** Monitor key performance indicators in quarterly dashboards
- **Template evolution:** Log all protocol template changes with rationale and impact
- **Effectiveness measurement:** Compare before/after metrics for each improvement
- **Continuous monitoring:** Automated alerts when metrics degrade

#### 11.4.3 Knowledge Base Integration
**Purpose:** Build and leverage institutional knowledge to accelerate protocol quality.

- **Pattern library:** Maintain repository of successful execution patterns
- **Best practices:** Document proven approaches for common scenarios
- **Common blockers:** Catalog typical issues with proven resolutions
- **Industry templates:** Specialized variations for specific domains

#### 11.4.4 Adaptation Mechanisms
**Purpose:** Enable protocol to automatically adjust based on context and patterns.

- **Context adaptation:** Adjust execution based on project type, complexity, constraints
- **Threshold tuning:** Modify quality gate thresholds based on risk tolerance
- **Workflow optimization:** Streamline steps based on historical efficiency data
- **Tool selection:** Choose optimal automation based on available resources

### 11.5 Meta-Cognition

#### 11.5.1 Self-Awareness and Process Awareness
**Purpose:** Enable AI to maintain explicit awareness of execution state and limitations.

**Awareness Statement Protocol:**
At each major execution checkpoint, generate awareness statement:
- Current phase and step status
- Artifacts completed vs. pending
- Identified blockers and their severity
- Confidence level in current outputs
- Known limitations and assumptions
- Required inputs for next steps

#### 11.5.2 Process Monitoring and Progress Tracking
**Purpose:** Continuously track execution status and detect anomalies.

- **Progress tracking:** Update execution status after each step
- **Velocity monitoring:** Flag execution delays beyond expected duration
- **Quality monitoring:** Track gate pass rates and artifact completeness
- **Anomaly detection:** Alert on unexpected patterns or deviations

#### 11.5.3 Self-Correction Protocols
**Purpose:** Enable autonomous detection and correction of execution issues.

- **Halt condition detection:** Recognize blockers and escalate appropriately
- **Quality gate failure handling:** Generate corrective action plans
- **Anomaly response:** Diagnose and propose fixes for unexpected conditions
- **Recovery procedures:** Maintain execution state for graceful resume

#### 11.5.4 Continuous Improvement Integration
**Purpose:** Systematically capture lessons and evolve protocol effectiveness.

- **Retrospective execution:** Conduct after-action reviews post-completion
- **Template review cadence:** Scheduled protocol enhancement cycles
- **Gate calibration:** Periodic adjustment of pass criteria
- **Tool evaluation:** Assessment of automation effectiveness
