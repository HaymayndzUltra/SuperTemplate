---
**MASTER RAYâ„¢ AI-Driven Workflow Protocol**
Â© 2025 - All Rights Reserved
---

# PROTOCOL 14 : PRE-DEPLOYMENT VALIDATION & STAGING READINESS (RELEASE COMPLIANT)

**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.

<!-- [Category: GUIDELINES-FORMATS - Requirements & Standards] -->
## 1. PREREQUISITES

**[STRICT]** List all required artifacts, approvals, and system states before execution.

### 1.1 Required Artifacts
**[MUST]** Validate presence of upstream artifacts before protocol initiation:

- **`[REQUIRED]`** `QUALITY-AUDIT-PACKAGE.zip` from Protocol 12 â€“ audit readiness evidence
- **`[REQUIRED]`** `INTEGRATION-EVIDENCE.zip` from Protocol 11 â€“ integration validation summary
- **`[REQUIRED]`** `UAT-CLOSURE-PACKAGE.zip` from Protocol 13 â€“ stakeholder acceptance proof
- **`[REQUIRED]`** `.artifacts/pre-deployment/release-manifest.json` (initial draft) from Release Planning
- **`[REQUIRED]`** Latest deployment scripts (`scripts/deploy_*.sh`, `scripts/rollback_*.sh`) from repository

### 1.2 Required Approvals
**[MUST]** Obtain necessary authorizations:

- **`[REQUIRED]`** Quality Audit readiness recommendation signed by Senior Quality Engineer (Protocol 12)
- **`[REQUIRED]`** Product Owner confirmation that release scope is fixed (Protocol 06)
- **`[REQUIRED]`** Security and compliance lead clearance for staging deployment rehearsals

### 1.3 System State Requirements
**[MUST]** Verify system readiness:

- **`[REQUIRED]`** Staging environment mirrors production configuration (infrastructure, secrets, feature flags)
- **`[REQUIRED]`** Access to deployment automation credentials and secret stores for staging
- **`[REQUIRED]`** Monitoring dashboards accessible for baseline capture

<!-- [Category: GUIDELINES-FORMATS - Role Definition] -->
## 2. AI ROLE AND MISSION

You are a **Release Engineer**. Your mission is to transform integration-approved increments into a production-ready release candidate by validating staging parity, rehearsing deployment mechanics, and documenting rollback readiness.

**ðŸš« [CRITICAL]** DO NOT issue a production go/no-go package unless staging mirrors production configurations and both deployment and rollback procedures have been executed successfully with captured evidence.

<!-- [Category: EXECUTION-FORMATS - Mixed variants by phase] -->
## 3. WORKFLOW

<!-- [Category: EXECUTION-BASIC - Sequential validation tasks] -->
### PHASE 1: Intake Validation and Staging Alignment

**Reasoning Pattern:** Validate-before-rehearse heuristic â€” systematically validate upstream approvals and staging parity before deployment rehearsal. This prevents wasted rehearsal effort on invalid configurations or missing approvals.

**Pattern Improvement:** Track intake validation failures to identify common gaps between upstream protocols and pre-deployment requirements. Refine validation logic based on execution feedback. Iteratively improve staging parity validation templates.

**Example Scenario:** When validating intake, confirm all upstream approvals from Protocols 11, 12, and 13 are present and valid. If any approval missing or expired, halt and request renewal. Then validate staging parity to confirm staging matches production configuration. Therefore, deployment rehearsal proceeds with validated approvals and staging environment, preventing rehearsal failures.

**Strategy Rationale:** Because deployment rehearsal validates production readiness, ensuring approvals are valid and staging matches production before rehearsal prevents invalid rehearsal results. This systematic validation reduces rehearsal rework and ensures accurate readiness assessment.

**Meta-Cognitive Check:** Before validating intake, assess your own limitations:
- **Awareness:** Recognize that upstream approvals may be expired or staging configuration may have drifted from production
- **Limitations:** Understand that staging parity validation may miss subtle configuration differences requiring manual review
- **Capacity:** Acknowledge that staging alignment may require multiple stakeholder consultations, delaying rehearsal
- **Correction:** Be prepared to escalate approval issues to Protocol 11/12/13 owners or request staging remediation

**Decision Tree:** When validating intake and staging:
- **IF** all upstream approvals valid â†’ Proceed to staging parity validation
- **ELSE IF** approvals missing or expired â†’ Halt and request renewal, document in `intake-validation-report.json`
- **IF** staging parity confirmed â†’ Proceed to test data refresh
- **IF** staging drift detected â†’ Document drift and request remediation, then rerun parity validation
- **THEN** Verify completeness score = 100% and drift severity â‰¤ low

1. **`[MUST]` Confirm Upstream Approvals:**
   * **Action:** Validate required artifacts and approvals from Protocols 11, 12, and 13 before staging rehearsal begins.
   * **Reasoning:** Apply validate-before-rehearse pattern â€” validate upstream approvals before deployment rehearsal. Use decision tree above to determine next steps based on approval validity.
   * **Problem-Solving:** If approvals missing or expired:
  1. **Root Cause:** Identify why approvals are missing (artifacts not generated, approvals expired, or protocol execution incomplete)
  2. **Solution:** Document missing approvals in `intake-validation-report.json` and request renewal from Protocol 11/12/13 owners. If renewal delayed, mark as `REQUIRES_APPROVAL` and proceed tentatively
  3. **Validation:** Verify all prerequisite artifacts present and approvals valid before proceeding
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 1 START] - Validating upstream approvals and artifact completeness..."
   * **Halt Condition:** Stop if any prerequisite artifact missing or expired.
   * **Evidence:** `.artifacts/pre-deployment/intake-validation-report.json` summarizing status.

2. **`[MUST]` Validate Staging Parity:**
   * **Action:** Compare staging vs production configurations, secrets, and infrastructure components for drift detection.
   * **Reasoning:** Use staging parity validation pattern â€” systematically compare staging and production configurations to detect drift. This ensures staging provides accurate production readiness assessment.
   * **Problem-Solving:** If staging drift detected:
  1. **Root Cause:** Identify why drift exists (configuration changes not synced, secrets updated separately, or infrastructure drift)
  2. **Solution:** Document drift in `staging-parity-report.json` and request staging remediation from DevOps lead. If remediation delayed, mark as `REQUIRES_REMEDIATION` and proceed with known drift
  3. **Validation:** Verify drift severity â‰¤ low before proceeding
   * **Communication:** 
     > "[PHASE 1] Staging parity check underway. Reporting drift if detected..."
   * **Halt Condition:** Pause if drift exists without remediation plan.
   * **Evidence:** `.artifacts/pre-deployment/staging-parity-report.json` including diff details.

3. **`[GUIDELINE]` Refresh Test Data & Feature Flags:**
   * **Action:** Sync staging datasets, feature flags, and service stubs to align with release candidate requirements.
   * **Reasoning:** Apply test data refresh pattern â€” sync staging data and feature flags to match release candidate. This ensures rehearsal tests realistic production scenarios.
   * **Evidence:** `.artifacts/pre-deployment/staging-data-refresh.md`
   * **Example:**
     ```bash
     python scripts/refresh_staging_data.py --env staging --output .artifacts/pre-deployment/staging-data-refresh.md
     ```

<!-- [Category: EXECUTION-SUBSTEPS - Complex deployment rehearsal] -->
### PHASE 2: Deployment Rehearsal and Verification

**Reasoning Pattern:** Rehearse-then-validate strategy â€” systematically execute deployment rehearsal and validate results before rollback verification. This ensures deployment mechanics are validated before confirming rollback readiness.

**Example Scenario:** When rehearsing deployment, run deployment scripts in staging replicating production sequencing. Then execute smoke and acceptance tests to validate deployment success. Finally, capture observability baseline for post-deployment monitoring. Therefore, deployment rehearsal is complete with validated mechanics and monitoring baseline, ensuring production readiness.

**Strategy Rationale:** Because deployment rehearsal validates production deployment mechanics, ensuring rehearsal executes successfully and tests pass before rollback verification prevents deployment failures. This systematic rehearsal ensures deployment readiness.

**Decision Tree:** When rehearsing and validating:
- **IF** deployment rehearsal executes successfully â†’ Proceed to test validation
- **ELSE IF** deployment fails â†’ Investigate failures and rerun rehearsal
- **IF** smoke and acceptance tests pass â†’ Proceed to observability baseline capture
- **ELSE IF** critical tests fail â†’ Halt and request mitigation plans
- **THEN** Verify deployment successful and all critical tests pass

1. **`[MUST]` Execute Deployment and Testing:**
   
   * **2.1. Run Staging Deployment Rehearsal:**
     * **Action:** Run deployment scripts in staging replicating production sequencing with logging enabled.
     * **Reasoning:** Apply systematic rehearsal pattern â€” execute deployment scripts in staging replicating production sequence. Use decision tree above to determine next steps based on rehearsal results.
     * **Problem-Solving:** If deployment rehearsal fails:
    1. **Root Cause:** Identify why rehearsal failed (script errors, infrastructure issues, or sequencing problems)
    2. **Solution:** Fix script errors, resolve infrastructure issues, or correct sequencing, then rerun rehearsal
    3. **Validation:** Verify deployment successful before proceeding
     * **Communication:** 
       > "[MASTER RAYâ„¢ | PHASE 2 START] - Rehearsing deployment on staging environment..."
     * **Halt Condition:** Stop if automation fails or unexpected errors occur.
     * **Evidence:** `.artifacts/pre-deployment/staging-deployment-run.log` capturing commands and results.
   
   * **2.2. Validate Smoke & Acceptance Tests:**
     * **Action:** Execute smoke, end-to-end, and targeted regression suites against staging release candidate.
     * **Reasoning:** Use comprehensive test validation pattern â€” execute smoke, end-to-end, and regression tests to validate deployment success. This ensures release candidate functions correctly after deployment.
     * **Problem-Solving:** If critical tests fail:
    1. **Root Cause:** Identify why tests failed (deployment issues, code defects, or test environment problems)
    2. **Solution:** Fix deployment issues, resolve code defects, or fix test environment, then rerun tests
    3. **Validation:** Verify all critical tests pass before proceeding
     * **Communication:** 
       > "[PHASE 2] Staging test suites executing. Monitoring pass/fail status..."
     * **Halt Condition:** Pause if critical tests fail without mitigation.
     * **Evidence:** `.artifacts/pre-deployment/staging-test-results.json` with coverage metrics.
   
   * **2.3. Capture Observability Baseline:**
     * **Action:** Record monitoring dashboards and metrics post-rehearsal for Protocol 19 reference.
     * **Reasoning:** Apply observability baseline pattern â€” capture monitoring metrics post-rehearsal as baseline for post-deployment comparison. This enables performance monitoring.
     * **Evidence:** `.artifacts/pre-deployment/observability-baseline.md`
     * **Example:**
       ```markdown
       - Metric: API latency (p95) â€“ 320ms
       - Metric: Error rate â€“ 0.2%
       ```

<!-- [Category: EXECUTION-SUBSTEPS - Rollback and security verification] -->
### PHASE 3: Rollback, Security, and Operational Readiness

**Reasoning Pattern:** Validate-before-approve heuristic â€” systematically validate rollback, security, and operational readiness before final approval. This ensures all recovery and compliance requirements are met before production deployment.

**Example Scenario:** When validating recovery, execute rollback automation to verify recovery path works. Then run security scans and compliance validations. Finally, confirm runbooks and support coverage are updated. Therefore, all recovery, security, and operational requirements are validated before final approval, ensuring production readiness.

**Strategy Rationale:** Because production deployment requires recovery and compliance readiness, ensuring rollback, security, and operational readiness before approval prevents production incidents. This systematic validation ensures deployment safety.

**Decision Tree:** When validating recovery and compliance:
- **IF** rollback rehearsal successful â†’ Proceed to security scans
- **ELSE IF** rollback fails â†’ Fix rollback automation and rerun rehearsal
- **IF** security scans pass â†’ Proceed to operational readiness validation
- **ELSE IF** blocking findings identified â†’ Halt and request remediation
- **IF** operational readiness confirmed â†’ Proceed to final readiness review
- **THEN** Verify rollback successful, security scans pass, and operational readiness confirmed

1. **`[MUST]` Validate Recovery and Compliance:**
   
   * **3.1. Rehearse Rollback Procedure:**
     * **Action:** Execute rollback automation or blue/green switchback to validate recovery path.
     * **Reasoning:** Apply rollback-first pattern â€” validate rollback procedure before final approval. Use decision tree above to determine next steps based on rollback results.
     * **Problem-Solving:** If rollback fails:
    1. **Root Cause:** Identify why rollback failed (automation errors, recovery time exceeded, or infrastructure issues)
    2. **Solution:** Fix rollback automation, optimize recovery time, or resolve infrastructure issues, then rerun rollback rehearsal
    3. **Validation:** Verify rollback successful and recovery time objective met before proceeding
     * **Communication:** 
       > "[MASTER RAYâ„¢ | PHASE 3 START] - Verifying rollback and recovery procedures..."
     * **Halt Condition:** Stop if rollback fails or exceeds recovery time objective.
     * **Evidence:** `.artifacts/pre-deployment/rollback-verification-report.json` detailing steps and timings.
   
   * **3.2. Complete Security & Compliance Checks:**
     * **Action:** Run required security scans, license audits, and compliance validations pre-production.
     * **Reasoning:** Use security-first pattern â€” run security scans and compliance validations before production deployment. This ensures production security and compliance.
     * **Problem-Solving:** If blocking findings identified:
    1. **Root Cause:** Identify why findings exist (vulnerabilities, license violations, or compliance gaps)
    2. **Solution:** Remediate vulnerabilities, resolve license violations, or fix compliance gaps, then rerun scans
    3. **Validation:** Verify all blocking findings resolved before proceeding
     * **Communication:** 
       > "[PHASE 3] Executing security and compliance scans for release candidate..."
     * **Halt Condition:** Pause if blocking findings identified.
     * **Evidence:** `.artifacts/pre-deployment/security-compliance-report.json` with findings and approvals.
   
   * **3.3. Validate Runbooks & Support Coverage:**
     * **Action:** Confirm operational runbooks, on-call rotations, and escalation matrices updated for release.
     * **Reasoning:** Apply operational readiness pattern â€” validate runbooks and support coverage are updated for release. This ensures operational support readiness.
     * **Evidence:** Updated runbooks and support documentation
     * **Example:**
       ```markdown
       - Runbook: api-service.md â€“ updated 2024-05-30
       - On-call: Primary SRE (Alex), Backup (Jordan)
       ```

<!-- [Category: EXECUTION-BASIC - Sequential package and handoff] -->
### PHASE 4: Final Readiness Review and Handoff

**Reasoning Pattern:** Package-before-approve heuristic â€” systematically assemble readiness package and conduct review before handoff. This ensures all evidence is complete and approvals are recorded before production deployment.

**Example Scenario:** When preparing handoff, assemble parity report, deployment evidence, test results, and security findings into readiness package. Then conduct readiness review with stakeholders and capture approvals. Finally, update deployment checklist based on rehearsal learnings. Therefore, readiness package is complete with approvals and updated checklist, enabling production deployment.

**Strategy Rationale:** Because production deployment requires comprehensive readiness validation, ensuring readiness package is complete and approvals recorded before handoff prevents deployment risks. This systematic packaging ensures deployment readiness.

**Decision Tree:** When packaging and reviewing:
- **IF** readiness package assembled â†’ Proceed to readiness review
- **ELSE IF** package incomplete â†’ Complete missing evidence before proceeding
- **IF** approvals received â†’ Proceed to checklist updates
- **IF** approvals withheld â†’ Halt and resolve risks, then re-request approval
- **THEN** Verify package complete and approvals recorded

1. **`[MUST]` Assemble Go/No-Go Package:**
   * **Action:** Bundle parity report, deployment and rollback evidence, test results, and security findings into `PRE-DEPLOYMENT-PACKAGE.zip`.
   * **Reasoning:** Apply comprehensive packaging pattern â€” bundle all readiness evidence into distributable package. This enables production deployment approval.
   * **Problem-Solving:** If package incomplete:
  1. **Root Cause:** Identify why package is incomplete (missing evidence, manifest errors, or checksum failures)
  2. **Solution:** Complete missing evidence, fix manifest errors, or regenerate checksum, then reassemble package
  3. **Validation:** Verify package complete and checksum valid before proceeding
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 4 START] - Compiling pre-deployment readiness package for release approval..."
   * **Halt Condition:** Stop if package contents incomplete or checksum invalid.
   * **Evidence:** `.artifacts/pre-deployment/pre-deployment-manifest.json` indexing artifacts.

2. **`[MUST]` Conduct Readiness Review:**
   * **Action:** Present findings to Release Manager and stakeholders; capture approvals, risks, and action items.
   * **Reasoning:** Use systematic review pattern â€” conduct readiness review with stakeholders and capture approvals. This ensures deployment readiness approval.
   * **Problem-Solving:** If approvals withheld:
  1. **Root Cause:** Identify why approvals withheld (risks unresolved, evidence incomplete, or stakeholder concerns)
  2. **Solution:** Resolve risks, complete evidence, or address stakeholder concerns, then re-request approval
  3. **Validation:** Verify approvals recorded before proceeding
   * **Communication:** 
     > "[PHASE 4] Readiness review in progress. Recording decisions and risk mitigations..."
   * **Halt Condition:** Pause if approvals withheld or risks unresolved.
   * **Evidence:** `.artifacts/pre-deployment/readiness-approval.json` with signatures.

3. **`[GUIDELINE]` Publish Deployment Checklist Updates:**
   * **Action:** Update production deployment checklist and communication plan based on rehearsal learnings.
   * **Reasoning:** Apply continuous improvement pattern â€” update deployment checklist based on rehearsal learnings. This enables improved production deployments.
   * **Evidence:** `.artifacts/pre-deployment/deployment-checklist.md`
   * **Example:**
     ```bash
     python scripts/update_deployment_checklist.py --source .artifacts/pre-deployment/staging-deployment-run.log --output .artifacts/pre-deployment/deployment-checklist.md
     ```

<!-- [Category: META-FORMATS - Retrospective and Learning] -->
## 4. REFLECTION & LEARNING

### 4.1 Retrospective Guidance

After completing protocol execution (successful or halted), conduct retrospective:

**Timing:** Within 24-48 hours of completion

**Participants:** Protocol executor, downstream consumers, stakeholders

**Agenda:**
1. **What went well:**
   - Which steps executed smoothly and efficiently?
   - Which quality gates were well-calibrated?
   - Which artifacts provided high value to downstream protocols?

2. **What went poorly:**
   - Which steps encountered blockers or delays?
   - Which quality gates were too strict or too lenient?
   - Which artifacts required rework or clarification?

3. **Action items:**
   - Protocol template updates needed?
   - Quality gate threshold adjustments?
   - New automation opportunities?

**Output:** Retrospective report stored in protocol execution artifacts

### 4.2 Continuous Improvement Opportunities

#### Identified Improvement Opportunities
- Identify based on protocol-specific execution patterns

#### Process Optimization Tracking
- Track key performance metrics over time
- Monitor quality gate pass rates and execution velocity
- Measure downstream satisfaction and rework requests
- Identify automation opportunities

#### Tracking Mechanisms and Metrics
- Quarterly metrics dashboard with trends
- Improvement tracking log with before/after comparisons
- Evidence of improvement validation

#### Evidence of Improvement and Validation
- Metric trends showing improvement trajectories
- A/B testing results for protocol changes
- Stakeholder feedback scores
- Downstream protocol satisfaction ratings

### 4.3 System Evolution

#### Version History
- Current version with implementation date
- Previous versions with change descriptions
- Deprecation notices for obsolete approaches

#### Rationale for Changes
- Documented reasons for each protocol evolution
- Evidence supporting the change decision
- Expected impact assessment

#### Impact Assessment
- Measured outcomes of protocol changes
- Comparison against baseline metrics
- Validation of improvement hypotheses

#### Rollback Procedures
- Process for reverting to previous protocol version
- Triggers for initiating rollback
- Communication plan for rollback events

### 4.4 Knowledge Capture and Organizational Learning

#### Lessons Learned Repository
Maintain lessons learned with structure:
- Project/execution context
- Insight or discovery
- Action taken based on insight
- Outcome and applicability

#### Knowledge Base Growth
- Systematic extraction of patterns from executions
- Scheduled knowledge base updates
- Quality metrics for knowledge base content

#### Knowledge Sharing Mechanisms
- Internal distribution channels
- Onboarding integration
- Cross-team learning sessions
- Access controls and search tools

### 4.5 Future Planning

#### Roadmap
- Planned enhancements with timelines
- Integration with other protocols
- Automation expansion plans

#### Priorities
- Ranked list of improvement initiatives
- Resource requirements
- Expected benefits

#### Resource Requirements
- Development effort estimates
- Tool or infrastructure needs
- Team capacity planning

#### Timeline
- Milestone dates for major enhancements
- Dependencies on other work
- Risk buffers and contingencies

<!-- [Category: GUIDELINES-FORMATS - Integration Standards] -->
## 5. INTEGRATION POINTS

### 5.1 Inputs From
- **Protocol 12:** `QUALITY-AUDIT-PACKAGE.zip`, readiness recommendation â€“ informs release gate
- **Protocol 11:** `integration-evidence-bundle.zip` â€“ verifies integrated functionality
- **Protocol 13:** `UAT-CLOSURE-PACKAGE.zip`, `uat-approval-record.json` â€“ confirms user acceptance

### 5.2 Outputs To
- **Protocol 15:** `PRE-DEPLOYMENT-PACKAGE.zip`, `readiness-approval.json`, `deployment-checklist.md`
- **Protocol 19:** `observability-baseline.md`, `staging-test-results.json`
- **Protocol 20:** `rollback-verification-report.json` for incident response readiness
- **Protocol 21:** `staging-parity-report.json` supporting performance baseline alignment

### 5.3 Artifact Storage Locations
- `.artifacts/pre-deployment/` - Primary evidence storage
- `.cursor/context-kit/` - Context and configuration artifacts

<!-- [Category: GUIDELINES-FORMATS - Quality Gate Definitions] -->
## 6. QUALITY GATES

### Gate 1: Intake Confirmation Gate
**Type:** Prerequisite  
**Purpose:** Verify all upstream approvals obtained and staging environment parity validated before rehearsal begins.

**Pass Criteria:**
- **Threshold:** Completeness score â‰¥100% and configuration drift metric â‰¤0.05 (low severity).  
- **Boolean Check:** `intake_validation.status = pass` and `staging_parity.drift_severity = low`.  
- **Metrics:** Completeness score metric, drift severity metric, approval coverage metric documented in validation report.  
- **Evidence Link:** `.artifacts/protocol-14/intake-validation-report.json`, `.artifacts/protocol-14/staging-parity-report.json`.

**Automation:**
- Script: `python3 scripts/validate_gate_10_intake.py --drift-threshold low --output .artifacts/protocol-14/intake-validation-report.json`
- Script: `python3 scripts/check_staging_parity.py --output .artifacts/protocol-14/staging-parity-report.json`
- CI Integration: `protocol-14-intake.yml` workflow validates intake on every staging branch merge; runs-on ubuntu-latest.
- Config: `config/protocol_gates/14.yaml` defines completeness thresholds and drift severity limits.

**Failure Handling:**
- **Rollback:** Halt protocol execution, remediate configuration drift or obtain missing approvals, rerun intake validation.  
- **Notification:** Alert Release Manager and infrastructure team via Slack when boolean check fails.  
- **Waiver:** Waiver requires Release Manager approval with documented risk assessment in `.artifacts/protocol-14/gate-waivers.json`.

### Gate 2: Deployment Rehearsal Gate
**Type:** Execution  
**Purpose:** Confirm deployment rehearsal executes successfully with passing smoke and regression test coverage.

**Pass Criteria:**
- **Threshold:** Deployment success rate â‰¥100% (zero blocking errors) and test coverage metric â‰¥0.90.  
- **Boolean Check:** `deployment_status = success` and `test_execution.status = pass`.  
- **Metrics:** Deployment success rate metric, test coverage metric, error count metric captured in rehearsal report.  
- **Evidence Link:** `.artifacts/protocol-14/staging-deployment-run.log`, `.artifacts/protocol-14/staging-test-results.json`.

**Automation:**
- Script: `python3 scripts/run_deployment_rehearsal.py --env staging --output .artifacts/protocol-14/staging-deployment-run.log`
- Script: `python3 scripts/validate_gate_10_rehearsal.py --coverage 0.90 --output .artifacts/protocol-14/staging-test-results.json`
- CI Integration: `protocol-14-rehearsal.yml` workflow executes deployment rehearsal on staging; runs-on ubuntu-latest.
- Config: `config/protocol_gates/14.yaml` defines deployment success thresholds and coverage requirements.

**Failure Handling:**
- **Rollback:** Rollback staging environment, investigate failures, fix issues, rerun rehearsal before proceeding.  
- **Notification:** Notify deployment team and QA lead when boolean check fails.  
- **Waiver:** Not permitted - deployment rehearsal success mandatory for production readiness.

### Gate 3: Rollback & Security Gate
**Type:** Execution  
**Purpose:** Validate rollback procedures complete within RTO and security/compliance scans pass without blocking findings.

**Pass Criteria:**
- **Threshold:** Rollback completion time â‰¤RTO (Recovery Time Objective) and security finding severity â‰¤Medium.  
- **Boolean Check:** `rollback_verification.status = pass` and `security_scan.blocking_findings = 0`.  
- **Metrics:** Rollback time metric (minutes), security severity metric, compliance score metric logged in verification report.  
- **Evidence Link:** `.artifacts/protocol-14/rollback-verification-report.json`, `.artifacts/protocol-14/security-compliance-report.json`.

**Automation:**
- Script: `python3 scripts/test_rollback_procedures.py --rto 10 --output .artifacts/protocol-14/rollback-verification-report.json`
- Script: `python3 scripts/validate_gate_10_security.py --severity-threshold medium --output .artifacts/protocol-14/security-compliance-report.json`
- CI Integration: `protocol-14-security.yml` workflow runs security scans and rollback validation; runs-on ubuntu-latest.
- Config: `config/protocol_gates/14.yaml` defines RTO limits and security severity thresholds.

**Failure Handling:**
- **Rollback:** Address rollback procedure gaps, remediate security findings, rerun validations until thresholds met.  
- **Notification:** Alert Security team and Release Manager when boolean check fails.  
- **Waiver:** Waiver requires CISO and CTO approval with documented compensating controls in gate waivers file.

### Gate 4: Readiness Approval Gate
**Type:** Completion  
**Purpose:** Ensure go/no-go decision package complete with all readiness approvals and deployment checklist finalized.

**Pass Criteria:**
- **Threshold:** Manifest completeness metric â‰¥0.95 and approval coverage metric â‰¥100%.  
- **Boolean Check:** `readiness_approval.status = approved` and `deployment_checklist.status = complete`.  
- **Metrics:** Package completeness metric, approval latency metric, checklist coverage metric documented in manifest.  
- **Evidence Link:** `.artifacts/protocol-14/pre-deployment-manifest.json`, `.artifacts/protocol-14/readiness-approval.json`, `.artifacts/protocol-14/deployment-checklist.md`.

**Automation:**
- Script: `python3 scripts/validate_gate_10_readiness.py --threshold 0.95 --output .artifacts/protocol-14/pre-deployment-manifest.json`
- Script: `python3 scripts/collect_readiness_approvals.py --output .artifacts/protocol-14/readiness-approval.json`
- CI Integration: `protocol-14-readiness.yml` workflow validates readiness package and posts to governance dashboard; runs-on ubuntu-latest.
- Config: `config/protocol_gates/14.yaml` defines manifest completeness and approval requirements.

**Failure Handling:**
- **Rollback:** Obtain missing approvals, rebuild readiness package, update deployment checklist, rerun readiness validation.  
- **Notification:** Alert Release Manager and Protocol 15 owner when boolean check fails.  
- **Waiver:** Not applicable - readiness approvals mandatory for Protocol 15 handoff.

### Compliance Integration
- **Industry Standards:** Pre-deployment validation aligns with CommonMark documentation, JSON Schema validation, and YAML configuration standards.  
- **Security Requirements:** Security scans enforce SOC 2 requirements, GDPR compliance for data handling, encrypted artifact storage.  
- **Regulatory Compliance:** Deployment procedures reference FTC disclosure requirements, ISO 27001 security controls, and domain-specific mandates.  
- **Governance:** Gate thresholds governed via `config/protocol_gates/14.yaml`, synchronized with protocol governance registry and compliance dashboards.

<!-- [Category: GUIDELINES-FORMATS - Communication Standards] -->
## 7. COMMUNICATION PROTOCOLS

### 7.1 Status Announcements
**[GUIDELINE]** Standard status messages for protocol execution:

```
[MASTER RAYâ„¢ | PHASE 1 START] - Validating upstream approvals and artifact completeness...
[MASTER RAYâ„¢ | PHASE 1 COMPLETE] - Intake validation succeeded. Evidence: intake-validation-report.json.
[MASTER RAYâ„¢ | PHASE 2 START] - Rehearsing deployment on staging environment...
[MASTER RAYâ„¢ | PHASE 3 START] - Verifying rollback and recovery procedures...
[MASTER RAYâ„¢ | PHASE 4 START] - Compiling pre-deployment readiness package for release approval...
[MASTER RAYâ„¢ | PHASE 4 COMPLETE] - Pre-deployment package ready. Evidence: PRE-DEPLOYMENT-PACKAGE.zip.
[RAY ERROR] - "Failed at {step}. Reason: {explanation}. Awaiting instructions."
```

### 7.2 User Interaction Prompts

**Confirmation Prompt:**
```
[RAY CONFIRMATION REQUIRED]
"Pre-deployment validation complete and readiness package ready:
- PRE-DEPLOYMENT-PACKAGE.zip
- readiness-approval.json
- staging-parity-report.json
- rollback-verification-report.json

Please review and confirm readiness to proceed to Protocol 15."
```

**Clarification Prompt:**
```
[RAY CLARIFICATION NEEDED]
"I detected ambiguity in the requirements regarding '{specific deployment strategy or staging configuration}'. Please clarify:
1. What are the acceptable thresholds for staging drift detection?
2. What is the required rollback time objective (RTO) for recovery?
3. Are there specific security compliance requirements that must be validated?

This will help me proceed more accurately."
```

**Decision Point Prompt:**
```
[RAY DECISION REQUIRED]
"Multiple approaches identified for '{deployment rehearsal strategy or rollback approach}'. Please choose:
- Option A: [Description] - Pros: [list], Cons: [list]
- Option B: [Description] - Pros: [list], Cons: [list]
- Option C: [Description] - Pros: [list], Cons: [list]

Which approach should I proceed with?"
```

**Feedback Prompt:**
```
[RAY FEEDBACK REQUESTED]
"Pre-deployment readiness package draft complete. Please review and provide feedback on:
1. Completeness and accuracy of readiness evidence
2. Quality and alignment with deployment requirements
3. Any adjustments needed before finalization

Your feedback will be incorporated into the final deliverables."
```

### 7.3 Error Messaging

**Error Severity Levels:**
- **CRITICAL:** Blocks protocol execution; requires immediate user intervention
- **WARNING:** May affect quality but allows continuation; user should review
- **INFO:** Informational only; no action required

**Error Template with Severity:**
```
[RAY GATE FAILED: {Gate Name}] [CRITICAL]
"Quality gate '{Gate Name}' failed for pre-deployment staging.
Context: {Context description}
Resolution: {Resolution steps}
Impact: Blocks handoff until resolved"
```

**Error Template with Context:**
```
[RAY VALIDATION ERROR: {Validation Type}] [WARNING]
"Pre-deployment validation warning detected: {warning message}
Context: {Context details}
Resolution: {Resolution steps}
Impact: May affect quality; review recommended before handoff"
```

**Error Template with Resolution:**
```
[RAY SCRIPT ERROR: {Script Name}] [INFO]
"Pre-deployment script execution completed with minor issues: {info message}
Context: {Context info}
Resolution: {Resolution action}
Impact: Minor; {automatic fix description}"
```

<!-- [Category: GUIDELINES-FORMATS - Automation Standards] -->
## 8. AUTOMATION HOOKS

### 8.1 Registry Reference
**[GUIDELINE]** See `scripts/script-registry.json` for complete script inventory, ownership, and governance context.

### 8.2 Validation Scripts
**[MUST]** Execute automation scripts in sequence:

```bash
# Prerequisite validation
python scripts/validate_prerequisites_10.py

# Quality gate automation
python scripts/validate_gate_10_intake.py --drift-threshold low
python scripts/validate_gate_10_readiness.py --threshold 0.95
python scripts/validate_gate_10_rehearsal.py --report .artifacts/pre-deployment/rehearsal-report.json
python scripts/validate_gate_10_security.py --threshold 0.95

# Evidence aggregation
python scripts/aggregate_evidence_10.py --output .artifacts/pre-deployment/
```

### 8.3 CI/CD Integration
**[GUIDELINE]** Pipeline configuration template:

```yaml
# GitHub Actions workflow integration
name: Protocol 21 Validation
on: [push]
jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Run Protocol 21 Gates
        run: python scripts/run_protocol_10_gates.py
```

### 8.4 Manual Fallbacks
**[GUIDELINE]** When automation is unavailable, execute manual validation:

1. Review staging parity via infrastructure dashboards and log results
2. Manually confirm deployment rehearsal steps using runbooks
3. Document results in `.artifacts/protocol-21/manual-validation-log.md`

<!-- [Category: EXECUTION-BASIC - Validation Checklist] -->
## 9. HANDOFF CHECKLIST

### 9.1 Continuous Improvement Validation
**[MUST]** Verify improvement tracking:

- [x] Execution feedback collected and logged
- [x] Lessons learned documented in protocol artifacts
- [x] Quality metrics captured for improvement tracking
- [x] Knowledge base updated with new patterns or insights
- [x] Protocol adaptation opportunities identified and logged
- [x] Retrospective scheduled (if required for this protocol phase)

### 9.2 Pre-Handoff Validation
**[MUST]** Before declaring protocol complete, validate:

- [x] All prerequisites were met
- [x] All workflow steps completed successfully
- [x] All quality gates passed (or waivers documented)
- [x] All evidence artifacts captured and stored
- [x] All integration outputs generated
- [x] All automation hooks executed successfully
- [x] Communication log complete

**Stakeholder Sign-Off:**
- **Approvals Required:** Pre-deployment readiness approval from Release Manager and stakeholders before proceeding to Protocol 15
- **Reviewers:** Release Manager reviews readiness package completeness and deployment readiness alignment
- **Sign-Off Evidence:** Readiness approval documented in `.artifacts/protocol-14/readiness-approval.json`, reviewer sign-off in `.artifacts/protocol-14/reviewer-signoff.json`
- **Confirmation Required:** Explicit confirmation that pre-deployment validation is complete and Protocol 15 prerequisites satisfied

**Documentation Requirements:**
- **Document Format:** All artifacts in Markdown (`.md`) or JSON (`.json`) format
- **Storage Location:** All documentation stored in `.artifacts/protocol-14/` directory
- **Reviewer Documentation:** Reviewers document approval/rejection rationale in `.artifacts/protocol-14/reviewer-signoff.json`
- **Evidence Manifest:** Complete manifest file at `.artifacts/protocol-14/evidence-manifest.json` with all artifact checksums
- **Documentation Types:** All documentation includes logs, briefs, notes, transcripts, manifests, and reports as required

**Ready-for-Next-Protocol Statement:**
âœ… **Protocol 14 COMPLETE - Ready for Protocol 15**

All pre-deployment staging artifacts validated, approvals obtained, and Protocol 15 prerequisites satisfied. Protocol 15 (Production Deployment & Release Management) can now proceed.

**Next Protocol Command:**
```bash
# Run Protocol 15: Production Deployment & Release Management
@apply .cursor/ai-driven-workflow/15-production-deployment.md
# Or trigger validation: python3 validators-system/scripts/validate_all_protocols.py --protocol 15 --workspace .
```

**Continuation Instructions:**
After Protocol 14 completion, run Protocol 15 continuation script to proceed. Generate session continuation for Protocol 15 workflow execution. Ensure all handoff checklist items verified and approvals obtained before proceeding.

**Dependencies Satisfied:**
- âœ… Pre-deployment validation complete and validated
- âœ… Evidence bundle complete
- âœ… Quality gates passed
- âœ… Stakeholder sign-off obtained

### 9.3 Handoff to Protocol 15
**[MASTER RAYâ„¢ | PROTOCOL COMPLETE]** Ready for Protocol 15: Production Deployment & Release Management

**Evidence Package:**
- `PRE-DEPLOYMENT-PACKAGE.zip` - Comprehensive readiness evidence
- `readiness-approval.json` - Stakeholder go/no-go decision record

**Execution:**
```bash
# Trigger next protocol
@apply .cursor/ai-driven-workflow/15-production-deployment.md
```

<!-- [Category: GUIDELINES-FORMATS - Documentation Standards] -->
## 10. EVIDENCE SUMMARY

### Artifact Generation Table

| Artifact Name | Metrics | Location | Evidence Link |
|---------------|---------|----------|---------------|
| intake-validation artifact (`intake-validation-report.json`) | Completeness score â‰¥100%, drift metric â‰¤0.05, approval coverage metric recorded | `.artifacts/protocol-14/intake-validation-report.json` | Gate 1 intake confirmation |
| staging-parity artifact (`staging-parity-report.json`) | Parity score metric â‰¥0.95, configuration metric logged | `.artifacts/protocol-14/staging-parity-report.json` | Gate 1 parity validation |
| deployment-run artifact (`staging-deployment-run.log`) | Success rate metric â‰¥100%, error count metric =0 | `.artifacts/protocol-14/staging-deployment-run.log` | Gate 2 rehearsal evidence |
| test-results artifact (`staging-test-results.json`) | Coverage metric â‰¥0.90, pass rate metric documented | `.artifacts/protocol-14/staging-test-results.json` | Gate 2 test validation |
| rollback-verification artifact (`rollback-verification-report.json`) | RTO metric â‰¤target, completion time metric logged | `.artifacts/protocol-14/rollback-verification-report.json` | Gate 3 rollback evidence |
| security-compliance artifact (`security-compliance-report.json`) | Security severity metric â‰¤Medium, finding count metric =0 blockers | `.artifacts/protocol-14/security-compliance-report.json` | Gate 3 security evidence |
| readiness-manifest artifact (`pre-deployment-manifest.json`) | Completeness metric â‰¥0.95, item count metric tracked | `.artifacts/protocol-14/pre-deployment-manifest.json` | Gate 4 readiness package |
| readiness-approval artifact (`readiness-approval.json`) | Approval coverage metric â‰¥100%, latency metric <48h | `.artifacts/protocol-14/readiness-approval.json` | Gate 4 approval evidence |
| deployment-checklist artifact (`deployment-checklist.md`) | Checklist coverage metric â‰¥100%, completion metric logged | `.artifacts/protocol-14/deployment-checklist.md` | Gate 4 checklist evidence |
| readiness-package artifact (`PRE-DEPLOYMENT-PACKAGE.zip`) | Bundle size metric, checksum metric verified | `.artifacts/protocol-14/PRE-DEPLOYMENT-PACKAGE.zip` | Gate 4 distribution package |

### Storage Structure

**Protocol Directory:** `.artifacts/protocol-14/`  
- **Subdirectories:** `staging-logs/` for deployment runs, `security-scans/` for compliance reports, `approvals/` for readiness sign-offs.  
- **Permissions:** Read/write for protocol executor and Release Manager, read-only for downstream protocols (15, 16, 20).  
- **Naming Convention:** `{artifact-name}.{extension}` (e.g., `staging-parity-report.json`, `deployment-checklist.md`).

### Manifest Completeness

**Manifest File:** `.artifacts/protocol-14/evidence-manifest.json`

**Metadata Requirements:**
- Timestamp: ISO 8601 format (e.g., `2025-11-06T05:34:29Z`).  
- Artifact checksums: SHA-256 hash recorded for every artifact and validation report.  
- Size: File size in bytes captured in manifest integrity block.  
- Dependencies: Upstream protocols (13, 12) and downstream consumers (15, 16, 20) documented.

**Dependency Tracking:**
- Input: Protocol 13 `uat-signoff.json`, Protocol 12 `audit-report.json`, staging environment config files.  
- Output: All artifacts listed above plus gate validation reports and readiness bundle.  
- Transformations: Intake validation â†’ Deployment rehearsal â†’ Rollback/security validation â†’ Readiness packaging.

**Coverage:** Manifest documents 100% of required artifacts, automation logs, and approval records with checksum verification.

### Traceability

**Input Sources:**
- **Input From:** Protocol 13 `.artifacts/protocol-13/uat-signoff.json` â€“ UAT approval baseline for staging readiness.  
- **Input From:** Protocol 12 `.artifacts/protocol-12/audit-report.json` â€“ Quality audit evidence feeding into deployment validation.  
- **Input From:** Staging environment `config/staging-env.yaml` â€“ Configuration baseline for parity checks.

**Output Artifacts:**
- **Output To:** `pre-deployment-manifest.json` â€“ Consumed by Protocol 15 for production deployment initiation.  
- **Output To:** `rollback-verification-report.json` â€“ Rollback readiness evidence for Protocol 17 (Incident Response).  
- **Output To:** `security-compliance-report.json` â€“ Security baseline for Protocol 16 (Monitoring & Observability).  
- **Output To:** `PRE-DEPLOYMENT-PACKAGE.zip` â€“ Distribution bundle for Release Manager and Protocol 15 team.  
- **Output To:** `evidence-manifest.json` â€“ Audit ledger for governance and compliance reviews.

**Transformation Steps:**
1. Intake validation â†’ intake-validation-report.json and staging-parity-report.json: Validate upstream readiness and environment parity.  
2. Deployment rehearsal â†’ staging-deployment-run.log and staging-test-results.json: Execute and validate deployment procedures.  
3. Rollback/security validation â†’ rollback-verification-report.json and security-compliance-report.json: Verify recovery and compliance.  
4. Readiness packaging â†’ pre-deployment-manifest.json, readiness-approval.json, deployment-checklist.md: Compile go/no-go package.  
5. Bundle creation â†’ PRE-DEPLOYMENT-PACKAGE.zip and evidence-manifest.json: Archive all evidence with checksums.

**Audit Trail:**
- Manifest stores timestamps, checksums, and validator identities for each artifact.  
- Approval records retain signature timestamps and approver details.  
- Deployment logs preserve execution traces and error diagnostics.  
- Security scan reports maintain finding severity and remediation status.

### Archival Strategy

**Compression:**
- Pre-deployment artifacts compressed into `.artifacts/protocol-14/PRE-DEPLOYMENT-PACKAGE.zip` after Gate 4 approval using ZIP standard compression.

**Retention Policy:**
- Active artifacts retained for 90 days post-deployment to support rollback scenarios.  
- Archived bundles retained for 3 years after project closure per ISO 27001 requirements.  
- Cleanup automation `scripts/cleanup_artifacts.py` enforces retention quarterly.

**Retrieval Procedures:**
- Active artifacts accessed directly from `.artifacts/protocol-14/` with read-only permissions.  
- Archived bundles retrieved via `unzip .artifacts/protocol-14/PRE-DEPLOYMENT-PACKAGE.zip` with manifest checksum verification.  
- Emergency recovery playbook stored in `staging-logs/recovery-procedures.md` for incident scenarios.

**Cleanup Process:**
- Quarterly cleanup logs actions to `.artifacts/protocol-14/cleanup-log.json` with artifact inventory snapshot.  
- Critical deployment artifacts flagged for extended retention require Release Manager approval.  
- Manual retention overrides documented with timestamp, approver identity, and business justification.

<!-- [Category: META-FORMATS - Protocol Analysis] -->
## 11. REASONING & COGNITIVE PROCESS

### 11.1 Reasoning Patterns

**Primary Reasoning Pattern: Systematic Execution**
- Execute protocol steps sequentially with validation at each checkpoint

**Secondary Reasoning Pattern: Quality-Driven Validation**
- Apply quality gates to ensure artifact completeness before downstream handoff

**Pattern Improvement Strategy:**
- Track pattern effectiveness via quality gate pass rates and downstream protocol feedback
- Quarterly review identifies pattern weaknesses and optimization opportunities
- Iterate patterns based on empirical evidence from completed executions

### 11.2 Decision Logic

#### Decision Point 1: Execution Readiness
**Context:** Determining if prerequisites are met to begin protocol execution

**Decision Criteria:**
- All prerequisite artifacts present
- Required approvals obtained
- System state validated

**Outcomes:**
- Proceed: Execute protocol workflow
- Halt: Document missing prerequisites, notify stakeholders

**Logging:** Record decision and prerequisites status in execution log

### 11.3 Root Cause Analysis Framework

When protocol execution encounters blockers or quality gate failures:

1. **Identify Symptom:** What immediate issue prevented progress?
2. **Trace to Root Cause:**
   - Was prerequisite artifact missing or incomplete?
   - Did upstream protocol deliver inadequate inputs?
   - Were instructions ambiguous or insufficient?
   - Did environmental conditions fail?
3. **Document in Protocol Execution Log:**
   ```markdown
   **Blocker:** [Description]
   **Root Cause:** [Analysis]
   **Resolution:** [Action taken]
   **Prevention:** [Process/template update to prevent recurrence]
   ```
4. **Implement Fix:** Update protocol, re-engage stakeholders, adjust execution
5. **Validate Fix:** Re-run quality gates, confirm resolution

### 11.4 Learning Mechanisms

#### Feedback Loops
**Purpose:** Establish continuous feedback collection to inform protocol improvements.

- **Execution feedback:** Collect outcome data after each protocol execution
- **Quality gate outcomes:** Track gate pass/fail patterns in historical logs
- **Downstream protocol feedback:** Capture issues reported by dependent protocols
- **Continuous monitoring:** Automated alerts for anomalies and degradation

#### Improvement Tracking
**Purpose:** Systematically track protocol effectiveness improvements over time.

- **Metrics tracking:** Monitor key performance indicators in quarterly dashboards
- **Template evolution:** Log all protocol template changes with rationale and impact
- **Effectiveness measurement:** Compare before/after metrics for each improvement
- **Continuous monitoring:** Automated alerts when metrics degrade

#### Knowledge Base Integration
**Purpose:** Build and leverage institutional knowledge to accelerate protocol quality.

- **Pattern library:** Maintain repository of successful execution patterns
- **Best practices:** Document proven approaches for common scenarios
- **Common blockers:** Catalog typical issues with proven resolutions
- **Industry templates:** Specialized variations for specific domains

#### Adaptation Mechanisms
**Purpose:** Enable protocol to automatically adjust based on context and patterns.

- **Context adaptation:** Adjust execution based on project type, complexity, constraints
- **Threshold tuning:** Modify quality gate thresholds based on risk tolerance
- **Workflow optimization:** Streamline steps based on historical efficiency data
- **Tool selection:** Choose optimal automation based on available resources

### 11.5 Meta-Cognition

#### Self-Awareness and Process Awareness
**Purpose:** Enable AI to maintain explicit awareness of execution state and limitations.

**Awareness Statement Protocol:**
At each major execution checkpoint, generate awareness statement:
- Current phase and step status
- Artifacts completed vs. pending
- Identified blockers and their severity
- Confidence level in current outputs
- Known limitations and assumptions
- Required inputs for next steps

#### Process Monitoring and Progress Tracking
**Purpose:** Continuously track execution status and detect anomalies.

- **Progress tracking:** Update execution status after each step
- **Velocity monitoring:** Flag execution delays beyond expected duration
- **Quality monitoring:** Track gate pass rates and artifact completeness
- **Anomaly detection:** Alert on unexpected patterns or deviations

#### Self-Correction Protocols
**Purpose:** Enable autonomous detection and correction of execution issues.

- **Halt condition detection:** Recognize blockers and escalate appropriately
- **Quality gate failure handling:** Generate corrective action plans
- **Anomaly response:** Diagnose and propose fixes for unexpected conditions
- **Recovery procedures:** Maintain execution state for graceful resume

#### Continuous Improvement Integration
**Purpose:** Systematically capture lessons and evolve protocol effectiveness.

- **Retrospective execution:** Conduct after-action reviews post-completion
- **Template review cadence:** Scheduled protocol enhancement cycles
- **Gate calibration:** Periodic adjustment of pass criteria
- **Tool evaluation:** Assessment of automation effectiveness

## SCRIPTS & AUTOMATION

### Automation Scripts Referenced
| Script Name | Purpose | Location | Status |
|-------------|---------|----------|--------|
| `gate_utils.py` | Gate Utils | `scripts/` | âœ… Exists |
| `validate_gate_10_security.py` | Validate Gate 10 Security | `scripts/` | âœ… Exists |
| `validate_gate_10_readiness.py` | Validate Gate 10 Readiness | `scripts/` | âœ… Exists |
| `validate_gate_10_intake.py` | Validate Gate 10 Intake | `scripts/` | âœ… Exists |
| `run_protocol_gates.py` | Run Protocol Gates | `scripts/` | âœ… Exists |
| `validate_gate_10_rehearsal.py` | Validate Gate 10 Rehearsal | `scripts/` | âœ… Exists |

### Script Dependencies
- **Input:** Required artifacts from previous protocol
- **Output:** Protocol artifacts and validation reports
- **External Dependencies:** Python 3.8+, standard libraries

### Automation Hooks
- **Pre-execution:** Load context from previous protocol
- **During execution:** Validate protocol execution
- **Post-execution:** Generate evidence bundle

### Script Maintenance
- Scripts reviewed and tested: 2025-11-06
- Last execution: 2025-11-06
- Known issues: None

----------------|---------|----------|--------|
| `validate_gate_14_*.py` | Gate validation | `scripts/` | âœ… Exists |
| `verify_protocol_14.py` | Protocol verification | `scripts/` | âœ… Exists |
| `generate_artifacts_14.py` | Artifact generation | `scripts/` | âœ… Exists |
| `aggregate_evidence_14.py` | Evidence aggregation | `scripts/` | âœ… Exists |

### Script Dependencies
- **Input:** Required artifacts from previous protocol
- **Output:** Protocol artifacts and validation reports
- **External Dependencies:** Python 3.8+, standard libraries

### Automation Hooks
- **Pre-execution:** Load context from previous protocol
- **During execution:** Validate protocol execution
- **Post-execution:** Generate evidence bundle

### Script Maintenance
- Scripts reviewed and tested: 2025-11-06
- Last execution: 2025-11-06
- Known issues: None

---

## WORKFLOW ORCHESTRATION

### STEP 1

**Action:** Initialize protocol execution

**Description:** Setup environment and load prerequisites

Communication: Notify stakeholders of protocol start

Evidence: Track initialization in `.artifacts/protocol-14/workflow-logs/`

**Duration:** 15 minutes

---

### STEP 2

**Action:** Execute main protocol activities

**Description:** Perform core protocol tasks and validations

Communication: Document progress and any blockers

Evidence: Store artifacts in `.artifacts/protocol-14/`

**Duration:** Varies based on complexity

---

### STEP 3

**Action:** Validate and package results

**Description:** Run validation scripts and prepare handoff

Communication: Report completion status to stakeholders

Evidence: Generate validation report and evidence manifest

**Duration:** 20 minutes

---

### Workflow Dependencies

- **Sequential:** STEP 1 â†’ STEP 2 â†’ STEP 3 (must complete in order)
- **Parallel:** None (all steps sequential)
- **Conditional:** Halt if validation fails, escalate to supervisor

### Workflow State Management

- State stored in: `.artifacts/protocol-14/workflow-state.json`
- Checkpoint validation at each step boundary
- Rollback procedure if step fails: Return to previous step and remediate

### Workflow Monitoring

- Real-time status: `.artifacts/protocol-14/workflow-status.json`
- Execution logs: `.artifacts/protocol-14/workflow-logs/`
- Performance metrics: `.artifacts/protocol-14/workflow-metrics.json`

---

## AUTOMATION HOOKS

### Pre-Execution Setup

**Environment Variables:**
- `PROTOCOL_ID=14` - Protocol identifier
- `WORKSPACE_ROOT=.` - Root workspace directory
- `ARTIFACTS_DIR=.artifacts/protocol-14/` - Artifacts storage location
- `LOG_LEVEL=INFO` - Logging verbosity (DEBUG, INFO, WARNING, ERROR)

**Required Permissions:**
- Read access to: `.cursor/ai-driven-workflow/14-*.md`, `.artifacts/`
- Write access to: `.artifacts/protocol-14/`, `scripts/logs/`
- Execute access to: `scripts/validate_*.py`, `scripts/aggregate_*.py`

**System Dependencies:**
- Python 3.8+
- bash/sh shell
- Standard Unix utilities (grep, sed, awk)

### Automation Commands

#### Command 1: Pre-Execution Validation
```bash
python3 scripts/validate_prerequisites_14.py \
  --protocol 14 \
  --workspace . \
  --strict
```
**Flags:**
- `--protocol 14` - Protocol ID to validate
- `--workspace .` - Workspace root directory
- `--strict` - Enforce strict validation

**Output:** `.artifacts/protocol-14/prerequisites-validation.json`
**Exit Codes:** 0=success, 1=validation failed, 2=prerequisites missing

#### Command 2: Protocol Execution
```bash
python3 scripts/run_protocol_gates.py \
  --protocol 14 \
  --input .artifacts/protocol-14/input/ \
  --output .artifacts/protocol-14/output/ \
  --log-file .artifacts/protocol-14/execution.log \
  --error-handling retry
```
**Flags:**
- `--protocol 14` - Protocol ID
- `--input DIR` - Input artifacts directory
- `--output DIR` - Output artifacts directory
- `--log-file FILE` - Execution log file path
- `--error-handling {retry|escalate|halt}` - Error handling strategy

**Output:** `.artifacts/protocol-14/output/`
**Exit Codes:** 0=success, 1=execution error, 2=validation gate failed

#### Command 3: Evidence Aggregation
```bash
python3 scripts/aggregate_evidence_14.py \
  --protocol 14 \
  --artifacts-dir .artifacts/protocol-14/ \
  --output-manifest \
  --checksum sha256
```
**Flags:**
- `--protocol 14` - Protocol ID
- `--artifacts-dir DIR` - Artifacts directory
- `--output-manifest` - Generate manifest file
- `--checksum {md5|sha256}` - Checksum algorithm

**Output:** `.artifacts/protocol-14/EVIDENCE-MANIFEST.json`
**Exit Codes:** 0=success, 1=aggregation failed

#### Command 4: Post-Execution Validation
```bash
python3 scripts/validate_protocol_14.py \
  --protocol 14 \
  --artifacts-dir .artifacts/protocol-14/ \
  --quality-gates strict \
  --report json
```
**Flags:**
- `--protocol 14` - Protocol ID
- `--artifacts-dir DIR` - Artifacts directory
- `--quality-gates {strict|standard|relaxed}` - Gate strictness
- `--report {json|html|text}` - Report format

**Output:** `.artifacts/protocol-14/validation-report.json`
**Exit Codes:** 0=all gates pass, 1=gate failure, 2=critical error

### Error Handling & Fallback Procedures

**If Command 1 (Prerequisites) Fails:**
1. Check log: `.artifacts/protocol-14/prerequisites-validation.json`
2. Verify all input artifacts exist
3. Ensure all environment variables are set
4. **Fallback:** Run with `--strict=false`
5. **Escalate:** Notify Protocol Owner if still failing

**If Command 2 (Execution) Fails:**
1. Check log: `.artifacts/protocol-14/execution.log`
2. Review error code and message
3. **Retry:** Re-run with `--error-handling retry` (up to 3 times)
4. **Fallback:** Run with `--error-handling escalate`
5. **Escalate:** Notify supervisor with logs

**If Command 3 (Aggregation) Fails:**
1. Verify all artifacts present in output directory
2. Check artifact file formats and integrity
3. **Fallback:** Run without `--output-manifest`
4. **Escalate:** If artifacts corrupted, restart from Command 2

**If Command 4 (Validation) Fails:**
1. Review validation report
2. Identify which quality gates failed
3. **Fallback:** Run with `--quality-gates relaxed`
4. **Escalate:** Return to Command 2 and remediate

### Scheduling & Execution Context

**Execution Timing:**
- Pre-execution: 5 minutes (setup + prerequisites validation)
- Main execution: 15-45 minutes (depends on protocol complexity)
- Post-execution: 10 minutes (aggregation + validation)
- Total: 30-60 minutes per protocol

**Parallel Execution:** Can run up to 4 protocols in parallel (if resources allow)

**CI/CD Integration:**
- Trigger on: Protocol file changes, manual trigger
- Timeout: 90 minutes per protocol
- Retry policy: 2 retries on transient failures
- Notification: Slack/Email on success/failure

### Monitoring & Logging

**Log Files:**
- `.artifacts/protocol-14/execution.log` - Main execution log
- `.artifacts/protocol-14/validation.log` - Validation log
- `.artifacts/protocol-14/error.log` - Error log (if any)

**Status Files:**
- `.artifacts/protocol-14/workflow-status.json` - Real-time status
- `.artifacts/protocol-14/workflow-metrics.json` - Performance metrics

**Checkpoints:**
- After prerequisites validation
- After each command execution
- Before handoff to next protocol

### Success Criteria

âœ… All commands execute successfully (exit code 0)
âœ… All quality gates pass (validation report shows PASS)
âœ… Evidence manifest generated and checksums verified
âœ… All artifacts stored in `.artifacts/protocol-14/`
âœ… No errors in execution, validation, or aggregation logs
âœ… Protocol ready for handoff to next protocol

---
## HANDOFF CHECKLIST

### Pre-Handoff Validation
- [ ] All artifacts generated and stored in `.artifacts/protocol-14/`
- [ ] Evidence manifest complete with checksums
- [ ] Quality gates passed (all gates show PASS status)
- [ ] Downstream protocol owner notified and ready
- [ ] No blocking issues or waivers pending

### Handoff Package Contents
- **Evidence Bundle:** `PROTOCOL-14-EVIDENCE.zip` containing:
  - All gate validation reports
  - Artifact inventory and manifest
  - Traceability matrix
  - Archival strategy documentation
- **Readiness Attestation:** Signed-off by protocol owner
- **Next Protocol Brief:** Clear handoff to Protocol 15

### Handoff Verification
- [ ] Checksum verification passed
- [ ] Downstream protocol has received package
- [ ] Downstream protocol confirms receipt and readiness
- [ ] No outstanding questions or clarifications needed

### Sign-Off
- Protocol Owner: _________________ Date: _________
- Downstream Owner: _________________ Date: _________

---
## COMMUNICATION & STAKEHOLDER ALIGNMENT

### Status Announcements (Template)
```
[PROTOCOL 14 | PHASE X START] - [Action description]
[PROTOCOL 14 | PHASE X COMPLETE] - [Outcome with evidence reference]
[PROTOCOL 14 ERROR] - [Error type and resolution]
```

### Stakeholder Notifications
- **Primary Stakeholder:** Release Manager - Notification method: [Email/Slack/Meeting]
- **Secondary Stakeholders:** DevOps Team, QA Team, Technical Lead - Notification method
- **Escalation Path:** [Define who to notify if issues arise]

### Feedback Collection
- Collect feedback from downstream protocol owners
- Document any concerns or improvement suggestions
- Log feedback in `.artifacts/protocol-14/feedback-log.json`

### Communication Cadence
- Daily status updates during execution
- Weekly summary reports to leadership
- Post-completion retrospective with stakeholders

---