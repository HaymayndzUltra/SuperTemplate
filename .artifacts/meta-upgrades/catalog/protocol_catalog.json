{
  "protocols": [
    {
      "protocol_id": "P01",
      "file": ".cursor/ai-driven-workflow/01-client-proposal-generation.md",
      "title": "# PROTOCOL 01: CLIENT PROPOSAL GENERATION",
      "purpose_line": "**What this does:** Turn job posts into winning proposals that get you hired.",
      "objectives": "Write a proposal that:\n- \u2705 Shows you read and understood their job post\n- \u2705 Proves you can do the work (with real examples)\n- \u2705 Sounds human, not like a template\n- \u2705 Gets read in 60 seconds (clients skim, not read)\n\n**\ud83d\udeab RULE: Only mention experience you actually have. Don't lie.**\n\n---",
      "prerequisites": "",
      "inputs": "",
      "outputs": "",
      "workflow": "",
      "quality_gates": "### Standards We Follow\n- **Markdown**: CommonMark v0.30 (standard formatting)\n- **JSON**: draft-07 schema (for validation)\n- **Security**: HIPAA-compliant (if handling client data)\n- **Legal**: FTC truth-in-advertising (don't lie in proposals)\n\n### Check 1: Did We Extract Everything from Job Post?\n- **What to check**: Did `jobpost-analysis.json` capture all the important stuff?\n  - Goals/objectives\n  - What they want delivered\n  - How they communicate\n  - Risks/problems\n- **Pass if**: Analysis is 90%+ complete\n- **If it fails**: Ask client for missing info, run analysis again, note the gap\n- **Run**: `python3 scripts/analyze_jobpost.py --input JOB-POST.md --output .artifacts/protocol-01/jobpost-analysis.json`\n\n### Check 2: Are We Confident About Their Tone?\n- **What to check**: Did we correctly detect how they communicate?\n- **Pass if**: Confidence score \u2265 80% and we picked a strategy\n- **If it fails**: Manually review the job post, update tone map, run check again\n- **Run**: `python3 scripts/tone_mapper.py --input .artifacts/protocol-01/jobpost-analysis.json --output .artifacts/protocol-01/tone-map.json`\n\n### Check 3: Is the Proposal Complete?\n- **What to check**: Does `PROPOSAL.md` have all required sections?\n  - Each section has \u2265 120 words\n  - Sounds human (empathy tokens logged)\n- **Pass if**: Structure score \u2265 95%\n- **If it fails**: Fill in missing sections, make it sound more human, check again\n- **Run**: `python3 scripts/validate_proposal_structure.py --input .artifacts/protocol-01/PROPOSAL.md`\n\n### Check 3.5: Is the Pricing Realistic?\n- **What to check**: Is your pricing based on real work hours and market rates?\n- **Pass if**:\n  - Hourly rate \u2264 $400 for solo work\n  - Hourly rate \u2264 $600 for team work\n  - Total price is 80-120% of market rate\n  - Pricing matches your actual skill level\n- **If it fails**: Recalculate based on realistic hours/week, adjust scope, or explain why you're charging premium\n- **Run**: `python3 scripts/validate_pricing.py --input .artifacts/protocol-01/pricing-analysis.json --proposal .artifacts/protocol-01/PROPOSAL.md`\n- **How it works**:\n  ```python\n  # Calculate effective hourly rate\n  effective_rate = total_price / (weeks * 40)\n  \n  # Flag if unrealistic\n  if effective_rate > 400 and engagement_type == \"solo\":\n      raise ValidationError(\"Hourly rate exceeds $400 for solo work\")\n  \n  # Warn if job post budget seems inflated\n  if job_post_budget > (calculated_price * 2):\n      warn(\"Job post budget may be inflated - use calculated price\")\n  ```\n\n### Gate 4: Real Compliance Validation\n- **Criteria**: HIPAA compliance check passes, quality gates enforce real thresholds.\n- **Evidence**: `.artifacts/protocol-01/compliance-validation-report.json`\n- **Pass Threshold**: All compliance checks pass (exit code 0).\n- **Failure Handling**: Address compliance issues, fix PHI violations, update security configurations.\n- **Automation**: `python3 scripts/check_hipaa.py && python3 scripts/enforce_gates.py`\n\n### Gate 5: Final Validation & Approval Readiness\n- **Criteria**: Readability \u2265 90, zero factual discrepancies, empathy coverage \u2265 3 tokens, real validation passed.\n- **Evidence**: `.artifacts/protocol-01/proposal-validation-report.json`\n- **Pass Threshold**: Validation script returns status `pass` and all real gates pass.\n- **Failure Handling**: Address flagged items, capture remediation notes, rerun validation.\n- **Automation**: `python3 scripts/validate_proposal.py --input .artifacts/protocol-01/PROPOSAL.md --report .artifacts/protocol-01/proposal-validation-report.json`\n\n---",
      "known_invariants": "**\ud83d\udeab RULE: Only mention experience you actually have. Don't lie.**",
      "dependencies": [],
      "handoffs": []
    },
    {
      "protocol_id": "P02",
      "file": ".cursor/ai-driven-workflow/02-client-discovery-initiation.md",
      "title": "# PROTOCOL 02: CLIENT DISCOVERY INITIATION (PROJECT-SCOPING COMPLIANT)",
      "purpose_line": "**Purpose:** Orchestrate structured client discovery to validate scope, requirements, and expectations, producing authoritative artifacts for project brief creation. This protocol transforms proposal acceptance into actionable project definition through systematic requirements gathering, risk assessment, and stakeholder alignment.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `PROPOSAL.md` from Protocol 01 (accepted proposal content)\n- [ ] `proposal-summary.json` from Protocol 01 (proposal highlights)\n- [ ] Client response transcript or email saved to `.artifacts/protocol-02/client-reply.md`\n\n### Required Approvals\n- [ ] Business development lead approval to initiate structured discovery\n\n### System State Requirements\n- [ ] Scheduled communication channel established with client (email, call, or chat)\n- [ ] Access to discovery templates within `.templates/discovery/`\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Context Alignment\n\n1. **`[MUST]` Review Proposal and Client Response:**\n   * **Action:** Synthesize proposal highlights and client feedback to identify priorities, tone, and unresolved questions; log results in `client-context-notes.md`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Reviewing accepted proposal and client reply to align objectives.\"\n   * **Halt condition:** Stop if the client response is missing or ambiguous; request clarification.\n   * **Evidence:** `.artifacts/protocol-02/client-context-notes.md`\n\n2. **`[GUIDELINE]` Capture Business Background:**\n   * **Action:** Draft a one-paragraph summary of the client's business model, target users, and success metrics using public info or provided material.\n   * **Example:**\n     ```markdown\n     **Business Snapshot**\n     - Industry: HealthTech SaaS\n     - Primary Users: Clinic administrators\n     - Success Metric: Reduce patient intake time by 30%\n     ```\n\n### STEP 2: Requirement Deep Dive\n\n1. **`[MUST]` Facilitate Feature Prioritization:**\n   * **Action:** Guide the client through identifying mandatory MVP features versus optional backlog items; capture in `client-discovery-form.md`.\n   * **Communication:** \n     > \"[PHASE 2] - Confirming core features and optional roadmap items.\"\n   * **Halt condition:** Pause if feature classifications are incomplete or conflicting.\n   * **Evidence:** `.artifacts/protocol-02/client-discovery-form.md`\n\n2. **`[MUST]` Validate Technical and Integration Requirements:**\n   * **Action:** Document stack preferences, compliance needs, integrations, and constraints in `scope-clarification.md`.\n   * **Communication:** \n     > \"[PHASE 2] - Documenting technology preferences, integrations, and compliance constraints.\"\n   * **Evidence:** `.artifacts/protocol-02/scope-clarification.md`\n\n3. **`[GUIDELINE]` Capture Risks and Assumptions:**\n   * **Action:** Note known risks, assumptions, and open questions for resolution in `risk-log.md`.\n   * **Example:**\n     ```markdown\n     - Assumption: Client provides existing API documentation\n     - Risk: Third-party auth provider contract pending renewal\n     ```\n\n### STEP 3: Delivery Framework Alignment\n\n1. **`[MUST]` Confirm Timeline, Budget, and Milestones:**\n   * **Action:** Establish milestone dates, success checkpoints, and budget guardrails; summarize in `timeline-discussion.md`.\n   * **Communication:** \n     > \"[PHASE 3] - Aligning delivery milestones, budget expectations, and decision points.\"\n   * **Halt condition:** Await confirmation if budget or schedule remains unresolved.\n   * **Evidence:** `.artifacts/protocol-02/timeline-discussion.md`\n\n2. **`[MUST]` Establish Collaboration and Communication Plan:**\n   * **Action:** Agree on communication cadence, tools, timezone overlap, and escalation paths; record in `communication-plan.md`.\n   * **Communication:** \n     > \"[PHASE 3] - Finalizing collaboration channels and escalation procedure.\"\n   * **Halt condition:** Pause until both parties confirm the communication plan.\n   * **Evidence:** `.artifacts/protocol-02/communication-plan.md`\n\n3. **`[GUIDELINE]` Define Decision Governance:**\n   * **Action:** Map decision owners, approval thresholds, and change-control expectations in `governance-map.md`.\n   * **Example:**\n     ```markdown\n     | Decision Type | Owner | SLA |\n     |---------------|-------|-----|\n     | Scope Change  | Product Owner | 2 business days |\n     ```\n\n### STEP 4: Discovery Confirmation\n\n1. **`[MUST]` Summarize Discovery Outcomes:**\n   * **Action:** Compile a client-facing recap (`discovery-recap.md`) and send validation prompt to confirm accuracy.\n   * **Communication:** \n     > \"[PHASE 4] - Presenting discovery recap for client confirmation.\"\n   * **Halt condition:** Stop until client explicitly approves the recap or requests updates.\n   * **Evidence:** `.artifacts/protocol-02/discovery-recap.md`\n\n2. **`[GUIDELINE]` Archive Communication Evidence:**\n   * **Action:** Store transcripts, call notes, and recordings in `.artifacts/protocol-02/transcripts/` for audit trail.\n   * **Example:**\n     ```text\n     2024-05-10-discovery-call.txt\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not advance to planning deliverables until every discovery question is answered and validated with the client.**",
      "dependencies": [
        "P01"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P03",
      "file": ".cursor/ai-driven-workflow/03-project-brief-creation.md",
      "title": "# PROTOCOL 03: PROJECT BRIEF CREATION (PROJECT-SCOPING COMPLIANT)",
      "purpose_line": "**Purpose:** Execute PROJECT BRIEF CREATION workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `client-discovery-form.md` from Protocol 02 (validated functional requirements)\n- [ ] `scope-clarification.md` from Protocol 02 (technical constraints)\n- [ ] `communication-plan.md` and `timeline-discussion.md` from Protocol 02 (collaboration expectations)\n- [ ] `PROPOSAL.md` and `proposal-summary.json` from Protocol 01 (accepted commitments)\n\n### Required Approvals\n- [ ] Client confirmation captured in `discovery-recap.md`\n- [ ] Internal solutions architect sign-off that discovery evidence is complete\n\n### System State Requirements\n- [ ] Access to project brief templates under `.templates/briefs/`\n- [ ] Automation scripts `assemble_project_brief.py` and `validate_brief_structure.py` available\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Discovery Validation\n\n1. **`[MUST]` Audit Required Artifacts:**\n   * **Action:** Confirm discovery artifacts exist, contain approved content, and align with accepted proposal commitments; log results in `project-brief-validation-report.json`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Auditing discovery artifacts for completeness and alignment.\"\n   * **Halt condition:** Stop if any artifact is missing, empty, or lacks approval evidence.\n   * **Evidence:** `.artifacts/protocol-03/project-brief-validation-report.json`\n\n2. **`[MUST]` Resolve Inconsistencies:**\n   * **Action:** Cross-check feature lists, constraints, and expectations; record discrepancies in `validation-issues.md` and resolve with stakeholders before proceeding.\n   * **Communication:** \n     > \"Highlighting discovery inconsistencies for resolution before brief assembly.\"\n   * **Evidence:** `.artifacts/protocol-03/validation-issues.md`\n\n3. **`[GUIDELINE]` Capture Context Summary:**\n   * **Action:** Summarize client goals, audience, and success metrics in `context-summary.md` for quick reference.\n   * **Example:**\n     ```markdown\n     **Client Goals**\n     - Reduce onboarding time from 7 days to 2 days\n     - Support 10k MAU within first quarter\n     ```\n\n### STEP 2: Brief Assembly\n\n1. **`[MUST]` Compile Core Sections:**\n   * **Action:** Generate `PROJECT-BRIEF.md` with sections: Executive Summary, Business Objectives, Functional Scope, Technical Architecture Baseline, Delivery Plan, Communication Plan, Risks & Assumptions.\n   * **Communication:** \n     > \"[PHASE 2] - Assembling Project Brief from validated discovery inputs.\"\n   * **Halt condition:** Pause if any section cannot be populated from validated sources.\n   * **Evidence:** `.artifacts/protocol-03/PROJECT-BRIEF.md`\n\n2. **`[MUST]` Embed Traceability Links:**\n   * **Action:** Reference source artifacts using inline footnotes and appendices linking back to discovery evidence.\n   * **Communication:** \n     > \"Embedding traceability to maintain auditability between discovery and brief.\"\n   * **Evidence:** `.artifacts/protocol-03/traceability-map.json`\n\n3. **`[GUIDELINE]` Draft Risk Register:**\n   * **Action:** Populate risk appendix with impact, likelihood, and mitigation strategies derived from discovery notes.\n   * **Example:**\n     ```markdown\n     | Risk | Impact | Likelihood | Mitigation |\n     |------|--------|------------|------------|\n     | Third-party API delay | High | Medium | Add buffer sprint and mock services |\n     ```\n\n### STEP 3: Validation and Approval\n\n1. **`[MUST]` Run Structural Validation:**\n   * **Action:** Execute `validate_brief_structure.py` to confirm section coverage, glossary presence, and formatting standards.\n   * **Communication:** \n     > \"[PHASE 3] - Running automated validation on Project Brief structure and content.\"\n   * **Halt condition:** Stop if validation fails; remediate and rerun.\n   * **Evidence:** `.artifacts/protocol-03/brief-structure-report.json`\n\n2. **`[MUST]` Capture Approval Evidence:**\n   * **Action:** Send approval summary to client and internal lead; log confirmations in `BRIEF-APPROVAL-RECORD.json`.\n   * **Communication:** \n     > \"Awaiting explicit client approval for Project Brief finalization.\"\n   * **Halt condition:** Do not proceed until approvals recorded.\n   * **Evidence:** `.artifacts/protocol-03/BRIEF-APPROVAL-RECORD.json`\n\n3. **`[GUIDELINE]` Prepare Downstream Briefing Deck:**\n   * **Action:** Optional slide deck summarizing key sections for kickoff; save as `project-brief-slides.pptx` if requested.\n   * **Example:**\n     ```markdown\n     Slide 1: Objectives & Success Metrics\n     Slide 2: MVP Scope Overview\n     Slide 3: Timeline & Governance\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not finalize the brief without recorded client approval and reconciliation against discovery scope.**",
      "dependencies": [
        "P01",
        "P02"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P04",
      "file": ".cursor/ai-driven-workflow/04-project-bootstrap-and-context-engineering.md",
      "title": "# PROTOCOL 04: PROJECT BOOTSTRAP AND CONTEXT ENGINEERING (GOVERNANCE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute PROJECT BOOTSTRAP AND CONTEXT ENGINEERING workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `PROJECT-BRIEF.md` from Protocol 03 (validated project summary)\n- [ ] `project-brief-validation-report.json` from Protocol 03 (evidence of alignment)\n- [ ] `BRIEF-APPROVAL-RECORD.json` from Protocol 03 (client/internal approvals)\n\n### Required Approvals\n- [ ] Delivery lead authorization to bootstrap repository\n- [ ] DevOps confirmation that bootstrap environment is isolated from production\n\n### System State Requirements\n- [ ] Access to bootstrap scripts under `scripts/`\n- [ ] Write permissions to `.cursor/` and `.artifacts/` directories\n- [ ] Environment doctor check (`scripts/doctor.py`) returning success\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Brief Intake and Verification\n\n1. **`[MUST]` Validate Project Brief Assets:**\n   * **Action:** Run `python scripts/validate_brief.py --path PROJECT-BRIEF.md --output .artifacts/protocol-04/brief-validation-report.json` to ensure structure and approvals are intact.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Validating Project Brief and approval evidence.\"\n   * **Halt condition:** Stop if validation fails or approvals missing.\n   * **Evidence:** `.artifacts/protocol-04/brief-validation-report.json`\n\n2. **`[MUST]` Generate Bootstrap Plan (Dry Run):**\n   * **Action:** Execute `python scripts/generate_from_brief.py --brief PROJECT-BRIEF.md --dry-run --yes` to preview scaffold operations.\n   * **Communication:** \n     > \"Previewing scaffold generation plan and mapping assets.\"\n   * **Evidence:** `.artifacts/protocol-04/bootstrap-dry-run.log`\n\n3. **`[GUIDELINE]` Extract Technical Signals:**\n   * **Action:** Produce `technical-baseline.json` summarizing stacks, services, and integration dependencies gleaned from the brief.\n   * **Example:**\n     ```json\n     {\n       \"frontend\": \"Next.js\",\n       \"backend\": \"FastAPI\",\n       \"datastore\": \"PostgreSQL\"\n     }\n     ```\n\n### STEP 2: Environment and Governance Preparation\n\n1. **`[MUST]` Run Environment Doctor:**\n   * **Action:** Execute `python scripts/doctor.py --strict` to confirm toolchain readiness; store output in `.artifacts/protocol-04/environment-report.json`.\n   * **Communication:** \n     > \"[PHASE 2] - Validating local environment and dependencies.\"\n   * **Halt condition:** Stop if doctor script reports missing dependencies.\n   * **Evidence:** `.artifacts/protocol-04/environment-report.json`\n\n2. **`[MUST]` Normalize Governance Rules:**\n   * **Action:** Run `python scripts/normalize_project_rules.py --target .cursor/rules/` followed by `python scripts/rules_audit_quick.py --output .artifacts/protocol-04/rule-audit-report.md`.\n   * **Communication:** \n     > \"Normalizing governance rules and auditing metadata integrity.\"\n   * **Evidence:** `.artifacts/protocol-04/rule-audit-report.md`\n\n3. **`[GUIDELINE]` Snapshot Existing Context Kit:**\n   * **Action:** Archive current `.cursor/context-kit/` into `.artifacts/protocol-04/pre-bootstrap-context.zip` for rollback options.\n   * **Example:**\n     ```bash\n     zip -r .artifacts/protocol-04/pre-bootstrap-context.zip .cursor/context-kit/\n     ```\n\n### STEP 3: Scaffold Generation and Verification\n\n1. **`[MUST]` Generate Governed Scaffold:**\n   * **Action:** Run `python scripts/generate_from_brief.py --brief PROJECT-BRIEF.md --output-root . --in-place --no-subdir --no-cursor-assets --force --yes` to materialize scaffold.\n   * **Communication:** \n     > \"[PHASE 3] - Generating governed scaffold artifacts.\"\n   * **Halt condition:** Stop if generator exits with non-zero status.\n   * **Evidence:** `.artifacts/protocol-04/bootstrap-manifest.json`\n\n2. **`[MUST]` Verify Scaffold Integrity:**\n   * **Action:** Execute `python scripts/validate_scaffold.py --manifest .artifacts/protocol-04/bootstrap-manifest.json` to ensure generated assets match registry expectations.\n   * **Communication:** \n     > \"Validating scaffold integrity and template compliance.\"\n   * **Evidence:** `.artifacts/protocol-04/scaffold-validation-report.json`\n\n3. **`[GUIDELINE]` Inspect Generated Structure:**\n   * **Action:** Review directories for completeness, confirm `generator-config.json` accuracy, and document observations in `scaffold-review-notes.md`.\n   * **Example:**\n     ```markdown\n     - \u2705 templates/bootstrap/app/ created\n     - \u2705 generator-config.json includes service mappings\n     - \u26a0\ufe0f Review README auto-generated content with product owner\n     ```\n\n### STEP 4: Context Kit Initialization\n\n1. **`[MUST]` Initialize Evidence Manager:**\n   * **Action:** Run `python scripts/evidence_manager.py init --path .artifacts/protocol-04/` to establish evidence tracking baseline.\n   * **Communication:** \n     > \"[PHASE 4] - Initializing evidence tracking and context kit.\"\n   * **Evidence:** `.artifacts/protocol-04/evidence-manifest.json`\n\n2. **`[MUST]` Validate Workflow Integration:**\n   * **Action:** Execute `python scripts/validate_workflows.py --mode bootstrap --output .artifacts/protocol-04/workflow-validation-report.json`.\n   * **Communication:** \n     > \"Running workflow validation to ensure protocol readiness.\"\n   * **Halt condition:** Stop if validation fails and resolve issues.\n   * **Evidence:** `.artifacts/protocol-04/workflow-validation-report.json`\n\n3. **`[GUIDELINE]` Update Context Kit Documentation:**\n   * **Action:** Document stack summary, governance status, and next steps in `.cursor/context-kit/governance-status.md`.\n   * **Example:**\n     ```markdown\n     ## Bootstrap Summary\n     - Stack: Next.js + FastAPI + PostgreSQL\n     - Governance: Rules normalized 2024-05-10\n     - Next: Protocol 05 legacy alignment\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Never modify existing production application code or delete repository assets outside governed directories.**",
      "dependencies": [
        "P03"
      ],
      "handoffs": [
        "P05"
      ]
    },
    {
      "protocol_id": "P05",
      "file": ".cursor/ai-driven-workflow/05-bootstrap-your-project.md",
      "title": "# PROTOCOL 05: BOOTSTRAP YOUR PROJECT (LEGACY ALIGNMENT COMPLIANT)",
      "purpose_line": "**Purpose:** Execute BOOTSTRAP YOUR PROJECT workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `.cursor/context-kit/governance-status.md` from Protocol 04 (baseline governance summary)\n- [ ] `bootstrap-manifest.json` from Protocol 04 (generated scaffold inventory)\n- [ ] Repository access manifest (list of directories allowed for modification)\n\n### Required Approvals\n- [ ] Product owner approval to proceed with legacy bootstrap alignment\n- [ ] Engineering lead confirmation that Cursor rule governance is required\n\n### System State Requirements\n- [ ] Ability to execute shell commands for rule normalization and template discovery\n- [ ] Read-only access to production code (no write operations permitted)\n- [ ] Cursor editor availability if automation requires `.mdc` rules\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Governance Tooling Activation\n\n1. **`[MUST]` Confirm Tooling Requirements:**\n   * **Action:** Ask whether the team uses Cursor; if yes, prepare `.cursor/rules/` for rule activation.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Confirming editor tooling to activate governance rules.\"\n   * **Halt condition:** Pause until tooling confirmation received.\n   * **Evidence:** `.artifacts/protocol-05/tooling-confirmation.log`\n\n2. **`[MUST]` Configure Cursor Rule Structure:**\n   * **Action:** Locate `master-rules` and `common-rules` directories, move them under `.cursor/rules/`, rename `.md` files to `.mdc`, and ensure YAML frontmatter includes `alwaysApply` metadata.\n   * **Communication:** \n     > \"Migrating master and common rules into Cursor-compatible `.mdc` format.\"\n   * **Evidence:** `.artifacts/protocol-05/rule-migration-report.md`\n\n3. **`[GUIDELINE]` Run Cursor Rule Generation:**\n   * **Action:** If `PROJECT-BRIEF.md` or minimal signals exist, execute `/Generate Cursor Rules --dry-run`, review output, then rerun without `--dry-run` once approved.\n   * **Example:**\n     ```text\n     /Generate Cursor Rules --dry-run\n     ```\n\n### STEP 2: Repository Mapping and Stack Detection\n\n1. **`[MUST]` Map Repository Structure:**\n   * **Action:** Produce a comprehensive tree of the repository, capturing key directories and files for architectural insight.\n   * **Communication:** \n     > \"[PHASE 2] - Mapping repository structure to identify foundational assets.\"\n   * **Halt condition:** Await user validation of proposed key files.\n   * **Evidence:** `.artifacts/protocol-05/repo-structure.txt`\n\n2. **`[MUST]` Validate Analysis Plan:**\n   * **Action:** Present the proposed key files (e.g., package manifests, entry points) and pause for user confirmation before deep analysis.\n   * **Communication:** \n     > \"Proposed analysis targets: `package.json`, `src/main.tsx`, `vite.config.ts`. Confirm or adjust before proceeding.\"\n   * **Evidence:** `.artifacts/protocol-05/analysis-plan.md`\n\n3. **`[MUST]` Capture Stack Signals:**\n   * **Action:** Analyze confirmed files to determine languages, frameworks, and build tooling; store in `.cursor/bootstrap/detected-stack.json`.\n   * **Communication:** \n     > \"Recording detected stack characteristics for context kit seeding.\"\n   * **Evidence:** `.cursor/bootstrap/detected-stack.json`\n\n### STEP 3: Thematic Investigation & Principle Extraction\n\n1. **`[MUST]` Define Investigation Themes:**\n   * **Action:** Generate thematic questions (security, data flow, conventions) tailored to the detected stack.\n   * **Communication:** \n     > \"[PHASE 3] - Establishing thematic investigation plan covering security, data flow, and conventions.\"\n   * **Evidence:** `.artifacts/protocol-05/investigation-themes.md`\n\n2. **`[MUST]` Perform Semantic Deep Dives:**\n   * **Action:** Use approved search tools to examine code implementing each theme; collect supporting snippets.\n   * **Communication:** \n     > \"Executing semantic analysis to uncover architectural principles.\"\n   * **Evidence:** `.artifacts/protocol-05/theme-findings.json`\n\n3. **`[GUIDELINE]` Synthesize Principles:**\n   * **Action:** Translate findings into pragmatic principles and document in `architecture-principles.md`.\n   * **Example:**\n     ```markdown\n     - Authentication relies on HMAC middleware (`src/middleware/validateHmac.ts`).\n     - Error responses standardize `{ success: false, error }` envelope.\n     ```\n\n### STEP 4: Validation Checkpoint and Context Kit Initialization\n\n1. **`[MUST]` Present Consolidated Findings:**\n   * **Action:** Share summary of understanding and outstanding questions; pause for user feedback before automation.\n   * **Communication:** \n     > \"[PHASE 4] - Presenting bootstrap findings for validation prior to context kit generation.\"\n   * **Halt condition:** Wait for user confirmation or corrections.\n   * **Evidence:** `.artifacts/protocol-05/validation-brief.md`\n\n2. **`[MUST]` Initialize Context Kit Structure:**\n   * **Action:** Create `.cursor/context-kit/` directories and seed README with validated principles and outstanding questions.\n   * **Communication:** \n     > \"Initializing context kit directories with validated principles.\"\n   * **Evidence:** `.cursor/context-kit/README.md`\n\n3. **`[GUIDELINE]` Record Manual Validation Log:**\n   * **Action:** Document validation feedback and decisions in `.artifacts/protocol-05/manual-validation-log.md`.\n\n### STEP 5: Documentation and Rule Alignment\n\n1. **`[MUST]` Generate Documentation Plan:**\n   * **Action:** Identify READMEs requiring creation or updates; capture mapping in `documentation-plan.md`.\n   * **Communication:** \n     > \"[PHASE 5] - Planning README updates aligned with validated principles.\"\n   * **Evidence:** `.artifacts/protocol-05/documentation-plan.md`\n\n2. **`[MUST]` Produce or Update READMEs:**\n   * **Action:** Create targeted READMEs capturing architecture, workflows, and conventions; obtain user approval for each.\n   * **Communication:** \n     > \"Publishing README updates; awaiting approval for each document.\"\n   * **Evidence:** `.artifacts/protocol-05/readme-updates/`\n\n3. **`[MUST]` Normalize and Audit Rules:**\n   * **Action:** Run `python scripts/normalize_project_rules.py --target .cursor/rules/` and `python scripts/rules_audit_quick.py --output .artifacts/protocol-05/rule-audit-report.md`; update context kit with audit link.\n   * **Communication:** \n     > \"Normalizing project rules and recording audit evidence.\"\n   * **Evidence:** `.artifacts/protocol-05/rule-audit-report.md`\n\n4. **`[GUIDELINE]` Offer Optional Scaffold Generation:**\n   * **Action:** If `brief.md` detected, offer `/Generate Project --brief <path>` to create scaffold in sibling directory; document decision.\n\n### STEP 6: Project Rule Finalization and Template Discovery\n\n1. **`[MUST]` Generate Rule Updates from READMEs:**\n   * **Action:** Create or update project rules reflecting README guidance; link each rule to its source doc.\n   * **Communication:** \n     > \"[PHASE 6] - Translating documentation into enforceable project rules.\"\n   * **Evidence:** `.cursor/rules/project-rules/*.mdc`\n\n2. **`[MUST]` Validate Rules Post-Update:**\n   * **Action:** Re-run rule audit and capture results in `rule-audit-final.md`; ensure no critical findings.\n   * **Communication:** \n     > \"Revalidating project rules after updates.\"\n   * **Evidence:** `.artifacts/protocol-05/rule-audit-final.md`\n\n3. **`[GUIDELINE]` Inventory Template Packs:**\n   * **Action:** List available template packs using TemplateRegistry and store in `.cursor/context-kit/template-inventory.md`.\n   * **Example:**\n     ```bash\n     python -c \"from project_generator.template_registry import TemplateRegistry; print(TemplateRegistry.list_all())\" \\\n       > .cursor/context-kit/template-inventory.md\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not edit or delete production application files; all modifications must remain within governed directories.**",
      "dependencies": [
        "P04"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P06",
      "file": ".cursor/ai-driven-workflow/06-create-prd.md",
      "title": "# PROTOCOL 06: IMPLEMENTATION-READY PRD CREATION (PLANNING COMPLIANT)",
      "purpose_line": "**Purpose:** Execute IMPLEMENTATION-READY PRD CREATION workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `architecture-principles.md` from Protocol 05 (transitively includes PROJECT-BRIEF.md from P03 and discovery artifacts from P04)\n\n### Required Approvals\n- [ ] Product owner authorization to begin PRD drafting\n- [ ] Technical lead confirmation of architectural constraints\n\n### System State Requirements\n- [ ] Access to PRD templates in `.templates/prd/`\n- [ ] Availability of automation scripts `generate_prd_assets.py` and `validate_prd_gate.py`\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Context Alignment\n\n1. **`[MUST]` Confirm Feature Intent:**\n   * **Action:** Determine whether the effort is a net-new feature or modification; capture rationale in `prd-context.json`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Validating feature intent and architectural placement.\"\n   * **Halt condition:** Await stakeholder clarification if intent unclear.\n   * **Evidence:** `.artifacts/protocol-06/prd-context.json`\n\n2. **`[MUST]` Map to Architectural Layer:**\n   * **Action:** Use discovery inputs and architecture principles to identify primary implementation layer (e.g., frontend, backend, data pipeline) and announce detected layer.\n   * **Communication:** \n     > \"Detected primary implementation layer: [layer]. Constraints: [communication, technology, governance].\"\n   * **Evidence:** `.artifacts/protocol-06/layer-detection.md`\n\n3. **`[GUIDELINE]` Capture Stakeholder Goals:**\n   * **Action:** Summarize business goals, KPIs, and success metrics in `stakeholder-goals.md` for quick reference.\n\n### STEP 2: Requirements Elaboration\n\n1. **`[MUST]` Gather User Narratives:**\n   * **Action:** Elicit user stories and personas aligned with detected layer; store in `user-stories.md`.\n   * **Communication:** \n     > \"[PHASE 2] - Capturing user stories and personas for PRD foundation.\"\n   * **Evidence:** `.artifacts/protocol-06/user-stories.md`\n\n2. **`[MUST]` Define Functional Requirements:**\n   * **Action:** Detail feature behavior, workflows, acceptance criteria, and non-functional requirements in `functional-requirements.md`.\n   * **Evidence:** `.artifacts/protocol-06/functional-requirements.md`\n\n3. **`[MUST]` Specify Technical Requirements:**\n   * **Action:** Document API contracts, data models, integration points, security considerations, and system interactions in `technical-specs.md`.\n   * **Communication:** \n     > \"Documenting technical interfaces and constraints to guide engineering.\"\n   * **Evidence:** `.artifacts/protocol-06/technical-specs.md`\n\n4. **`[GUIDELINE]` Populate Decision Matrix:**\n   * **Action:** Maintain architectural decision matrix linking need types to implementation targets.\n   * **Example:**\n     ```markdown\n     | Need | Target | Constraints | Notes |\n     |------|--------|-------------|-------|\n     | Analytics KPI export | Backend service | Must align with GDPR retention | Use existing data warehouse pipeline |\n     ```\n\n### STEP 3: Risk, Dependency, and Validation Planning\n\n1. **`[MUST]` Consolidate Risks and Assumptions:**\n   * **Action:** Aggregate risks, assumptions, and mitigations from discovery into `risk-assumption-log.md`; include new items identified during elaboration.\n   * **Communication:** \n     > \"[PHASE 3] - Updating risk and assumption log for PRD readiness.\"\n   * **Evidence:** `.artifacts/protocol-06/risk-assumption-log.md`\n\n2. **`[MUST]` Define Acceptance & Validation Criteria:**\n   * **Action:** Establish measurable acceptance tests, KPIs, and validation steps in `validation-plan.md`.\n   * **Evidence:** `.artifacts/protocol-06/validation-plan.md`\n\n3. **`[GUIDELINE]` Align Timeline & Release Strategy:**\n   * **Action:** Outline milestones, release phases, and rollout strategy referencing `timeline-discussion.md`.\n\n### STEP 4: PRD Assembly and Automation\n\n1. **`[MUST]` Assemble PRD Document:**\n   * **Action:** Compile context, requirements, risks, and validation sections into `prd-{feature}.md` following standard template.\n   * **Communication:** \n     > \"[PHASE 4] - Assembling implementation-ready PRD.\"\n   * **Halt condition:** Pause if any mandatory section lacks confirmed content.\n   * **Evidence:** `.artifacts/protocol-06/prd-{feature}.md`\n\n2. **`[MUST]` Generate PRD Assets:**\n   * **Action:** Run `python scripts/generate_prd_assets.py --prd .artifacts/protocol-06/prd-{feature}.md --output .artifacts/protocol-06/prd-assets/` to create supporting artifacts (user stories, schemas, APIs).\n   * **Communication:** \n     > \"[RAY AUTOMATION] PRD assets generated and archived.\"\n   * **Evidence:** `.artifacts/protocol-06/prd-assets/`\n\n3. **`[MUST]` Validate PRD Quality:**\n   * **Action:** Execute `python scripts/validate_prd_gate.py --prd .artifacts/protocol-06/prd-{feature}.md --output .artifacts/protocol-06/prd-validation.json` ensuring completeness and alignment.\n   * **Communication:** \n     > \"PRD validation status: {status} - Score: {score}/100.\"\n   * **Evidence:** `.artifacts/protocol-06/prd-validation.json`\n\n4. **`[GUIDELINE]` Record Traceability:**\n   * **Action:** Map PRD sections to source discovery artifacts in `prd-traceability.json`.\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not write production code or modify repositories; deliver documentation only.**",
      "dependencies": [
        "P05"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P07",
      "file": ".cursor/ai-driven-workflow/07-technical-design-architecture.md",
      "title": "# PROTOCOL 07: TECHNICAL DESIGN & ARCHITECTURE (ARCHITECTURE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute TECHNICAL DESIGN & ARCHITECTURE workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `prd-{feature}.md`, `technical-specs.md`, and `prd-validation.json` from Protocol 06 (transitively includes PROJECT-BRIEF.md from P03 and risk artifacts from P04)\n\n### Required Approvals\n- [ ] Product and engineering leadership approval to begin architecture design\n- [ ] Security/compliance stakeholder availability for design review\n\n### System State Requirements\n- [ ] Access to architecture templates (`.templates/architecture/`)\n- [ ] Diagram tooling (draw.io, Mermaid) or ASCII diagram capability\n- [ ] Automation scripts `plan_from_brief.py`, `validate_workflow_integration.py` available\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Source Validation & Context Alignment\n\n1. **`[MUST]` Verify Inputs and Versions:**\n   * **Action:** Confirm that Project Brief, PRD, and discovery artifacts exist, match approved versions, and reflect latest sign-offs; record results in `source-alignment-report.json`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Validating brief and PRD alignment for architecture planning.\"\n   * **Halt condition:** Stop if any artifact missing or outdated.\n   * **Evidence:** `.artifacts/protocol-07/source-alignment-report.json`\n\n2. **`[MUST]` Consolidate Design Inputs:**\n   * **Action:** Extract functional scope, non-functional requirements, constraints, and risks into `design-input-matrix.md`.\n   * **Communication:** \n     > \"Consolidating functional and non-functional requirements into design input matrix.\"\n   * **Evidence:** `.artifacts/protocol-07/design-input-matrix.md`\n\n3. **`[GUIDELINE]` Map Key Assumptions:**\n   * **Action:** Translate outstanding assumptions into design checkpoints for later validation; store in `design-assumptions.md`.\n\n### STEP 2: Architecture Decomposition\n\n1. **`[MUST]` Identify System Boundaries:**\n   * **Action:** Use `plan_from_brief.py` to derive domains, services, and integration surfaces; output to `architecture-boundaries.json`.\n   * **Communication:** \n     > \"[PHASE 2] - Mapping system boundaries and core components.\"\n   * **Evidence:** `.artifacts/protocol-07/architecture-boundaries.json`\n\n2. **`[MUST]` Capture Architecture Decisions:**\n   * **Action:** Create Architecture Decision Records (ADRs) for key choices, including rationale, constraints, and alternatives; compile in `architecture-decisions.md`.\n   * **Communication:** \n     > \"Documenting architecture decisions with traceable rationale.\"\n   * **Evidence:** `.artifacts/protocol-07/architecture-decisions.md`\n\n3. **`[GUIDELINE]` Produce Interaction Diagrams:**\n   * **Action:** Generate sequence/data flow diagram showing critical interactions; save as `interaction-diagram.drawio` or `interaction-diagram.md`.\n\n### STEP 3: Specification Packaging & Validation\n\n1. **`[MUST]` Assemble Technical Design Document:**\n   * **Action:** Compile inputs, boundaries, ADRs, data contracts, security notes, and operational considerations into `TECHNICAL-DESIGN.md`.\n   * **Communication:** \n     > \"[PHASE 3] - Assembling comprehensive technical design specification.\"\n   * **Evidence:** `.artifacts/protocol-07/TECHNICAL-DESIGN.md`\n\n2. **`[MUST]` Validate Compliance and Feasibility:**\n   * **Action:** Run `python scripts/validate_workflow_integration.py --design .artifacts/protocol-07/TECHNICAL-DESIGN.md --output .artifacts/protocol-07/design-validation-report.json` covering security, integration, and performance constraints.\n   * **Communication:** \n     > \"Design validation status: {status}; review report for details.\"\n   * **Evidence:** `.artifacts/protocol-07/design-validation-report.json`\n\n3. **`[GUIDELINE]` Draft Implementation Roadmap:**\n   * **Action:** Outline epics/modules, sequencing, and readiness criteria in `implementation-roadmap.md`.\n\n### STEP 4: Approval & Handoff Preparation\n\n1. **`[MUST]` Conduct Stakeholder Review:**\n   * **Action:** Present design summary, diagram, and decisions; log approvals in `design-approval-record.json` with timestamps and approvers.\n   * **Communication:** \n     > \"[PHASE 4] - Requesting stakeholder approval for technical design.\"\n   * **Halt condition:** Do not continue without recorded approval or documented waiver.\n   * **Evidence:** `.artifacts/protocol-07/design-approval-record.json`\n\n2. **`[MUST]` Generate Task Inputs:**\n   * **Action:** Export component responsibilities, interfaces, and dependencies into `task-generation-input.json` for Protocol 08.\n   * **Evidence:** `.artifacts/protocol-07/task-generation-input.json`\n\n3. **`[GUIDELINE]` Archive Artifacts:**\n   * **Action:** Produce `design-artifact-manifest.json` listing all diagrams, ADRs, validation reports, and locations.\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not introduce components or integrations that lack grounding in the brief or PRD; every element must trace to validated requirements.**",
      "dependencies": [
        "P06"
      ],
      "handoffs": [
        "P08"
      ]
    },
    {
      "protocol_id": "P08",
      "file": ".cursor/ai-driven-workflow/08-generate-tasks.md",
      "title": "# PROTOCOL 08: TECHNICAL TASK GENERATION (PLANNING COMPLIANT)",
      "purpose_line": "**Purpose:** Execute TECHNICAL TASK GENERATION workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `TECHNICAL-DESIGN.md` and `task-generation-input.json` from Protocol 07\n- [ ] `prd-{feature}.md`, `user-stories.md`, `functional-requirements.md` from Protocol 06\n- [ ] Applicable rule index files and automation catalog from `.cursor/rules/` and `.cursor/context-kit/`\n\n### Required Approvals\n- [ ] Technical design approval recorded in `design-approval-record.json`\n- [ ] Product owner acknowledgement that PRD is final for decomposition\n\n### System State Requirements\n- [ ] Access to repository search tools compliant with Tool Usage Protocol\n- [ ] Ability to execute automation scripts `validate_tasks.py` and `enrich_tasks.py`\n- [ ] Permissions to write task files under `.cursor/tasks/` or `tasks/`\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Context Preparation\n\n1. **`[MUST]` Index Governance Rules:**\n   * **Action:** Locate rule directories, parse metadata (description, tags, triggers, scope), and build an index stored in `rule-index.json`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Indexing governance rules for task alignment.\"\n   * **Halt condition:** Stop if rule directories missing or metadata incomplete.\n   * **Evidence:** `.artifacts/protocol-08/rule-index.json`\n\n2. **`[MUST]` Analyze Inputs:**\n   * **Action:** Review PRD, technical design, and task-generation input to identify feature scope, implementation layers, and constraints; log summary in `task-context.md`.\n   * **Evidence:** `.artifacts/protocol-08/task-context.md`\n\n3. **`[GUIDELINE]` Identify Personas & Automation Candidates:**\n   * **Action:** Determine LLM personas and relevant automation hooks from previous protocols; note in `task-personas.json`.\n\n### STEP 2: High-Level Task Structuring\n\n1. **`[MUST]` Create Task File Skeleton:**\n   * **Action:** Initialize `tasks-{feature}.md` under `.cursor/tasks/` with sections for high-level tasks, dependencies, and automation metadata.\n   * **Communication:** \n     > \"[PHASE 2] - Drafting high-level task structure with WHY context.\"\n   * **Evidence:** `.cursor/tasks/tasks-{feature}.md`\n\n2. **`[MUST]` Generate High-Level Tasks:**\n   * **Action:** Produce MVP-focused tasks with numbering, WHY statements, complexity tags, and dependency annotations referencing other tasks.\n   * **Evidence:** `.artifacts/protocol-08/high-level-tasks.json`\n\n3. **`[MUST]` Present for Approval:**\n   * **Action:** Share high-level task list summary and await explicit \"Go\" before decomposition.\n   * **Halt condition:** Do not proceed until approval recorded in `task-approval-log.md`.\n   * **Evidence:** `.artifacts/protocol-08/task-approval-log.md`\n\n4. **`[GUIDELINE]` Recommend Branching Strategy:**\n   * **Action:** Suggest Git branch naming and parallelization strategy in `task-context.md`.\n\n### STEP 3: Detailed Decomposition\n\n1. **`[MUST]` Break Down Tasks by Layer:**\n   * **Action:** For each approved high-level task, generate detailed subtasks using appropriate templates (frontend, backend, etc.), ensuring rule references inserted.\n   * **Communication:** \n     > \"[PHASE 3] - Decomposing approved tasks into actionable subtasks with rule mapping.\"\n   * **Evidence:** `.cursor/tasks/tasks-{feature}.md` updated with subtasks\n\n2. **`[MUST]` Assign Automation Hooks:**\n   * **Action:** Annotate high-level tasks with automation metadata (script/workflow commands) referencing validated tools.\n   * **Evidence:** `.artifacts/protocol-08/task-automation-matrix.json`\n\n3. **`[GUIDELINE]` Map Personas:**\n   * **Action:** Assign LLM personas or role ownership per high-level task in `task-personas.json`.\n\n### STEP 4: Validation and Packaging\n\n1. **`[MUST]` Validate Task Structure:**\n   * **Action:** Execute `python scripts/validate_tasks.py --task-file .cursor/tasks/tasks-{feature}.md --output .artifacts/protocol-08/task-validation.json` to ensure completeness and compliance.\n   * **Communication:** \n     > \"Task validation status: {status} - {issues} issues detected.\"\n   * **Evidence:** `.artifacts/protocol-08/task-validation.json`\n\n2. **`[MUST]` Enrich Task Metadata:**\n   * **Action:** Run `python scripts/enrich_tasks.py --task-file .cursor/tasks/tasks-{feature}.md --output .artifacts/protocol-08/task-enrichment.json` to add effort estimates, risk flags, and automation coverage.\n   * **Evidence:** `.artifacts/protocol-08/task-enrichment.json`\n\n3. **`[MUST]` Archive Supporting Data:**\n   * **Action:** Save rule index, personas, automation matrix, and validation outputs in `.artifacts/protocol-08/` with manifest `task-artifact-manifest.json`.\n\n4. **`[GUIDELINE]` Summarize Execution Plan:**\n   * **Action:** Produce `task-execution-summary.md` highlighting dependencies, automation, and readiness for Protocol 21.\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not author production code; produce structured task documentation only.**",
      "dependencies": [
        "P06",
        "P07"
      ],
      "handoffs": [
        "P21"
      ]
    },
    {
      "protocol_id": "P09",
      "file": ".cursor/ai-driven-workflow/09-environment-setup-validation.md",
      "title": "# PROTOCOL 09: ENVIRONMENT SETUP & VALIDATION (DEVOPS COMPLIANT)",
      "purpose_line": "**Purpose:** Execute ENVIRONMENT SETUP & VALIDATION workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `TECHNICAL-DESIGN.md`, `design-validation-report.json`, `task-generation-input.json` from Protocol 07\n- [ ] `tasks-{feature}.md`, `task-automation-matrix.json` from Protocol 08\n- [ ] `.cursor/context-kit/governance-status.md` and `bootstrap-manifest.json` from Protocol 04\n\n### Required Approvals\n- [ ] DevOps lead authorization to provision environments\n- [ ] Security team confirmation for credential handling and secret storage\n\n### System State Requirements\n- [ ] Access to infrastructure credentials, repositories, and artifact storage\n- [ ] Clean workstation or container image available for validation\n- [ ] Automation scripts `doctor.py`, `scaffold_phase_artifacts.py`, and validation suites accessible\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Requirement Alignment\n\n1. **`[MUST]` Extract Environment Requirements:**\n   * **Action:** Review `TECHNICAL-DESIGN.md`, `task-generation-input.json`, and `tasks-{feature}.md` to identify runtime tooling, services, and configuration needs; capture in `environment-requirements.md`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Consolidating environment requirements from design and task plans.\"\n   * **Halt condition:** Stop if requirements conflict or remain undefined.\n   * **Evidence:** `.artifacts/protocol-09/environment-requirements.md`\n\n2. **`[MUST]` Validate Credentials & Access:**\n   * **Action:** Confirm repository access, secret storage workflow, API keys, and external service credentials; record in `access-readiness-checklist.json`.\n   * **Communication:** \n     > \"Validating credentials and secret storage readiness.\"\n   * **Evidence:** `.artifacts/protocol-09/access-readiness-checklist.json`\n\n3. **`[GUIDELINE]` Capture Risk Flags:**\n   * **Action:** Log environment risks (e.g., license limits, dependency volatility) in `environment-risk-log.md`.\n\n### STEP 2: Provisioning & Tooling Verification\n\n1. **`[MUST]` Execute Environment Doctor:**\n   * **Action:** Run `python scripts/doctor.py --strict --output .artifacts/protocol-09/environment-diagnostics.json` to verify required tooling.\n   * **Communication:** \n     > \"[PHASE 2] - Running environment diagnostics for tooling compliance.\"\n   * **Halt condition:** Pause if diagnostics fail.\n   * **Evidence:** `.artifacts/protocol-09/environment-diagnostics.json`\n\n2. **`[MUST]` Provision Scaffold & Dependencies:**\n   * **Action:** Clone repository, install dependencies, and execute bootstrap scripts (e.g., `bash scripts/setup.sh --non-interactive`); document in `provision-log.md`.\n   * **Evidence:** `.artifacts/protocol-09/provision-log.md`\n\n3. **`[GUIDELINE]` Validate Container/Image:**\n   * **Action:** Build/pull required dev containers or VM images; store metadata in `runtime-images.json`.\n\n### STEP 3: Configuration & Validation\n\n1. **`[MUST]` Apply Configuration Templates:**\n   * **Action:** Populate environment variables, secret placeholders, and configuration files; run `python scripts/scaffold_phase_artifacts.py --phase env --output .artifacts/protocol-09/env-configuration-report.json`.\n   * **Communication:** \n     > \"[PHASE 3] - Applying configuration templates and documenting outcomes.\"\n   * **Evidence:** `.artifacts/protocol-09/env-configuration-report.json`\n\n2. **`[MUST]` Run Validation Suite:**\n   * **Action:** Execute smoke tests, linting, migrations, and sample automation hooks from `task-automation-matrix.json`; store outputs in `validation-suite-report.json`.\n   * **Evidence:** `.artifacts/protocol-09/validation-suite-report.json`\n\n3. **`[GUIDELINE]` Record Performance Baseline:**\n   * **Action:** Capture setup duration and validation runtimes in `provision-log.md`.\n\n### STEP 4: Documentation & Handoff\n\n1. **`[MUST]` Create Environment Handbook:**\n   * **Action:** Assemble `ENVIRONMENT-README.md` with setup steps, commands, validation expectations, troubleshooting, and automation references.\n   * **Communication:** \n     > \"[PHASE 4] - Drafting environment handbook for contributors.\"\n   * **Evidence:** `.artifacts/protocol-09/ENVIRONMENT-README.md`\n\n2. **`[MUST]` Record Approval & Distribution Plan:**\n   * **Action:** Log validation status, approver, distribution channels in `environment-approval-record.json`.\n   * **Halt condition:** Do not proceed without approval.\n   * **Evidence:** `.artifacts/protocol-09/environment-approval-record.json`\n\n3. **`[GUIDELINE]` Package Onboarding Assets:**\n   * **Action:** Bundle scripts, env templates, and handbook into `environment-onboarding.zip`; update manifest `environment-artifact-manifest.json`.\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not declare the environment ready until validation passes on a clean baseline and credentials are verified.**",
      "dependencies": [
        "P04",
        "P07",
        "P08"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P10",
      "file": ".cursor/ai-driven-workflow/10-process-tasks.md",
      "title": "# PROTOCOL 10: CONTROLLED TASK EXECUTION (DELIVERY COMPLIANT)",
      "purpose_line": "**Purpose:** Execute CONTROLLED TASK EXECUTION workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `tasks-{feature}.md`, `task-validation.json`, `task-enrichment.json` from Protocol 08\n- [ ] `ENVIRONMENT-README.md`, `validation-suite-report.json` from Protocol 09\n- [ ] `rule-index.json` and applicable governance rules from `.cursor/rules/`\n\n### Required Approvals\n- [ ] Engineering lead authorization to begin execution on selected tasks\n- [ ] QA lead acknowledgement of quality gate responsibilities\n\n### System State Requirements\n- [ ] Validated development environment configured per Protocol 09\n- [ ] Access to required repositories, CI/CD tooling, and documentation\n- [ ] Automation scripts `update_task_state.py`, `/review`, and quality audit tools available\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Pre-Execution Alignment\n\n1. **`[MUST]` Select Parent Task:**\n   * **Action:** Identify next unchecked parent task from `tasks-{feature}.md`; document selection in `execution-session-log.md`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Preparing to execute parent task {ID}: {Title}.\"\n   * **Halt condition:** Await confirmation if task ambiguity detected.\n   * **Evidence:** `.artifacts/protocol-21/execution-session-log.md`\n\n2. **`[MUST]` Confirm Recommended Model & Environment:**\n   * **Action:** Read recommended model tag in task file, verify environment readiness (tool versions, credentials) referencing Protocol 09 outputs; log results.\n   * **Communication:** \n     > \"[RAY PRE-FLIGHT CHECK] Recommended model: {Model}. Environment diagnostics verified. Reply 'Go' to proceed.\"\n   * **Halt condition:** Do not start execution until confirmation received.\n   * **Evidence:** `.artifacts/protocol-21/preflight-checklist.json`\n\n3. **`[GUIDELINE]` Note Quality Gate Plan:**\n   * **Action:** Outline planned quality checks (tests, linting, audits) in `execution-session-log.md`.\n\n### STEP 2: Subtask Execution Loop\n\n1. **`[MUST]` Load Subtask Context:**\n   * **Action:** For each unchecked subtask, gather rule references (`[APPLIES RULES: ...]`), load documentation, and announce context loading.\n   * **Communication:** \n     > \"[RAY CONTEXT LOADED] Subtask {ID} applying rules: {rule list}.\"\n   * **Evidence:** `.artifacts/protocol-21/context-history.log`\n\n2. **`[MUST]` Execute Subtask:**\n   * **Action:** Perform implementation steps using allowed tools, keeping scope limited to the subtask description and loaded rules.\n   * **Evidence:** `.artifacts/protocol-21/subtask-evidence/{ID}/`\n\n3. **`[MUST]` Update Task File & Commit Strategy:**\n   * **Action:** Mark subtask as complete in `tasks-{feature}.md`, propose semantic commit message, and log actions in `execution-session-log.md`.\n   * **Evidence:** `.artifacts/protocol-21/task-file-diff.patch`\n\n4. **`[GUIDELINE]` Capture Quick Validation:**\n   * **Action:** Run targeted tests or linting relevant to subtask and record results.\n\n### STEP 3: Parent Task Completion\n\n1. **`[MUST]` Run Comprehensive Quality Gate:**\n   * **Action:** Execute `/review` or `.cursor/ai-driven-workflow/4-quality-audit.md --mode comprehensive`, analyze CI results, and resolve CRITICAL/HIGH findings.\n   * **Communication:** \n     > \"[RAY QUALITY GATE] Running comprehensive audit for parent task {ID}.\"\n   * **Evidence:** `.artifacts/protocol-21/quality-reports/{parentID}.json`\n\n2. **`[MUST]` Sync Task State:**\n   * **Action:** Run `python scripts/update_task_state.py --task-file .cursor/tasks/tasks-{feature}.md --task-id {parentID} --status complete --output .artifacts/protocol-21/task-state.json` and update task tracker.\n   * **Evidence:** `.artifacts/protocol-21/task-state.json`\n\n3. **`[MUST]` Document Retrospective Snapshot:**\n   * **Action:** Summarize work, risks, remaining issues in `parent-task-retrospective.md`; note commit decisions.\n   * **Evidence:** `.artifacts/protocol-21/parent-task-retrospective.md`\n\n4. **`[GUIDELINE]` Recommend Commit Strategy:**\n   * **Action:** Suggest keeping granular commits or squashing based on complexity; await human confirmation before executing.\n\n### STEP 4: Session Closeout\n\n1. **`[MUST]` Record Session Summary:**\n   * **Action:** Update `execution-session-log.md` with completed subtasks, quality gate status, CI outcomes, and approvals.\n   * **Evidence:** `.artifacts/protocol-21/execution-session-log.md`\n\n2. **`[MUST]` Archive Evidence:**\n   * **Action:** Ensure subtask artifacts, quality reports, and task diffs stored in `.artifacts/protocol-21/` with manifest `execution-artifact-manifest.json`.\n\n3. **`[GUIDELINE]` Prepare Next Session Brief:**\n   * **Action:** Document next parent task recommendation and outstanding blockers for upcoming session.\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not modify tasks outside the authorized task file or skip quality gates; progress must remain auditable.**",
      "dependencies": [
        "P08",
        "P09"
      ],
      "handoffs": [
        "P09"
      ]
    },
    {
      "protocol_id": "P11",
      "file": ".cursor/ai-driven-workflow/11-integration-testing.md",
      "title": "# PROTOCOL 11 : INTEGRATION TESTING & SYSTEM VALIDATION (QUALITY COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `TECHNICAL-DESIGN.md`, `contract-validation-config.json` from Protocol 07\n- [ ] `validation-suite-report.json`, `environment-approval-record.json` from Protocol 09\n- [ ] `execution-artifact-manifest.json`, `task-state.json` from Protocol 10\n\n### Required Approvals\n- [ ] Quality orchestrator authorization to commence integration testing\n- [ ] Environment owner confirmation that integration environment matches baseline\n\n### System State Requirements\n- [ ] Access to integration environment credentials, seeded datasets, and observability tooling\n- [ ] Automation scripts `validate_environment.py`, `run_contract_tests.py`, integration test runner available\n- [ ] Storage for evidence bundle under `.artifacts/protocol-15/`\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Scope & Environment Alignment\n\n1. **`[MUST]` Define Integration Scope:**\n   * **Action:** Consolidate completed features, architectural interfaces, and dependencies from Protocols 3 and 6; produce `integration-scope-matrix.json` if not already created.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Aligning integration scope across delivery and architecture artifacts.\"\n   * **Halt condition:** Stop if required artifacts missing or inconsistent.\n   * **Evidence:** `.artifacts/protocol-15/integration-scope-matrix.json`\n\n2. **`[MUST]` Validate Environment Parity:**\n   * **Action:** Run `python scripts/validate_environment.py --env integration --output .artifacts/protocol-15/environment-validation-report.json` to confirm environment matches baseline configuration.\n   * **Communication:** \n     > \"Validating integration environment parity and service connectivity.\"\n   * **Evidence:** `.artifacts/protocol-15/environment-validation-report.json`\n\n3. **`[GUIDELINE]` Refresh Test Data Inventory:**\n   * **Action:** Update dataset catalog with sources, refresh cadence, and anonymization notes in `test-data-inventory.md`.\n\n### STEP 2: Test Design & Instrumentation\n\n1. **`[MUST]` Assemble Test Plan:**\n   * **Action:** Map integration scenarios to automated suites, specifying entry/exit conditions, observability hooks, and rollback steps in `integration-test-plan.md`.\n   * **Communication:** \n     > \"[PHASE 2] - Building integration scenarios and automation plan.\"\n   * **Evidence:** `.artifacts/protocol-15/integration-test-plan.md`\n\n2. **`[MUST]` Configure Contract Validation:**\n   * **Action:** Execute `python scripts/run_contract_tests.py --env integration --output .artifacts/protocol-15/contract-validation-results.json` and record configuration in `contract-validation-config.json`.\n   * **Evidence:** `.artifacts/protocol-15/contract-validation-results.json`\n\n3. **`[GUIDELINE]` Verify Observability:**\n   * **Action:** Ensure logging, tracing, and metrics coverage for scenarios; document in `observability-readiness.md`.\n\n### STEP 3: Execution & Defect Management\n\n1. **`[MUST]` Run Integration Suites:**\n   * **Action:** Execute automated tests (API, workflow, migration) using commands defined in test plan; store consolidated results in `test-execution-report.json`.\n   * **Communication:** \n     > \"[PHASE 3] - Executing integration test suites across critical paths.\"\n   * **Evidence:** `.artifacts/protocol-15/test-execution-report.json`\n\n2. **`[MUST]` Log and Triage Defects:**\n   * **Action:** Capture failures, create tickets, assign owners, and document remediation status in `defect-log.csv`.\n   * **Halt condition:** Pause progression until critical defects receive mitigation plan.\n   * **Evidence:** `.artifacts/protocol-15/defect-log.csv`\n\n3. **`[GUIDELINE]` Perform Regression Spot-Checks:**\n   * **Action:** Rerun targeted suites around resolved defects; record coverage in `regression-summary.md`.\n\n### STEP 4: Evidence Packaging & Sign-Off\n\n1. **`[MUST]` Compile Evidence Bundle:**\n   * **Action:** Package scope matrix, environment validation, test results, defects, and regression logs into `INTEGRATION-EVIDENCE.zip`; generate manifest `integration-evidence-manifest.json`.\n   * **Communication:** \n     > \"[PHASE 4] - Compiling integration evidence bundle for quality audit.\"\n   * **Evidence:** `.artifacts/protocol-15/integration-evidence-manifest.json`\n\n2. **`[MUST]` Record Integration Sign-Off:**\n   * **Action:** Capture approval details (approver, timestamp, scope) in `integration-signoff.json`.\n   * **Halt condition:** Do not transition to Protocol 19 without sign-off or documented waiver.\n   * **Evidence:** `.artifacts/protocol-15/integration-signoff.json`\n\n3. **`[GUIDELINE]` Provide Forward Recommendations:**\n   * **Action:** Document monitoring improvements, deployment checks, or automation gaps for Protocols 4, 10, and 12 in `forward-recommendations.md`.\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] Do not grant integration readiness unless all critical paths and contracts pass with evidence logged.**",
      "dependencies": [
        "P07",
        "P09",
        "P10"
      ],
      "handoffs": [
        "P19"
      ]
    },
    {
      "protocol_id": "P12",
      "file": ".cursor/ai-driven-workflow/12-quality-audit.md",
      "title": "# PROTOCOL 12 : QUALITY AUDIT ORCHESTRATOR (QUALITY ASSURANCE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `INTEGRATION-EVIDENCE.zip` from Protocol 11 \u2013 consolidated integration and regression results\n- [ ] `integration-signoff.json` from Protocol 11 \u2013 upstream readiness snapshot\n- [ ] Latest Git diff summary produced by `scripts/collect_change_context.py`\n- [ ] `TECHNICAL-DESIGN.md` from Protocol 07 \u2013 architecture baseline for compliance checks\n\n### Required Approvals\n- [ ] Integration validation sign-off from Protocol 11 Integration Lead\n- [ ] Security waiver or approval (if applicable)\n- [ ] Product Owner acknowledgement that scope matches PRD acceptance criteria (Protocol 06)\n\n### System State Requirements\n- [ ] CI workflows `ci-test.yml` and `ci-lint.yml` configured in repository\n- [ ] Access to `.cursor/ai-driven-workflow/review-protocols/` directory and router utility\n- [ ] Write permissions to `.artifacts/quality-audit/` for evidence capture\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Pre-Audit Automation Enablement\n\n1. **`[MUST]` Execute Baseline CI Validation:**\n   * **Action:** Run required CI workflows (`ci-test.yml`, `ci-lint.yml`) and store outputs at `.artifacts/quality-audit/ci-<workflow>-results.json`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Executing baseline CI workflows for quality audit enablement...\"\n   * **Halt condition:** Stop if any workflow fails or artifacts cannot be generated.\n   * **Evidence:** CI result JSON files plus console transcript stored in `.artifacts/quality-audit/ci-workflow-log.txt`.\n\n2. **`[MUST]` Aggregate Coverage Metrics:**\n   * **Action:** Invoke coverage aggregation to produce `.artifacts/quality-audit/coverage-report.json` with line/function coverage stats.\n   * **Communication:** \n     > \"[RAY AUTOMATION] Coverage aggregation complete. Overall coverage: {percentage}%\"\n   * **Halt condition:** Pause if coverage report lacks required sections or falls below mandated baseline (<80%).\n   * **Evidence:** Coverage report and timestamped metadata file `coverage-metadata.yaml`.\n\n3. **`[GUIDELINE]` Snapshot Change Context:**\n   * **Action:** Generate Git diff summary focusing on touched modules to guide audit scope.\n   * **Example:**\n     ```bash\n     python scripts/collect_change_context.py --since main --output .artifacts/quality-audit/change-context.json\n     ```\n\n### STEP 2: Mode Determination and Routing\n\n1. **`[MUST]` Resolve Review Mode:**\n   * **Action:** Parse `/review --mode {target}` input or fallback rules to determine specialized protocol.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Determining review mode '{mode}' via centralized router...\"\n   * **Halt condition:** Suspend execution if router cannot map mode to protocol.\n   * **Evidence:** `.artifacts/quality-audit/mode-resolution.json` capturing requested mode, router decision, and fallback chain.\n\n2. **`[MUST]` Load Specialized Protocol Instructions:**\n   * **Action:** Fetch markdown from `.cursor/ai-driven-workflow/review-protocols/{protocol}.md` and register execution scope.\n   * **Communication:** \n     > \"[ROUTER] Specialized protocol '{protocol}' loaded for execution.\"\n   * **Halt condition:** Stop if file retrieval fails or integrity check mismatches expected hash.\n   * **Evidence:** `.artifacts/quality-audit/protocol-manifest.json` with hash, version, and dependencies.\n\n3. **`[GUIDELINE]` Validate Router Fallback Logic:**\n   * **Action:** Confirm router escalates from custom to generic protocol when custom file missing.\n   * **Example:**\n     ```python\n     selected = router.resolve(mode)\n     assert selected in router.available_protocols\n     ```\n\n### STEP 3: Specialized Protocol Execution Oversight\n\n1. **`[MUST]` Execute Selected Review Protocol:**\n   * **Action:** Follow instructions inside loaded protocol, delegating steps while capturing evidence references in orchestrator log.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Executing specialized review protocol '{protocol}'...\"\n   * **Halt condition:** Halt if specialized protocol reports blocking findings without mitigation.\n   * **Evidence:** `.artifacts/quality-audit/execution-log.md` enumerating steps, checks, and outcomes.\n\n2. **`[MUST]` Consolidate Findings Across Checks:**\n   * **Action:** Merge lint/test/security outputs into unified dataset `audit-findings.json` categorized by severity.\n   * **Communication:** \n     > \"[PHASE 3] Consolidating findings from specialized review outputs...\"\n   * **Halt condition:** Pause if any required artifact missing from specialized run.\n   * **Evidence:** `.artifacts/quality-audit/audit-findings.json` plus severity summary chart `finding-summary.csv`.\n\n3. **`[GUIDELINE]` Trigger Extended Checks for Comprehensive Mode:**\n   * **Action:** When mode == `comprehensive`, sequence quick \u2192 security \u2192 architecture \u2192 design \u2192 ui reviews.\n   * **Example:**\n     ```bash\n     python scripts/run_comprehensive_review.py --output .artifacts/quality-audit/comprehensive-trace.json\n     ```\n\n### STEP 4: Unified Reporting and Handoff Preparation\n\n1. **`[MUST]` Generate Audit Report Package:**\n   * **Action:** Compile CI, coverage, specialized findings, and router manifests into `QUALITY-AUDIT-PACKAGE.zip`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Packaging unified quality audit deliverables...\"\n   * **Halt condition:** Stop if package checksum verification fails.\n   * **Evidence:** `.artifacts/quality-audit/quality-audit-manifest.json` plus zipped artifact.\n\n2. **`[MUST]` Issue Readiness Recommendation:**\n   * **Action:** Produce decision record (`go`, `go-with-risks`, `no-go`) referencing gate scores and mitigations.\n   * **Communication:** \n     > \"[RAY VALIDATION REQUEST] - Audit decision: {decision}. Confirm acceptance to proceed to UAT coordination?\"\n   * **Halt condition:** Await stakeholder confirmation for `go-with-risks` or `no-go` outcomes.\n   * **Evidence:** `.artifacts/quality-audit/readiness-recommendation.md` detailing rationale and signatories.\n\n3. **`[GUIDELINE]` Publish Audit Summary to Context Kit:**\n   * **Action:** Update `.cursor/context-kit/quality-audit-summary.json` for rapid reuse in subsequent phases.\n   * **Example:**\n     ```python\n     save_summary(findings, path=\".cursor/context-kit/quality-audit-summary.json\")\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT bypass pre-audit automation or deliver reports without executing the selected specialized protocol end-to-end.**",
      "dependencies": [
        "P06",
        "P07",
        "P11"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P13",
      "file": ".cursor/ai-driven-workflow/13-uat-coordination.md",
      "title": "# PROTOCOL 13 : USER ACCEPTANCE TESTING (UAT) COORDINATION (CUSTOMER VALIDATION COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `QUALITY-AUDIT-PACKAGE.zip` from Protocol 12 \u2013 final quality audit evidence\n- [ ] `INTEGRATION-EVIDENCE.zip` from Protocol 11 \u2013 integration verification traceability\n- [ ] `readiness-recommendation.md` from Protocol 12 \u2013 quality audit recommendation\n- [ ] `release-notes-draft.md` from Protocol 10 \u2013 baseline scope statement\n- [ ] `uat-scenario-catalog.csv` (if existing) from prior cycles stored in `.cursor/context-kit/`\n\n### Required Approvals\n- [ ] Product Owner confirmation that UAT objectives align with PRD acceptance criteria (Protocol 06)\n- [ ] Quality Audit readiness recommendation signed by Senior Quality Engineer (Protocol 12)\n- [ ] Staging environment access granted by DevOps lead (Protocol 09)\n\n### System State Requirements\n- [ ] UAT/staging environment synchronized with latest release candidate build\n- [ ] Communication channels (email/slack) configured for participants\n- [ ] Access to `.artifacts/uat/` directory with write permissions\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Entry Validation and Participant Preparation\n\n1. **`[MUST]` Verify UAT Entry Criteria:**\n   * **Action:** Cross-check prerequisites across Protocols 4, 9, and 10 to confirm readiness for UAT execution.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Validating UAT scope, entry criteria, and prerequisite artifacts...\"\n   * **Halt condition:** Stop if any required artifact or approval is missing.\n   * **Evidence:** `.artifacts/uat/uat-entry-checklist.json` capturing each prerequisite and signatory.\n\n2. **`[MUST]` Assemble Participant Roster and Logistics:**\n   * **Action:** Identify participants, confirm environment access, schedule sessions, and document contact matrix.\n   * **Communication:** \n     > \"[PHASE 1] Participant roster confirmed. Invitations dispatching now...\"\n   * **Halt condition:** Pause if any participant lacks environment or data access.\n   * **Evidence:** `.artifacts/uat/participant-roster.csv` and `.artifacts/uat/session-schedule.ics`.\n\n3. **`[GUIDELINE]` Prepare UAT Toolkit:**\n   * **Action:** Curate scenarios, test data, walkthrough videos, and support documentation tailored to personas.\n   * **Example:**\n     ```bash\n     python scripts/build_uat_toolkit.py --scenarios config/uat-scenarios.yaml --output .artifacts/uat/uat-toolkit-manifest.json\n     ```\n\n### STEP 2: Orientation and Cycle Facilitation\n\n1. **`[MUST]` Conduct UAT Kickoff:**\n   * **Action:** Brief participants on objectives, scope, acceptance criteria, communication channels, and support expectations.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Hosting UAT kickoff session with stakeholders...\"\n   * **Halt condition:** Halt progression if kickoff feedback reveals misaligned expectations.\n   * **Evidence:** `.artifacts/uat/kickoff-notes.md` summarizing agreements and questions.\n\n2. **`[MUST]` Facilitate Execution Cycles:**\n   * **Action:** Monitor scenario execution, support testers, and ensure evidence capture via structured logging.\n   * **Communication:** \n     > \"[PHASE 2] Monitoring UAT execution. Logging scenario outcomes in real time...\"\n   * **Halt condition:** Suspend if critical environment issues prevent progress.\n   * **Evidence:** `.artifacts/uat/execution-log.json` and attachments (screenshots, recordings).\n\n3. **`[GUIDELINE]` Capture Qualitative Insights:**\n   * **Action:** Record usability notes, enhancement ideas, and sentiment quotes.\n   * **Example:**\n     ```markdown\n     - Persona: Billing Manager\n       - Quote: \"The reconciliation workflow matches expectations.\"\n       - Improvement: Add tooltip for tax adjustments.\n     ```\n\n### STEP 3: Defect Management and Revalidation\n\n1. **`[MUST]` Log and Prioritize Findings:**\n   * **Action:** Convert issues into tracked defects, categorize severity, assign owners, and sync with Protocol 21 task board.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Triage UAT findings and initiating remediation workflows...\"\n   * **Halt condition:** Pause progression if blocker severity items remain untriaged.\n   * **Evidence:** `.artifacts/uat/uat-defect-register.csv` with linkage to ticket IDs.\n\n2. **`[MUST]` Coordinate Fix Verification:**\n   * **Action:** Ensure fixes deployed to UAT/staging, re-run impacted scenarios, and update execution logs with retest outcomes.\n   * **Communication:** \n     > \"[PHASE 3] Fix verification in progress. Requesting confirmation from testers...\"\n   * **Halt condition:** Stop if retests fail to confirm resolution.\n   * **Evidence:** `.artifacts/uat/retest-results.json` mapping defects to retest status.\n\n3. **`[GUIDELINE]` Refresh Release Notes & FAQs:**\n   * **Action:** Update release notes with accepted scope, known issues, and FAQ entries informed by UAT insights.\n   * **Example:**\n     ```bash\n     python scripts/generate_release_notes.py --source .artifacts/uat/feedback-notebook.md --output .artifacts/uat/release-notes-draft.md\n     ```\n\n### STEP 4: Acceptance, Documentation, and Handoff\n\n1. **`[MUST]` Capture Formal UAT Sign-Off:**\n   * **Action:** Collect approvals from designated stakeholders confirming acceptance criteria met and residual risk tolerated.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Requesting formal UAT acceptance approvals...\"\n   * **Halt condition:** Do not proceed if signatures missing or conditional approvals unmet.\n   * **Evidence:** `.artifacts/uat/uat-approval-record.json` and e-sign evidence if available.\n\n2. **`[MUST]` Compile UAT Closure Package:**\n   * **Action:** Bundle entry checklist, execution logs, defect register, retest results, sign-off record, and release notes into `UAT-CLOSURE-PACKAGE.zip`.\n   * **Communication:** \n     > \"[PHASE 4] Compiling UAT closure package for deployment handoff...\"\n   * **Halt condition:** Stop if any mandatory artifact missing from package.\n   * **Evidence:** `.artifacts/uat/uat-closure-manifest.json` with artifact list and checksum.\n\n3. **`[GUIDELINE]` Deliver Deployment Handoff Brief:**\n   * **Action:** Summarize outcomes, risks, and support expectations for Protocols 10 and 11 teams.\n   * **Example:**\n     ```markdown\n     ## UAT Handoff Summary\n     - Decision: GO\n     - Known Issues: None\n     - Support Notes: Customer champions available during launch window.\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT declare UAT complete without recorded stakeholder approvals, resolved blocking feedback, and updated release documentation reflecting accepted scope.**",
      "dependencies": [
        "P06",
        "P09",
        "P10",
        "P11",
        "P12"
      ],
      "handoffs": [
        "P21"
      ]
    },
    {
      "protocol_id": "P14",
      "file": ".cursor/ai-driven-workflow/14-pre-deployment-staging.md",
      "title": "# PROTOCOL 14 : PRE-DEPLOYMENT VALIDATION & STAGING READINESS (RELEASE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `QUALITY-AUDIT-PACKAGE.zip` from Protocol 12 \u2013 audit readiness evidence\n- [ ] `integration-evidence-bundle.zip` from Protocol 11 \u2013 integration validation summary\n- [ ] `UAT-CLOSURE-PACKAGE.zip` from Protocol 13 \u2013 stakeholder acceptance proof\n- [ ] `.artifacts/pre-deployment/release-manifest.json` (initial draft) from Release Planning\n- [ ] Latest deployment scripts (`scripts/deploy_*.sh`, `scripts/rollback_*.sh`) from repository\n\n### Required Approvals\n- [ ] Quality Audit readiness recommendation signed by Senior Quality Engineer (Protocol 12)\n- [ ] Product Owner confirmation that release scope is fixed (Protocol 06)\n- [ ] Security and compliance lead clearance for staging deployment rehearsals\n\n### System State Requirements\n- [ ] Staging environment mirrors production configuration (infrastructure, secrets, feature flags)\n- [ ] Access to deployment automation credentials and secret stores for staging\n- [ ] Monitoring dashboards accessible for baseline capture\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Intake Validation and Staging Alignment\n\n1. **`[MUST]` Confirm Upstream Approvals:**\n   * **Action:** Validate required artifacts and approvals from Protocols 11, 12, and 13 before staging rehearsal begins.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Validating upstream approvals and artifact completeness...\"\n   * **Halt condition:** Stop if any prerequisite artifact missing or expired.\n   * **Evidence:** `.artifacts/pre-deployment/intake-validation-report.json` summarizing status.\n\n2. **`[MUST]` Validate Staging Parity:**\n   * **Action:** Compare staging vs production configurations, secrets, and infrastructure components for drift detection.\n   * **Communication:** \n     > \"[PHASE 1] Staging parity check underway. Reporting drift if detected...\"\n   * **Halt condition:** Pause if drift exists without remediation plan.\n   * **Evidence:** `.artifacts/pre-deployment/staging-parity-report.json` including diff details.\n\n3. **`[GUIDELINE]` Refresh Test Data & Feature Flags:**\n   * **Action:** Sync staging datasets, feature flags, and service stubs to align with release candidate requirements.\n   * **Example:**\n     ```bash\n     python scripts/refresh_staging_data.py --env staging --output .artifacts/pre-deployment/staging-data-refresh.md\n     ```\n\n### STEP 2: Deployment Rehearsal and Verification\n\n1. **`[MUST]` Execute Staging Deployment Rehearsal:**\n   * **Action:** Run deployment scripts in staging replicating production sequencing with logging enabled.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Rehearsing deployment on staging environment...\"\n   * **Halt condition:** Stop if automation fails or unexpected errors occur.\n   * **Evidence:** `.artifacts/pre-deployment/staging-deployment-run.log` capturing commands and results.\n\n2. **`[MUST]` Validate Smoke & Acceptance Tests:**\n   * **Action:** Execute smoke, end-to-end, and targeted regression suites against staging release candidate.\n   * **Communication:** \n     > \"[PHASE 2] Staging test suites executing. Monitoring pass/fail status...\"\n   * **Halt condition:** Pause if critical tests fail without mitigation.\n   * **Evidence:** `.artifacts/pre-deployment/staging-test-results.json` with coverage metrics.\n\n3. **`[GUIDELINE]` Capture Observability Baseline:**\n   * **Action:** Record monitoring dashboards and metrics post-rehearsal for Protocol 19 reference.\n   * **Example:**\n     ```markdown\n     - Metric: API latency (p95) \u2013 320ms\n     - Metric: Error rate \u2013 0.2%\n     ```\n\n### STEP 3: Rollback, Security, and Operational Readiness\n\n1. **`[MUST]` Rehearse Rollback Procedure:**\n   * **Action:** Execute rollback automation or blue/green switchback to validate recovery path.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Verifying rollback and recovery procedures...\"\n   * **Halt condition:** Stop if rollback fails or exceeds recovery time objective.\n   * **Evidence:** `.artifacts/pre-deployment/rollback-verification-report.json` detailing steps and timings.\n\n2. **`[MUST]` Complete Security & Compliance Checks:**\n   * **Action:** Run required security scans, license audits, and compliance validations pre-production.\n   * **Communication:** \n     > \"[PHASE 3] Executing security and compliance scans for release candidate...\"\n   * **Halt condition:** Pause if blocking findings identified.\n   * **Evidence:** `.artifacts/pre-deployment/security-compliance-report.json` with findings and approvals.\n\n3. **`[GUIDELINE]` Validate Runbooks & Support Coverage:**\n   * **Action:** Confirm operational runbooks, on-call rotations, and escalation matrices updated for release.\n   * **Example:**\n     ```markdown\n     - Runbook: api-service.md \u2013 updated 2024-05-30\n     - On-call: Primary SRE (Alex), Backup (Jordan)\n     ```\n\n### STEP 4: Final Readiness Review and Handoff\n\n1. **`[MUST]` Assemble Go/No-Go Package:**\n   * **Action:** Bundle parity report, deployment and rollback evidence, test results, and security findings into `PRE-DEPLOYMENT-PACKAGE.zip`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Compiling pre-deployment readiness package for release approval...\"\n   * **Halt condition:** Stop if package contents incomplete or checksum invalid.\n   * **Evidence:** `.artifacts/pre-deployment/pre-deployment-manifest.json` indexing artifacts.\n\n2. **`[MUST]` Conduct Readiness Review:**\n   * **Action:** Present findings to Release Manager and stakeholders; capture approvals, risks, and action items.\n   * **Communication:** \n     > \"[PHASE 4] Readiness review in progress. Recording decisions and risk mitigations...\"\n   * **Halt condition:** Pause if approvals withheld or risks unresolved.\n   * **Evidence:** `.artifacts/pre-deployment/readiness-approval.json` with signatures.\n\n3. **`[GUIDELINE]` Publish Deployment Checklist Updates:**\n   * **Action:** Update production deployment checklist and communication plan based on rehearsal learnings.\n   * **Example:**\n     ```bash\n     python scripts/update_deployment_checklist.py --source .artifacts/pre-deployment/staging-deployment-run.log --output .artifacts/pre-deployment/deployment-checklist.md\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT issue a production go/no-go package unless staging mirrors production configurations and both deployment and rollback procedures have been executed successfully with captured evidence.**",
      "dependencies": [
        "P06",
        "P11",
        "P12",
        "P13"
      ],
      "handoffs": [
        "P19"
      ]
    },
    {
      "protocol_id": "P15",
      "file": ".cursor/ai-driven-workflow/15-production-deployment.md",
      "title": "# PROTOCOL 15 : PRODUCTION DEPLOYMENT & RELEASE MANAGEMENT (RELIABILITY COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `PRE-DEPLOYMENT-PACKAGE.zip` from Protocol 14 \u2013 readiness evidence bundle\n- [ ] `readiness-approval.json` from Protocol 14 \u2013 stakeholder go decision\n- [ ] `rollback-verification-report.json` from Protocol 14 \u2013 validated rollback plan\n- [ ] `UAT-CLOSURE-PACKAGE.zip` from Protocol 13 \u2013 customer acceptance proof\n- [ ] Latest release manifest `.artifacts/pre-deployment/deployment-checklist.md`\n\n### Required Approvals\n- [ ] Executive sponsor or Product Owner authorization to deploy to production\n- [ ] SRE/Operations lead approval confirming monitoring coverage\n- [ ] Security lead sign-off if release includes security-impacting changes\n\n### System State Requirements\n- [ ] Production environment credentials available with MFA satisfied\n- [ ] Deployment automation scripts accessible (`scripts/deploy_*.sh`, `scripts/rollback_*.sh`)\n- [ ] Monitoring dashboards and alerting tools operational for health window\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Readiness Verification and Approval\n\n1. **`[MUST]` Validate Pre-Deployment Evidence:**\n   * **Action:** Confirm Protocol 21 and 15 artifacts are complete, current, and free of blocking issues.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Verifying deployment readiness artifacts...\"\n   * **Halt condition:** Stop if any prerequisite artifact missing or outdated.\n   * **Evidence:** `.artifacts/deployment/deployment-readiness-checklist.json` capturing status per artifact.\n\n2. **`[MUST]` Confirm Release Scope and Stakeholders:**\n   * **Action:** Review release manifest, impacted services, rollback procedures, and stakeholder list.\n   * **Communication:** \n     > \"[PHASE 1] Release scope and stakeholder confirmations underway...\"\n   * **Halt condition:** Pause if approvals list incomplete or scope unclear.\n   * **Evidence:** `.artifacts/deployment/release-manifest.md` annotated with confirmations.\n\n3. **`[GUIDELINE]` Schedule Deployment Window:**\n   * **Action:** Coordinate release window, communications, and on-call coverage.\n   * **Example:**\n     ```markdown\n     - Deployment window: 2024-06-01 02:00-04:00 UTC\n     - Communication channels: #release-war-room\n     - On-call: SRE (Alex), Product (Taylor)\n     ```\n\n### STEP 2: Staging Verification Confirmation\n\n1. **`[MUST]` Reconfirm Staging Health:**\n   * **Action:** Review Protocol 21 staging run logs and optionally rerun quick validation to ensure nothing drifted.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Reconfirming staging health prior to production launch...\"\n   * **Halt condition:** Stop if staging validation fails or environment drift detected.\n   * **Evidence:** `.artifacts/deployment/staging-validation-results.json` (refreshed if rerun).\n\n2. **`[MUST]` Freeze Change Window:**\n   * **Action:** Communicate code freeze start, lock deployment branch, and ensure no conflicting changes queued.\n   * **Communication:** \n     > \"[PHASE 2] Change freeze in effect. All teams acknowledge?\"\n   * **Halt condition:** Pause until freeze confirmed across stakeholders.\n   * **Evidence:** `.artifacts/deployment/change-freeze-confirmation.md` with acknowledgements.\n\n3. **`[GUIDELINE]` Conduct Final Dry Run:**\n   * **Action:** Execute dry-run of production scripts using `--dry-run` or staging flag to confirm command readiness.\n   * **Example:**\n     ```bash\n     bash scripts/deploy_backend.sh --env production --release ${TAG} --dry-run\n     ```\n\n### STEP 3: Production Deployment & Immediate Validation\n\n1. **`[MUST]` Request Production Approval:**\n   * **Action:** Present readiness checklist, staging evidence, and rollback plan to approvers; capture go/no-go decision.\n   * **Communication:** \n     > \"[APPROVAL REQUEST] All readiness gates passed. Approve production deployment? (yes/no)\"\n   * **Halt condition:** Do not continue without recorded approval.\n   * **Evidence:** `.artifacts/deployment/production-approval.json` with timestamps and approvers.\n\n2. **`[MUST]` Execute Production Deployment:**\n   * **Action:** Perform deployment according to rollout strategy (blue/green, canary, rolling) while logging commands.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Executing production deployment sequence...\"\n   * **Halt condition:** Trigger rollback if critical errors encountered.\n   * **Evidence:** `.artifacts/deployment/production-deployment-report.json` capturing actions and durations.\n\n3. **`[MUST]` Run Immediate Post-Deployment Checks:**\n   * **Action:** Execute smoke tests, health checks, and service verifications within minutes of deployment completion.\n   * **Communication:** \n     > \"[PHASE 3] Running post-deployment validation checks...\"\n   * **Halt condition:** Initiate rollback if checks fail beyond tolerances.\n   * **Evidence:** `.artifacts/deployment/post-deployment-validation.json` including metrics snapshot.\n\n4. **`[GUIDELINE]` Notify Stakeholders of Deployment Progress:**\n   * **Action:** Provide updates at key milestones (start, 50%, completion) in designated channels.\n   * **Example:**\n     ```markdown\n     [RAY ANNOUNCEMENT] Production deployment 50% complete. No errors observed. Next update in 10 minutes.\n     ```\n\n### STEP 4: Stabilization Window and Documentation\n\n1. **`[MUST]` Monitor Health Window:**\n   * **Action:** Track metrics during agreed soak period, documenting anomalies and decisions.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Monitoring post-deployment health window...\"\n   * **Halt condition:** Escalate to Protocol 20 if thresholds breached.\n   * **Evidence:** `.artifacts/deployment/deployment-health-log.md` summarizing observations.\n\n2. **`[MUST]` Compile Release Report:**\n   * **Action:** Consolidate readiness checklist, deployment logs, validation results, and monitoring data into `DEPLOYMENT-REPORT.md`.\n   * **Communication:** \n     > \"[PHASE 4] Compiling final release report and evidence bundle...\"\n   * **Halt condition:** Delay handoff until report and attachments complete.\n   * **Evidence:** `.artifacts/deployment/DEPLOYMENT-REPORT.md` plus zipped evidence package `DEPLOYMENT-EVIDENCE.zip`.\n\n3. **`[GUIDELINE]` Trigger Retrospective Inputs:**\n   * **Action:** Provide summary and improvement items to Protocol 22 and log follow-up actions.\n   * **Example:**\n     ```markdown\n     - Improvement: Automate canary rollback trigger thresholds\n     - Owner: Release Engineering\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT deploy to production without recorded staging success, stakeholder approval, and an executable rollback plan.**",
      "dependencies": [
        "P13",
        "P14"
      ],
      "handoffs": [
        "P20",
        "P21",
        "P22"
      ]
    },
    {
      "protocol_id": "P16",
      "file": ".cursor/ai-driven-workflow/16-monitoring-observability.md",
      "title": "# PROTOCOL 16 : POST-DEPLOYMENT MONITORING & OBSERVABILITY (SRE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `post-deployment-validation.json` from Protocol 15 \u2013 immediate health check results\n- [ ] `deployment-health-log.md` from Protocol 15 \u2013 stabilization observations\n- [ ] `DEPLOYMENT-REPORT.md` from Protocol 15 \u2013 release summary and risks\n- [ ] `staging-test-results.json` from Protocol 21 \u2013 baseline test data\n- [ ] Prior monitoring baselines `.artifacts/monitoring/baseline-metrics.json` (if available)\n\n### Required Approvals\n- [ ] Release Manager confirmation that production deployment completed successfully\n- [ ] SRE team lead authorization to adjust monitoring configuration\n- [ ] Security/compliance approval for alert thresholds impacting regulated services\n\n### System State Requirements\n- [ ] Production monitoring stack accessible (metrics, logs, traces, synthetics)\n- [ ] Alerting integrations (PagerDuty/Slack/Email) operational with test credentials\n- [ ] Write permissions to `.artifacts/monitoring/` and `.cursor/context-kit/`\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Instrumentation Alignment and Baseline Capture\n\n1. **`[MUST]` Review Deployment Outputs:**\n   * **Action:** Analyze Protocol 15 artifacts to identify monitoring requirements, risky components, and new endpoints.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Reviewing deployment evidence to map monitoring requirements...\"\n   * **Halt condition:** Stop if required deployment artifacts missing or inconsistent.\n   * **Evidence:** `.artifacts/monitoring/monitoring-requirements.md` summarizing KPIs, SLOs, and risk items.\n\n2. **`[MUST]` Verify Instrumentation Coverage:**\n   * **Action:** Ensure metrics, logs, traces, and synthetic checks cover all critical services introduced or modified.\n   * **Communication:** \n     > \"[PHASE 1] Validating instrumentation coverage across services and dependencies...\"\n   * **Halt condition:** Pause if any critical service lacks telemetry coverage.\n   * **Evidence:** `.artifacts/monitoring/instrumentation-audit.json` listing coverage status per service.\n\n3. **`[GUIDELINE]` Capture Baseline Snapshot:**\n   * **Action:** Record baseline metrics immediately after deployment for reference.\n   * **Example:**\n     ```bash\n     python scripts/collect_perf.py --env production --output .artifacts/monitoring/baseline-metrics.json\n     ```\n\n### STEP 2: Monitoring Activation and Alert Validation\n\n1. **`[MUST]` Configure Dashboards and Alerts:**\n   * **Action:** Update dashboards, alert rules, and SLO dashboards to reflect latest release changes.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Activating dashboards and alert policies...\"\n   * **Halt condition:** Stop if dashboards fail validation or alerts missing thresholds.\n   * **Evidence:** `.artifacts/monitoring/dashboard-config.md` with links and thresholds.\n\n2. **`[MUST]` Test Alert Paths:**\n   * **Action:** Trigger synthetic incidents to confirm alert delivery, escalation, and acknowledgment.\n   * **Communication:** \n     > \"[PHASE 2] Triggering synthetic alerts to confirm notification pathways...\"\n   * **Halt condition:** Halt if alerts fail to reach on-call or acknowledgement outside SLA.\n   * **Evidence:** `.artifacts/monitoring/alert-test-results.json` capturing timestamps and response times.\n\n3. **`[GUIDELINE]` Update Runbooks:**\n   * **Action:** Document new detection signals and mitigation steps in incident runbooks.\n   * **Example:**\n     ```markdown\n     ### Updated Signals\n     - Alert: API latency > 500ms (5m)\n     - Response: Scale API pods + purge CDN cache\n     ```\n\n### STEP 3: Continuous Observability Assurance\n\n1. **`[MUST]` Schedule Ongoing Checks:**\n   * **Action:** Define automated cadence for verifying monitoring assets (dashboards, alerts, synthetic runs).\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Scheduling ongoing observability validation tasks...\"\n   * **Halt condition:** Pause if automation cannot be scheduled or lacks ownership.\n   * **Evidence:** `.artifacts/monitoring/observability-schedule.json` documenting cadence and owners.\n\n2. **`[MUST]` Correlate Alerts with Incidents:**\n   * **Action:** Compare recent alerts to incident tickets, adjust thresholds for noise or missed detections.\n   * **Communication:** \n     > \"[PHASE 3] Correlating recent alerts with incident history to tune thresholds...\"\n   * **Halt condition:** Stop if correlation reveals unresolved monitoring gaps.\n   * **Evidence:** `.artifacts/monitoring/alert-tuning-report.md` summarizing adjustments.\n\n3. **`[GUIDELINE]` Publish Observability Scorecard:**\n   * **Action:** Create summary of SLO attainment, alert precision, and outstanding risks for leadership review.\n   * **Example:**\n     ```markdown\n     | Metric | Target | Actual | Status |\n     |--------|--------|--------|--------|\n     | Alert Precision | \u2265 85% | 87% | \u2705 |\n     ```\n\n### STEP 4: Handoff and Improvement Loop\n\n1. **`[MUST]` Deliver Monitoring Package:**\n   * **Action:** Bundle instrumentation audit, dashboard configuration, alert results, and schedule into `MONITORING-PACKAGE.zip`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Delivering monitoring package to incident response and retrospective owners...\"\n   * **Halt condition:** Halt if package incomplete or checksum invalid.\n   * **Evidence:** `.artifacts/monitoring/monitoring-package-manifest.json` plus zipped bundle.\n\n2. **`[MUST]` Record Approval and Ownership:**\n   * **Action:** Document SRE approval, on-call rotation owners, and effective date for monitoring configuration.\n   * **Communication:** \n     > \"[PHASE 4] Recording monitoring ownership and approvals...\"\n   * **Halt condition:** Pause if approvals missing or outdated.\n   * **Evidence:** `.artifacts/monitoring/monitoring-approval-record.json`.\n\n3. **`[GUIDELINE]` Queue Improvement Actions:**\n   * **Action:** Log backlog items for instrumentation gaps or automation enhancements discovered.\n   * **Example:**\n     ```markdown\n     - Task: Automate alert noise suppression for service XYZ\n     - Owner: Observability Guild\n     - Due: Next release cycle\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT declare monitoring complete until alerting rules, dashboards, and runbooks have been validated against live production telemetry for the current release.**",
      "dependencies": [
        "P15",
        "P21"
      ],
      "handoffs": [
        "P15"
      ]
    },
    {
      "protocol_id": "P17",
      "file": ".cursor/ai-driven-workflow/17-incident-response-rollback.md",
      "title": "# PROTOCOL 17: INCIDENT RESPONSE & ROLLBACK (OPERATIONS RESILIENCE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute INCIDENT RESPONSE & ROLLBACK workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `MONITORING-PACKAGE.zip` from Protocol 16 \u2013 monitoring configuration and validation evidence\n- [ ] `alert-test-results.json` from Protocol 16 \u2013 alert routing baseline\n- [ ] `production-deployment-report.json` from Protocol 15 \u2013 deployment context\n- [ ] `rollback-verification-report.json` from Protocol 14 \u2013 rollback rehearsal evidence\n- [ ] `incident-playbook.md` (if available) from `.cursor/context-kit/`\n\n### Required Approvals\n- [ ] Incident commander/on-call authority to declare incident state\n- [ ] Release Manager acknowledgement of potential rollback impact\n- [ ] Security/compliance approval if incident involves regulated data or customer notification\n\n### System State Requirements\n- [ ] Access to production monitoring dashboards and alerting tools\n- [ ] Privileged credentials available for executing rollback or mitigation scripts\n- [ ] Communication channels (war-room bridge, incident Slack channel) active\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Detection and Severity Assessment\n\n1. **`[MUST]` Monitor Active Alerts:**\n   * **Action:** Continuously ingest alerts and dashboards from Protocol 19 outputs to detect incidents.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Monitoring production alerts for incident signals...\"\n   * **Halt condition:** Pause progression until alert validity confirmed (false positive vs real incident).\n   * **Evidence:** `.artifacts/incidents/incident-intake-log.md` capturing alert details and timestamps.\n\n2. **`[MUST]` Classify Incident Severity:**\n   * **Action:** Determine severity (SEV-1/2/3) based on SLO breaches, customer impact, and blast radius.\n   * **Communication:** \n     > \"[PHASE 1] Assessing incident severity and affected services...\"\n   * **Halt condition:** Stop until severity consensus reached among responders.\n   * **Evidence:** `.artifacts/incidents/severity-assessment.json` documenting rationale.\n\n3. **`[GUIDELINE]` Notify Stakeholders:**\n   * **Action:** Trigger communication plan (PagerDuty, Slack, email) based on severity.\n   * **Example:**\n     ```markdown\n     - Channel: #incident-sev1\n     - Stakeholders: SRE On-call, Product Owner, Support Lead\n     ```\n\n### STEP 2: Containment and Mitigation Planning\n\n1. **`[MUST]` Identify Mitigation Options:**\n   * **Action:** Consult monitoring runbooks and rollback plan to propose mitigation (rollback, feature flag, hotfix).\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Identifying mitigation strategy for incident containment...\"\n   * **Halt condition:** Pause if mitigation options unclear or dependencies unknown.\n   * **Evidence:** `.artifacts/incidents/mitigation-plan.md` enumerating options and risks.\n\n2. **`[MUST]` Validate Rollback Feasibility:**\n   * **Action:** Confirm rollback scripts, data backups, and prerequisites from Protocols 10 and 11 are ready.\n   * **Communication:** \n     > \"[PHASE 2] Validating rollback readiness and dependencies...\"\n   * **Halt condition:** Stop if rollback prerequisites unmet.\n   * **Evidence:** `.artifacts/incidents/rollback-readiness-checklist.json` with verification results.\n\n3. **`[GUIDELINE]` Align Decision Makers:**\n   * **Action:** Present options to incident commander and stakeholders for approval, capturing decision timestamp.\n   * **Example:**\n     ```markdown\n     Decision: Execute rollback_backend.sh\n     Approved by: Incident Commander (Alex), Release Manager (Jordan)\n     Time: 02:34 UTC\n     ```\n\n### STEP 3: Execution and Recovery Validation\n\n1. **`[MUST]` Execute Mitigation or Rollback:**\n   * **Action:** Run approved mitigation commands with full logging and change management adherence.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Executing approved mitigation/rollback actions...\"\n   * **Halt condition:** Halt sequence if scripts fail or produce unexpected results.\n   * **Evidence:** `.artifacts/incidents/mitigation-execution-report.json` including command outputs.\n\n2. **`[MUST]` Validate System Recovery:**\n   * **Action:** Run smoke tests, health checks, and user journeys to confirm system stability.\n   * **Communication:** \n     > \"[PHASE 3] Validating post-mitigation system health...\"\n   * **Halt condition:** If validation fails, re-enter mitigation planning.\n   * **Evidence:** `.artifacts/incidents/recovery-validation.json` summarizing results.\n\n3. **`[GUIDELINE]` Maintain Incident Timeline:**\n   * **Action:** Update timeline with key events, commands, and communications.\n   * **Example:**\n     ```markdown\n     02:10 UTC - Alert triggered (API latency > 800ms)\n     02:25 UTC - Rollback initiated\n     02:32 UTC - Recovery validation passed\n     ```\n\n### STEP 4: Resolution, Documentation, and Handoff\n\n1. **`[MUST]` Confirm Incident Resolution:**\n   * **Action:** Verify SLO/SLA restored, alerts cleared, and stakeholders informed.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Confirming incident resolution and notifying stakeholders...\"\n   * **Halt condition:** Do not close incident until metrics stable and communications sent.\n   * **Evidence:** `.artifacts/incidents/resolution-summary.json` with final status.\n\n2. **`[MUST]` Capture Root Cause Inputs:**\n   * **Action:** Archive logs, dashboards, diffs, and contributing factors for postmortem.\n   * **Communication:** \n     > \"[PHASE 4] Capturing root cause evidence for retrospective...\"\n   * **Halt condition:** Halt closure if critical evidence missing.\n   * **Evidence:** `.artifacts/incidents/rca-manifest.json` indexing stored artifacts.\n\n3. **`[GUIDELINE]` Generate Incident Report Draft:**\n   * **Action:** Summarize severity, timeline, actions, and next steps in `INCIDENT-REPORT.md` for Protocol 22.\n   * **Example:**\n     ```markdown\n     ## Summary\n     - Severity: SEV-1\n     - Duration: 27 minutes\n     - Resolution: Rollback to release v1.2.3\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT perform rollback actions without confirming incident severity, affected scope, and stakeholder alignment on recovery strategy.**",
      "dependencies": [
        "P14",
        "P15",
        "P16"
      ],
      "handoffs": [
        "P19",
        "P22"
      ]
    },
    {
      "protocol_id": "P18",
      "file": ".cursor/ai-driven-workflow/18-performance-optimization.md",
      "title": "# PROTOCOL 18 : PERFORMANCE OPTIMIZATION & TUNING (PERFORMANCE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `MONITORING-PACKAGE.zip` from Protocol 16 \u2013 monitoring dashboards and alert configuration\n- [ ] `INCIDENT-REPORT.md` from Protocol 17 (if available) \u2013 recent incident context impacting performance\n- [ ] `performance-intake-backlog.json` from previous cycles (if available) \u2013 outstanding performance actions\n- [ ] `baseline-metrics.json` from previous optimization cycles (if available)\n- [ ] Latest deployment notes `DEPLOYMENT-REPORT.md` from Protocol 15\n\n### Required Approvals\n- [ ] Product Owner prioritization of performance objectives for this cycle\n- [ ] SRE lead approval for executing load/stress tests in target environments\n- [ ] Security/compliance clearance for profiling and data sampling activities\n\n### System State Requirements\n- [ ] Access to production telemetry tools (APM, logging, tracing)\n- [ ] Load testing environment configured to mirror production scale\n- [ ] Write permissions to `.artifacts/performance/` and `.cursor/context-kit/`\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Intake, Baseline, and Hypothesis Framing\n\n1. **`[MUST]` Collect Telemetry Inputs:**\n   * **Action:** Aggregate monitoring dashboards (Protocol 19), incident timelines (Protocol 20), and deployment notes (Protocol 15) to identify performance pain points.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Consolidating telemetry and incident evidence for performance triage...\"\n   * **Halt condition:** Pause if critical telemetry or incident data unavailable.\n   * **Evidence:** `.artifacts/performance/performance-intake-report.json` summarizing metrics, alerts, and business impact.\n\n2. **`[MUST]` Establish Baseline Metrics:**\n   * **Action:** Capture current SLO/SLA values, throughput, latency, error rates, and resource utilization for impacted services.\n   * **Communication:** \n     > \"[PHASE 1] Baseline capture in progress. Documenting SLO adherence and bottlenecks...\"\n   * **Halt condition:** Halt if baselines lack required sources or verification.\n   * **Evidence:** `.artifacts/performance/baseline-metrics.csv` with collection methodology.\n\n3. **`[GUIDELINE]` Formulate Hypotheses:**\n   * **Action:** Draft hypotheses linking observed symptoms to root causes (code hot paths, database contention, infra limits).\n   * **Example:**\n     ```markdown\n     - Hypothesis: Cache miss rate causes elevated DB load during checkout\n     - Validation: Review Redis hit ratio + profile checkout API\n     ```\n\n### STEP 2: Diagnostics and Load Simulation\n\n1. **`[MUST]` Profile Critical Transactions:**\n   * **Action:** Run profilers, tracing, and database analysis to identify bottlenecks for prioritized services.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Profiling critical transactions across services...\"\n   * **Halt condition:** Pause if profiling data inconclusive or missing key components.\n   * **Evidence:** `.artifacts/performance/profiling-report.md` including flame graphs and query plans.\n\n2. **`[MUST]` Execute Load & Stress Tests:**\n   * **Action:** Perform load tests replicating peak workloads and failure scenarios informed by deployment/monitoring data.\n   * **Communication:** \n     > \"[PHASE 2] Executing load scenarios to validate capacity and resilience...\"\n   * **Halt condition:** Stop if environment unstable or results show regressions requiring mitigation.\n   * **Evidence:** `.artifacts/performance/load-test-results.json` capturing throughput, latency percentiles, and errors.\n\n3. **`[GUIDELINE]` Analyze Capacity & Cost:**\n   * **Action:** Evaluate infrastructure utilization, scaling policies, and cost impact of potential optimizations.\n   * **Example:**\n     ```markdown\n     - Current CPU Utilization (p95): 82%\n     - Scaling Policy Change: Increase min replicas from 6 \u2192 8\n     ```\n\n### STEP 3: Optimization Implementation and Verification\n\n1. **`[MUST]` Define Optimization Plan:**\n   * **Action:** Translate findings into prioritized optimization tasks with owners, risk assessment, and expected impact.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Publishing optimization backlog with ownership and risk notes...\"\n   * **Halt condition:** Pause if plan lacks approvals or dependencies unresolved.\n   * **Evidence:** `.artifacts/performance/optimization-plan.json` with tasks and expected gains.\n\n2. **`[MUST]` Implement and Validate Changes:**\n   * **Action:** Coordinate with Protocol 21 teams to implement optimizations, then rerun targeted tests confirming improvements.\n   * **Communication:** \n     > \"[PHASE 3] Validating optimization changes against baseline metrics...\"\n   * **Halt condition:** Halt if validation reveals regressions or insufficient gains.\n   * **Evidence:** `.artifacts/performance/optimization-validation-report.json` comparing before/after metrics.\n\n3. **`[GUIDELINE]` Update Instrumentation:**\n   * **Action:** Ensure monitoring dashboards, alerts, and tracing reflect new performance expectations.\n   * **Example:**\n     ```markdown\n     - Dashboard update: Added p95 latency panel for /checkout endpoint\n     - Alert: Adjusted latency threshold from 600ms \u2192 450ms\n     ```\n\n### STEP 4: Governance, Communication, and Handoff\n\n1. **`[MUST]` Record SLO Adjustments:**\n   * **Action:** Document updated SLO targets, alert thresholds, and escalation policies impacted by optimizations.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Documenting SLO updates and communicating performance improvements...\"\n   * **Halt condition:** Stop if approvals missing for SLO changes.\n   * **Evidence:** `.artifacts/performance/slo-update-record.json` with sign-offs.\n\n2. **`[MUST]` Publish Performance Report:**\n   * **Action:** Compile intake summary, diagnostics, optimization actions, and validation results into `PERFORMANCE-REPORT.md`.\n   * **Communication:** \n     > \"[PHASE 4] Publishing performance report and distributing to stakeholders...\"\n   * **Halt condition:** Halt if report incomplete or evidence missing.\n   * **Evidence:** `.artifacts/performance/performance-report-manifest.json` referencing attachments.\n\n3. **`[GUIDELINE]` Feed Continuous Improvement Loop:**\n   * **Action:** Share recommendations with Protocol 22 and Protocol 19 for ongoing monitoring enhancements.\n   * **Example:**\n     ```markdown\n     - Action: Automate load-test regression suite weekly\n     - Consumer: Protocol 19 Observability Team\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT deploy performance changes without reproducible benchmarking evidence and updated SLO instrumentation demonstrating improvement under expected peak load.**",
      "dependencies": [
        "P15",
        "P16",
        "P17"
      ],
      "handoffs": [
        "P15",
        "P19",
        "P20",
        "P21",
        "P22"
      ]
    },
    {
      "protocol_id": "P19",
      "file": ".cursor/ai-driven-workflow/19-documentation-knowledge-transfer.md",
      "title": "# PROTOCOL 19 : DOCUMENTATION & KNOWLEDGE TRANSFER (KNOWLEDGE MANAGEMENT COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `FINAL-PRD.md` from Protocol 06 \u2013 authoritative product requirements\n- [ ] `architecture-decision-log.json` from Protocol 07 \u2013 consolidated architecture reasoning\n- [ ] `SPRINT-IMPLEMENTATION-NOTES.md` from Protocol 10 \u2013 development insights and caveats\n- [ ] `INTEGRATION-VALIDATION-REPORT.zip` from Protocol 11 \u2013 cross-system validation evidence\n- [ ] `QUALITY-AUDIT-PACKAGE.zip` from Protocol 12 \u2013 audit findings and recommendations\n- [ ] `PRODUCTION-DEPLOYMENT-REPORT.json` from Protocol 15 \u2013 release outcomes and approvals\n- [ ] `OBSERVABILITY-BASELINE.md` from Protocol 16 \u2013 monitoring dashboards and metrics\n- [ ] `INCIDENT-POSTMORTEMS/` from Protocol 17 \u2013 recent incident analyses (if available)\n- [ ] `PERFORMANCE-INSIGHTS.md` from Protocol 18 \u2013 optimization results and targets (if available)\n- [ ] `UAT-FEEDBACK.csv` from Protocol 13 \u2013 stakeholder feedback and outstanding actions\n\n### Required Approvals\n- [ ] Product Owner sign-off confirming scope completeness\n- [ ] Engineering Lead approval of technical accuracy for documentation\n- [ ] Support & Operations leadership approval for knowledge base publication\n\n### System State Requirements\n- [ ] Access to documentation repositories (`docs/`, knowledge base portals)\n- [ ] Collaboration tools configured for review routing (e.g., Confluence, Notion, Teams)\n- [ ] Recording tools authorized for knowledge-transfer sessions\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Source Consolidation & Audience Alignment\n\n1. **`[MUST]` Inventory Knowledge Inputs:**\n   * **Action:** Compile all upstream artifacts, version them, and log freshness status for each knowledge source.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Beginning knowledge source inventory for Protocol 19. Confirming artifact freshness...\"\n   * **Halt condition:** Stop if any prerequisite artifact is missing or obsolete.\n   * **Evidence:** `.artifacts/protocol-19/source-inventory.json` listing artifact name, path, owner, and last-reviewed date.\n\n2. **`[MUST]` Define Documentation Personas & Needs:**\n   * **Action:** Map required deliverables, formats, and acceptance criteria for engineering, operations, support, compliance, and client stakeholders.\n   * **Communication:** \n     > \"[PHASE 1] Documenting consumer personas and their required knowledge assets...\"\n   * **Halt condition:** Pause if any persona lacks defined deliverables or acceptance criteria.\n   * **Evidence:** `.artifacts/protocol-19/audience-requirements.csv` capturing persona \u2192 deliverable mappings.\n\n3. **`[GUIDELINE]` Establish Documentation Production Timeline:**\n   * **Action:** Publish milestone plan covering drafting, peer review, approvals, and publication windows.\n   * **Example:**\n     ```markdown\n     - Milestone: Draft system overview \u2013 Due 2024-05-15 \u2013 Owner: Tech Writer\n     - Milestone: Support runbook review \u2013 Due 2024-05-18 \u2013 Owner: Support Lead\n     ```\n\n### STEP 2: Draft Creation & Knowledge Capture\n\n1. **`[MUST]` Produce Structured Documentation Drafts:**\n   * **Action:** Author or update system overview, API guides, deployment runbooks, troubleshooting FAQs, and compliance checklists using approved templates.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Drafting documentation set across technical and operational domains...\"\n   * **Halt condition:** Halt if required template fields remain unfilled or conflicting source data emerges.\n   * **Evidence:** `.artifacts/protocol-19/draft-index.json` referencing each draft path and version tag.\n\n2. **`[MUST]` Capture Knowledge Transfer Sessions:**\n   * **Action:** Schedule and record walkthroughs with engineering, QA, operations, and support leads capturing tacit knowledge.\n   * **Communication:** \n     > \"[PHASE 2] Facilitating knowledge transfer session. Recording insights and action items...\"\n   * **Halt condition:** Stop if critical SMEs are unavailable or session recordings fail.\n   * **Evidence:** `.artifacts/protocol-19/kt-session-log.md` with attendee list, questions, and recording links.\n\n3. **`[GUIDELINE]` Enrich Deliverables with Visuals and Examples:**\n   * **Action:** Integrate diagrams, code snippets, CLI commands, and sample payloads to boost comprehension.\n   * **Example:**\n     ```bash\n     python scripts/export_sequence_diagrams.py --source architecture-decision-log.json --output docs/media/\n     ```\n\n### STEP 3: Review, Validation & Approval\n\n1. **`[MUST]` Execute Multi-Disciplinary Review Cycle:**\n   * **Action:** Route drafts to designated reviewers, track comments, ensure remediation, and secure approvals.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Initiating cross-functional documentation review. Awaiting approvals...\"\n   * **Halt condition:** Pause until all assigned reviewers sign off or waive.\n   * **Evidence:** `.artifacts/protocol-19/review-tracker.csv` containing reviewer, status, decision date, and notes.\n\n2. **`[MUST]` Validate Documentation Accuracy:**\n   * **Action:** Cross-check docs against repositories, infrastructure manifests, monitoring dashboards, and incident records to confirm accuracy.\n   * **Communication:** \n     > \"[PHASE 3] Running accuracy validation across source systems...\"\n   * **Halt condition:** Halt if discrepancies exist without remediation plan.\n   * **Evidence:** `.artifacts/protocol-19/validation-report.json` summarizing findings and resolutions.\n\n3. **`[GUIDELINE]` Perform Style & Accessibility Checks:**\n   * **Action:** Run terminology linting, readability scoring, and accessibility audits on published formats.\n   * **Example:**\n     ```bash\n     python scripts/check_doc_style.py --input docs/ --output .artifacts/protocol-19/style-audit.json\n     ```\n\n### STEP 4: Publication & Enablement\n\n1. **`[MUST]` Publish and Distribute Final Package:**\n   * **Action:** Release approved materials to knowledge portals, confirm permissions, and notify stakeholders.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 4 START] - Publishing documentation package and confirming access controls...\"\n   * **Halt condition:** Pause if publication automation fails or access tests fail.\n   * **Evidence:** `.artifacts/protocol-19/publication-manifest.json` detailing locations, versions, and access status.\n\n2. **`[MUST]` Deliver Knowledge Transfer Enablement:**\n   * **Action:** Conduct enablement sessions, capture attendance, and record follow-up actions for downstream teams.\n   * **Communication:** \n     > \"[PHASE 4] Conducted enablement workshop. Logging attendance and action items...\"\n   * **Halt condition:** Stop if attendance below threshold or critical questions unresolved.\n   * **Evidence:** `.artifacts/protocol-19/enablement-summary.md` including participants, topics, decisions.\n\n3. **`[GUIDELINE]` Capture Feedback & Continuous Improvement Backlog:**\n   * **Action:** Aggregate feedback, outstanding gaps, and future updates for maintenance planning.\n   * **Example:**\n     ```json\n     {\n       \"source\": \"Support Enablement\",\n       \"request\": \"Add troubleshooting tree for API timeouts\",\n       \"owner\": \"Support Lead\",\n       \"target_protocol\": 18\n     }\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] NEVER declare documentation complete until every downstream consumer has confirmed access to approved materials and critical knowledge gaps have zero open issues.**",
      "dependencies": [
        "P06",
        "P07",
        "P10",
        "P11",
        "P12",
        "P13",
        "P15",
        "P16",
        "P17",
        "P18"
      ],
      "handoffs": [
        "P19"
      ]
    },
    {
      "protocol_id": "P20",
      "file": ".cursor/ai-driven-workflow/20-project-closure.md",
      "title": "# PROTOCOL 20 : PROJECT CLOSURE & HANDOVER (PROGRAM GOVERNANCE COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `DOCUMENTATION-PACKAGE.zip` from Protocol 19 \u2013 finalized knowledge assets\n- [ ] `ENABLEMENT-ACCESS-LOG.csv` from Protocol 19 \u2013 stakeholder enablement confirmation\n- [ ] `PROJECT-DELIVERABLE-REGISTER.xlsx` from Program PMO \u2013 consolidated deliverable list\n- [ ] `FINAL-DEPLOYMENT-REPORT.json` from Protocol 15 \u2013 release acceptance and production health\n- [ ] `SLA-BASELINE.md` from Protocol 19 \u2013 operational performance baselines\n- [ ] `INCIDENT-POSTMORTEMS/` from Protocol 20 \u2013 outstanding corrective actions\n- [ ] `PERFORMANCE-IMPROVEMENT-BACKLOG.json` from Protocol 21 \u2013 optimization commitments\n- [ ] `MAINTENANCE-PLAN-DRAFT.md` from Protocol 21 (if pre-populated) \u2013 support plan considerations\n- [ ] `FINANCIAL-CLOSEOUT-REPORT.pdf` from Finance \u2013 budget reconciliation and remaining funds\n\n### Required Approvals\n- [ ] Executive Sponsor acceptance of final deliverables\n- [ ] Product Owner approval of release readiness\n- [ ] Operations Director approval for transition to steady state support\n- [ ] Legal/Compliance sign-off for contractual obligations\n\n### System State Requirements\n- [ ] Access to project portfolio management tool for status updates\n- [ ] All project tasks in task tracker marked completed or deferred with approvals\n- [ ] Communication channels open for final stakeholder notifications\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Closure Intake & Deliverable Validation\n\n1. **`[MUST]` Verify Closure Prerequisites:**\n   * **Action:** Confirm receipt and validity of all upstream artifacts, approvals, and outstanding actions.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Validating closure prerequisites and deliverable readiness...\"\n   * **Halt condition:** Stop if any required artifact or approval is missing.\n   * **Evidence:** `.artifacts/protocol-20/closure-prerequisite-checklist.json` with validation results.\n\n2. **`[MUST]` Audit Deliverable Register:**\n   * **Action:** Cross-reference deliverable register with final documentation and deployment evidence to ensure completion.\n   * **Communication:** \n     > \"[PHASE 1] Auditing deliverable register for completion status...\"\n   * **Halt condition:** Pause if deliverables are incomplete or lack acceptance evidence.\n   * **Evidence:** `.artifacts/protocol-20/deliverable-audit-log.csv` capturing status per deliverable.\n\n3. **`[GUIDELINE]` Review Financial & Contractual Status:**\n   * **Action:** Validate budget closure, invoice status, and contractual obligations.\n   * **Example:**\n     ```markdown\n     - Contract Clause 4.3 \u2013 Warranty support confirmed by Legal on 2024-05-20\n     - Budget variance: +2% under plan (Finance closeout report)\n     ```\n\n### STEP 2: Stakeholder Acceptance & Transition Planning\n\n1. **`[MUST]` Facilitate Final Acceptance Reviews:**\n   * **Action:** Convene acceptance meeting with sponsor, product owner, operations, and support leads; capture decisions.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Hosting final acceptance review. Recording approvals and outstanding actions...\"\n   * **Halt condition:** Stop if any stakeholder withholds approval.\n   * **Evidence:** `.artifacts/protocol-20/acceptance-minutes.md` with attendees, decisions, action items.\n\n2. **`[MUST]` Confirm Operational Ownership Transfer:**\n   * **Action:** Document owning teams, SLAs, and escalation paths; verify support readiness using enablement evidence.\n   * **Communication:** \n     > \"[PHASE 2] Confirming operational ownership and support readiness...\"\n   * **Halt condition:** Pause if ownership assignments incomplete or SLAs undefined.\n   * **Evidence:** `.artifacts/protocol-20/operational-handover-record.json` mapping services to owners and SLAs.\n\n3. **`[GUIDELINE]` Plan Celebration & Recognition Activities:**\n   * **Action:** Coordinate recognition communications or events acknowledging team contributions.\n   * **Example:**\n     ```markdown\n     - Recognition email drafted for executive sponsor approval by 2024-05-22\n     ```\n\n### STEP 3: Governance Closure & Archive Preparation\n\n1. **`[MUST]` Close Project Governance Artifacts:**\n   * **Action:** Update project portfolio tools, close tasks/issues, archive documentation, and set permissions to maintenance state.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Closing governance artifacts and archiving project documentation...\"\n   * **Halt condition:** Halt if any governance item remains open without disposition.\n   * **Evidence:** `.artifacts/protocol-20/governance-closure-report.json` summarizing updates.\n\n2. **`[MUST]` Prepare Handover Package for Support:**\n   * **Action:** Assemble curated package containing documentation, SLAs, runbooks, and outstanding risk registers.\n   * **Communication:** \n     > \"[PHASE 3] Packaging closure evidence for support handover...\"\n   * **Halt condition:** Pause if package inventory incomplete.\n   * **Evidence:** `.artifacts/protocol-20/handover-package-index.json` listing contents and recipients.\n\n3. **`[GUIDELINE]` Capture Closure Metrics & Lessons:**\n   * **Action:** Record closure KPIs (budget variance, schedule adherence, satisfaction scores) for retrospective.\n   * **Example:**\n     ```json\n     {\n       \"metric\": \"Stakeholder satisfaction\",\n       \"value\": 4.6,\n       \"target\": 4.5\n     }\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT close the project until every contractual deliverable, financial obligation, and operational handover item has signed approval and recorded evidence.**",
      "dependencies": [
        "P15",
        "P19",
        "P20",
        "P21"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P21",
      "file": ".cursor/ai-driven-workflow/21-maintenance-support.md",
      "title": "# PROTOCOL 21 : CONTINUOUS MAINTENANCE & SUPPORT PLANNING (SERVICE RELIABILITY COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `CLOSURE-PACKAGE.zip` from Protocol 20 \u2013 curated operational handover assets\n- [ ] `operational-handover-record.json` from Protocol 20 \u2013 ownership assignments and SLAs\n- [ ] `knowledge-transfer-feedback.json` from Protocol 19 \u2013 open knowledge gaps and follow-ups\n- [ ] `OBSERVABILITY-BASELINE.md` from Protocol 19 \u2013 monitoring dashboards and alert thresholds\n- [ ] `INCIDENT-POSTMORTEMS/` from Protocol 17 \u2013 outstanding corrective actions (if available)\n- [ ] `PERFORMANCE-IMPROVEMENT-BACKLOG.json` (initialize as empty template) \u2013 optimization work queue to be populated\n- [ ] `TECH-DEBT-REGISTER.md` from Protocol 10 \u2013 backlog of technical debt items identified during development\n- [ ] `SECURITY-RISK-LOG.csv` from Security Review \u2013 active security obligations\n- [ ] `SERVICE-CATALOG.xlsx` from Operations \u2013 service inventory and dependencies\n\n### Required Approvals\n- [ ] Operations Director endorsement of maintenance planning scope\n- [ ] Support Lead confirmation of staffing and coverage model\n- [ ] Product Owner acknowledgement of ongoing enhancement priorities\n- [ ] Security Lead approval of remediation commitments\n\n### System State Requirements\n- [ ] Access to monitoring, ticketing, and knowledge base platforms\n- [ ] Support tooling configured for escalation paths and runbook references\n- [ ] Service level objective dashboards accessible for ongoing measurement\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Intake & Operational Readiness Assessment\n\n1. **`[MUST]` Validate Handover Completeness:**\n   * **Action:** Inspect handover package, ownership records, and knowledge gaps to confirm operational readiness.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Reviewing handover package and operational assignments for maintenance planning...\"\n   * **Halt condition:** Stop if any critical artifact missing or ownership assignment unclear.\n   * **Evidence:** `.artifacts/protocol-21/handover-validation-report.json` summarizing completeness checks.\n\n2. **`[MUST]` Assess Operational Baselines:**\n   * **Action:** Review observability baselines, SLA metrics, and incident history to identify risk areas.\n   * **Communication:** \n     > \"[PHASE 1] Assessing operational baselines and historic incidents...\"\n   * **Halt condition:** Pause if baseline metrics unavailable or outdated.\n   * **Evidence:** `.artifacts/protocol-21/operational-baseline-analysis.md` with findings.\n\n3. **`[GUIDELINE]` Align Support Model with Demand Forecast:**\n   * **Action:** Estimate ticket volume, coverage requirements, and staffing rotation using historic data.\n   * **Example:**\n     ```python\n     from maintenance.forecast import forecast_ticket_volume\n     forecast_ticket_volume(input_path=\".artifacts/protocol-21/ticket-history.csv\",\n                            output_path=\".artifacts/protocol-21/support-coverage-plan.json\")\n     ```\n\n### STEP 2: Maintenance Backlog Formation & Prioritization\n\n1. **`[MUST]` Consolidate Maintenance Backlog:**\n   * **Action:** Merge technical debt, incident remediation, security risks, and performance backlog into a unified tracker.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Consolidating maintenance backlog from cross-protocol sources...\"\n   * **Halt condition:** Halt if backlog items lack ownership or severity ratings.\n   * **Evidence:** `.artifacts/protocol-21/maintenance-backlog.csv` with priority, owner, due date.\n\n2. **`[MUST]` Prioritize Remediation & Enhancement Streams:**\n   * **Action:** Apply risk, impact, and effort scoring to backlog items; align with SLA and compliance requirements.\n   * **Communication:** \n     > \"[PHASE 2] Prioritizing maintenance items based on risk and business impact...\"\n   * **Halt condition:** Pause if prioritization conflicts unresolved with stakeholders.\n   * **Evidence:** `.artifacts/protocol-21/backlog-prioritization-matrix.json` with scoring rationale.\n\n3. **`[GUIDELINE]` Establish Automation Opportunities:**\n   * **Action:** Identify tasks suitable for runbook automation or self-healing workflows.\n   * **Example:**\n     ```bash\n     python scripts/discover_automation_candidates.py --input .artifacts/protocol-21/maintenance-backlog.csv \\\n       --output .artifacts/protocol-21/automation-candidates.json\n     ```\n\n### STEP 3: Maintenance Plan Finalization & Governance Setup\n\n1. **`[MUST]` Draft Maintenance & Support Plan:**\n   * **Action:** Document maintenance cadence, release windows, escalation matrix, and KPI reporting structure.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Drafting maintenance plan and aligning governance cadence...\"\n   * **Halt condition:** Stop if plan lacks coverage for critical services or SLAs.\n   * **Evidence:** `.artifacts/protocol-21/maintenance-plan.md` with sections for cadence, responsibilities, governance.\n\n2. **`[MUST]` Secure Stakeholder Approvals:**\n   * **Action:** Review plan with operations, support, product, and security leads; capture approvals and adjustments.\n   * **Communication:** \n     > \"[PHASE 3] Presenting maintenance plan for stakeholder approval...\"\n   * **Halt condition:** Pause if any stakeholder rejects or defers approval.\n   * **Evidence:** `.artifacts/protocol-21/approval-log.csv` documenting approvals, conditions, and dates.\n\n3. **`[GUIDELINE]` Configure Monitoring & Reporting Cadence:**\n   * **Action:** Schedule KPI reviews, set up dashboards, and document reporting templates.\n   * **Example:**\n     ```yaml\n     kpi_reviews:\n       - metric: \"Mean Time to Resolution\"\n         cadence: \"Weekly\"\n         owner: \"Support Lead\"\n       - metric: \"Error Budget Consumption\"\n         cadence: \"Monthly\"\n         owner: \"SRE Manager\"\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT finalize the maintenance plan without explicit commitments for every critical incident follow-up, SLA target, and optimization backlog item.**",
      "dependencies": [
        "P10",
        "P17",
        "P19",
        "P20"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P22",
      "file": ".cursor/ai-driven-workflow/22-implementation-retrospective.md",
      "title": "# PROTOCOL 22 : IMPLEMENTATION RETROSPECTIVE (CONTINUOUS IMPROVEMENT COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `maintenance-plan.md` from Protocol 21 \u2013 finalized maintenance roadmap\n- [ ] `maintenance-lessons-input.md` from Protocol 21 \u2013 operational insights backlog\n- [ ] `closure-lessons-input.md` from Protocol 20 \u2013 project closure metrics and lessons\n- [ ] `LESSONS-LEARNED-DOC-NOTES.md` from Protocol 19 \u2013 documentation lessons and feedback\n- [ ] `INCIDENT-POSTMORTEMS/` from Protocol 20 \u2013 root cause analyses and corrective actions\n- [ ] `PERFORMANCE-INSIGHTS.md` from Protocol 21 \u2013 optimization outcomes and remaining gaps\n- [ ] `QUALITY-AUDIT-PACKAGE.zip` from Protocol 19 \u2013 audit findings and remediation status\n- [ ] `UAT-FEEDBACK.csv` from Protocol 20 \u2013 user feedback and unmet expectations\n- [ ] `SPRINT-IMPLEMENTATION-NOTES.md` from Protocol 21 \u2013 development challenges and successes\n\n### Required Approvals\n- [ ] Executive Sponsor commitment to participate or delegate\n- [ ] Product Owner confirmation of retrospective scope and objectives\n- [ ] Engineering Manager approval of action plan cadence\n- [ ] Operations Lead agreement to integrate operational learnings\n\n### System State Requirements\n- [ ] Collaboration workspace prepared with retrospective template and virtual board access\n- [ ] Survey tools configured for anonymous feedback (if required)\n- [ ] Action tracking system ready to log improvement tasks (e.g., Jira, Linear)\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Retrospective Preparation & Data Synthesis\n\n1. **`[MUST]` Aggregate Cross-Protocol Insights:**\n   * **Action:** Consolidate artifacts from protocols 3\u201318 into a single retrospective knowledge base.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Aggregating lessons and evidence across delivery, quality, and operations...\"\n   * **Halt condition:** Stop if any key artifact is missing or outdated.\n   * **Evidence:** `.artifacts/protocol-22/retrospective-source-compilation.json` with artifact inventory and freshness.\n\n2. **`[MUST]` Identify Thematic Focus Areas:**\n   * **Action:** Categorize insights into themes (requirements, delivery, quality, operations, customer) using qualitative analysis.\n   * **Communication:** \n     > \"[PHASE 1] Categorizing retrospective inputs into thematic focus areas...\"\n   * **Halt condition:** Pause if themes lack supporting evidence or stakeholder alignment.\n   * **Evidence:** `.artifacts/protocol-22/theme-matrix.csv` mapping inputs to themes.\n\n3. **`[GUIDELINE]` Issue Pre-Retrospective Survey:**\n   * **Action:** Send survey for anonymous input on wins, challenges, and ideas.\n   * **Example:**\n     ```markdown\n     - Question: \"What should we keep doing to maintain quality?\"\n     - Question: \"Where did tooling slow us down?\"\n     ```\n\n### STEP 2: Facilitation & Insight Generation\n\n1. **`[MUST]` Conduct Structured Retrospective Session:**\n   * **Action:** Facilitate meeting using agenda (Set the Stage \u2192 Gather Data \u2192 Generate Insights \u2192 Decide Actions).\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Facilitating retrospective session. Capturing insights in real time...\"\n   * **Halt condition:** Halt if quorum not met or key roles absent.\n   * **Evidence:** `.artifacts/protocol-22/session-notes.md` capturing discussion, decisions, and votes.\n\n2. **`[MUST]` Capture Actionable Insights & Decisions:**\n   * **Action:** Translate discussion outcomes into actionable statements with rationale and evidence references.\n   * **Communication:** \n     > \"[PHASE 2] Documenting actionable insights with supporting evidence...\"\n   * **Halt condition:** Pause if insights lack measurable impact or ownership alignment.\n   * **Evidence:** `.artifacts/protocol-22/insight-log.json` listing insight, impact, source, owner candidates.\n\n3. **`[GUIDELINE]` Highlight Celebrations & Success Stories:**\n   * **Action:** Document noteworthy wins and recognition items for leadership communications.\n   * **Example:**\n     ```markdown\n     - Success: Zero-severity-one incidents during release window\n     - Recognition: QA team for proactive test automation coverage increase\n     ```\n\n### STEP 3: Action Plan & Continuous Improvement Alignment\n\n1. **`[MUST]` Prioritize Improvement Actions:**\n   * **Action:** Score improvement ideas using impact/effort matrix and align to owning protocols or teams.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Prioritizing action items and aligning owners...\"\n   * **Halt condition:** Halt if priority conflicts unresolved or lacking consensus.\n   * **Evidence:** `.artifacts/protocol-22/action-prioritization-matrix.csv` with scoring and rank.\n\n2. **`[MUST]` Assign Owners, Due Dates, and Follow-Up Protocols:**\n   * **Action:** Create action register with accountable owner, timeline, and protocol linkage for feedback loops.\n   * **Communication:** \n     > \"[PHASE 3] Assigning action ownership and scheduling follow-ups...\"\n   * **Halt condition:** Pause if any critical action lacks owner or due date.\n   * **Evidence:** `.artifacts/protocol-22/action-register.csv` capturing owner, due date, linked protocol.\n\n3. **`[GUIDELINE]` Publish Retrospective Report & Communication:**\n   * **Action:** Share summary with stakeholders, including wins, opportunities, and action commitments.\n   * **Example:**\n     ```bash\n     python scripts/generate_retrospective_report.py --inputs .artifacts/protocol-5 --output .artifacts/protocol-22/retrospective-report.md\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT conclude the retrospective until every critical action item has an accountable owner, due date, and follow-up protocol linkage.**",
      "dependencies": [
        "P19",
        "P20",
        "P21"
      ],
      "handoffs": []
    },
    {
      "protocol_id": "P23",
      "file": ".cursor/ai-driven-workflow/23-script-governance-protocol.md",
      "title": "# PROTOCOL 23 : SCRIPT GOVERNANCE (AUTOMATION QUALITY COMPLIANT)",
      "purpose_line": "**Purpose:** Execute Unknown Protocol workflow with quality validation and evidence generation.",
      "objectives": "",
      "prerequisites": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n\n### Required Artifacts\n- [ ] `.artifacts/quality-audit/QUALITY-AUDIT-PACKAGE.zip` from Protocol 19 \u2013 baseline quality expectations\n- [ ] `.cursor/context-kit/quality-audit-summary.json` \u2013 latest audit findings to align governance focus\n- [ ] Existing `script-registry.json` (if present) in `.cursor/context-kit/` \u2013 prior inventory snapshot\n\n### Required Approvals\n- [ ] Automation owner approval to perform read-only validation on `/scripts/`\n- [ ] Security lead acknowledgement for accessing script metadata\n\n### System State Requirements\n- [ ] Repository `/scripts/` directory accessible with read permissions\n- [ ] Static analysis tools (`pylint`, `shellcheck`, `yamllint`) installed or containerized equivalents configured\n- [ ] Write permissions to `.artifacts/scripts/` and `.cursor/context-kit/`\n\n---",
      "inputs": "",
      "outputs": "",
      "workflow": "### STEP 1: Script Discovery and Inventory Baseline\n\n1. **`[MUST]` Index Scripts Across Repository:**\n   * **Action:** Enumerate `.py`, `.sh`, `.ps1`, and `.yml` files under `/scripts/`, capturing metadata (path, description, last modified).\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 1 START] - Beginning script discovery and indexing...\"\n   * **Halt condition:** Stop if `/scripts/` directory missing or inaccessible.\n   * **Evidence:** `.artifacts/scripts/script-index.json` with completeness score.\n\n2. **`[MUST]` Validate Inventory Completeness:**\n   * **Action:** Compare discovered files against existing registry (if available) ensuring \u226595% alignment.\n   * **Communication:** \n     > \"[PHASE 1] Inventory completeness evaluated. Deviations recorded.\"\n   * **Halt condition:** Pause if completeness <95% without documented rationale.\n   * **Evidence:** `.artifacts/scripts/inventory-validation-report.json` summarizing matches and gaps.\n   * **Automation:** `python3 scripts/validate_script_registry.py --min-coverage 95.0 --fail-on-orphans`\n\n3. **`[GUIDELINE]` Categorize Scripts by Function:**\n   * **Action:** Group scripts into categories (deployment, validation, reporting) for governance insights.\n   * **Example:**\n     ```python\n     categories = classify_scripts(script_index)\n     save(categories, \".artifacts/scripts/script-categories.json\")\n     ```\n\n### STEP 2: Documentation and Static Compliance Checks\n\n1. **`[MUST]` Assess Documentation Quality:**\n   * **Action:** Ensure each script includes purpose statement, usage instructions, and artifact output description.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 2 START] - Auditing script documentation completeness...\"\n   * **Halt condition:** Halt if any critical script lacks documentation.\n   * **Evidence:** `.artifacts/scripts/documentation-audit.csv` capturing compliance per script.\n   * **Automation:** `python3 scripts/generate_protocol_23_artifacts.py --output-dir .artifacts/protocol-23`\n\n2. **`[MUST]` Run Static Analysis Toolchain:**\n   * **Action:** Execute read-only static analysis (`pylint`, `shellcheck`, `yamllint`) capturing warnings and severity levels.\n   * **Communication:** \n     > \"[RAY AUTOMATION] Executing static analysis suite across script inventory...\"\n   * **Halt condition:** Pause if tool execution fails or generates blocking severity findings.\n   * **Evidence:** `.artifacts/scripts/static-analysis-report.json` aggregated by tool and script.\n\n3. **`[MUST]` Confirm Artifact Output Compliance:**\n   * **Action:** Validate each script\u2019s expected outputs align with `.artifacts/` storage conventions and JSON schema rules.\n   * **Communication:** \n     > \"[PHASE 2] Verifying artifact output compliance and schema adherence...\"\n   * **Halt condition:** Stop if artifact paths or schemas deviate without mitigation plan.\n   * **Evidence:** `.artifacts/scripts/artifact-compliance-report.json` including schema validation results.\n   * **Automation:** `python3 scripts/generate_protocol_23_artifacts.py --output-dir .artifacts/protocol-23`\n\n4. **`[GUIDELINE]` Extend Protocol 19 Gates:**\n   * **Action:** Map relevant Protocol 19 quality gate expectations to scripts to ensure consistency.\n   * **Example:**\n     ```markdown\n     - Gate Alignment: Pre-Audit Automation \u2192 Scripts: run_protocol_4_pre_audit.py\n     - Evidence: static-analysis-report.json (severity <= medium)\n     ```\n\n### STEP 3: Governance Reporting and Feedback Loop\n\n1. **`[MUST]` Generate Compliance Scorecard:**\n   * **Action:** Consolidate inventory, documentation, static analysis, and artifact compliance into `script-compliance.json`.\n   * **Communication:** \n     > \"[MASTER RAY\u2122 | PHASE 3 START] - Compiling script governance scorecard for downstream consumers...\"\n   * **Halt condition:** Pause if data model validation fails.\n   * **Evidence:** `.cursor/context-kit/script-compliance.json` with compliance index.\n   * **Automation:** `python3 scripts/generate_protocol_23_artifacts.py --output-dir .artifacts/protocol-23`\n\n2. **`[MUST]` Publish Remediation Backlog:**\n   * **Action:** Create backlog entries for non-compliant scripts and notify owners.\n   * **Communication:** \n     > \"[PHASE 3] Script remediation backlog prepared. Owners notified.\"\n   * **Halt condition:** Stop if backlog cannot be linked to issue tracker.\n   * **Evidence:** `.artifacts/scripts/remediation-backlog.csv` containing action items.\n\n3. **`[GUIDELINE]` Share Insights with Quality Audit:**\n   * **Action:** Provide summary to Protocol 19 to influence upcoming audits.\n   * **Example:**\n     ```markdown\n     ### Script Governance Highlights\n     - Coverage: 98% scripts documented\n     - Blocking Issues: None\n     - Recommendations: Automate schema validation nightly\n     ```\n\n---",
      "quality_gates": "",
      "known_invariants": "**[STRICT]** List all required artifacts, approvals, and system states before execution.\n**\ud83d\udeab [CRITICAL] DO NOT modify or execute scripts directly; only validate, analyze, and report compliance results.**",
      "dependencies": [
        "P19"
      ],
      "handoffs": [
        "P19"
      ]
    }
  ]
}