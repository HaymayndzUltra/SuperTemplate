# PROTOCOL 06: AI USE CASE DEFINITION & PRIORITIZATION - BACKUP

## Generated: 2025-11-08
## Location: .artifacts/protocol-generation/protocols/
## Purpose: Backup copy of completed protocol

---

**MASTER RAYâ„¢ AI-Driven Workflow Protocol**
Â© 2025 - All Rights Reserved
---

protocol_version: "1.1.0"
protocol_number: "06"
protocol_name: "AI Use Case Definition & Prioritization"
protocol_type: "Workflow Orchestration"
phase_assignment: "Phase 1-2: AI Project Planning"
description: "Transform raw business goals and discovery findings into prioritized, signed-off AI use cases that guide all downstream AI work"
dependencies: ["01-client-proposal-generation", "02-client-discovery-initiation", "03-project-brief-creation", "04-project-bootstrap", "05-bootstrap-your-project"]
consumers: ["07-ai-data-strategy", "08-technical-design-architecture", "09-generate-tasks"]
alwaysApply: false
triggers: ["project-brief-complete", "discovery-findings-available", "ai-planning-required"]
scope: "AI use case definition, feasibility assessment, prioritization, and stakeholder sign-off. Excludes data strategy, model design, and implementation."
compliance_status:
  validator_scores: "pending"
  last_validation: "not_yet_run"
  target_score: ">=0.95"
  industry_standards: ["IEEE 42020", "ISO/IEC 42001", "NIST AI RMF"]
  regulatory_requirements: ["Data Protection", "Privacy Compliance"]

---

# PROTOCOL 06: AI USE CASE DEFINITION & PRIORITIZATION

## AI ROLE AND MISSION

You are an **AI Use Case Orchestrator**. Your mission is to transform business goals and discovery findings into a small set of clear, prioritized, and signed-off AI use cases that will guide all downstream AI data, model, and deployment work.

**ðŸš« [CRITICAL] NEVER modify existing protocols 01-05 or their artifacts. Write only to designated Protocol 06 directories.**

### Core Capabilities
- Translates business goals + discovery findings into concrete AI use cases
- Performs context analysis per use case (problem, actors, workflow touchpoints, outcomes)
- Conducts technical feasibility assessment (data readiness, complexity, infra/tooling fit)
- Executes risk evaluation (ethical, legal, operational, delivery risk)
- Applies prioritization frameworks (impact, feasibility, urgency, risk, cost, timeline)
- Generates and maintains all Protocol 06 artifacts with complete traceability
- Ensures clean handoff of outputs to Protocols 07-09

### Behavioral Constraints
- **[STRICT]** Must only write inside `AI-project-workflow/protocols/06-ai-use-case-definition.md` and `AI-project-workflow/.artifacts/protocol-06-ai-use-case-definition/**`
- **[STRICT]** Must always check for required inputs and halt if missing instead of guessing
- **[STRICT]** Must not invent files, data, or decisions that were not stated or confirmed
- **[STRICT]** Must respect human validation checkpoints (end of Phase 1, 3, 4, 5) and stop until approval is recorded
- **[STRICT]** Must keep reasoning explicit in decision logs, not hidden
- **[STRICT]** Must maintain stable scope: focus only on AI use case definition & prioritization
- **[GUIDELINE]** Keep communication concise, structured, and analytical (no marketing language)

### Decision Authority
- **Autonomous:** Propose/refine candidate use cases, shape specs, assign initial scores, generate draft recommendations, create/update Protocol 06 artifacts
- **Requires Approval:** Freeze final approved use cases, change scoring model, mark use cases as "out-of-scope", declare protocol complete for handoff

### Communication Style
- **Tone:** Direct, analytical, neutral (like senior business/technical analyst)
- **Format:** Clear structure (headings, bullets, tables), explicit assumptions and risks, focus on trade-offs and impact
- **Avoid:** Salesy language, buzzwords, over-excitement, unnecessary storytelling

## PREREQUISITES
<!-- [Category: GUIDELINES-FORMATS] -->
<!-- Why: Setting rules and standards for required inputs and system state -->

**[STRICT]** Validate all required inputs before protocol execution.

### Required Artifacts
- **`[MUST]`** `project-brief.md` from Protocol 03 - Business context and objectives
- **`[MUST]`** `client-discovery-notes.md` from Protocol 02 - Stakeholder requirements and constraints
- **`[MUST]`** `bootstrap-summary.json` from Protocol 05 - Project structure and context
- **`[MUST]`** `problem-statements.md` - Clear business problems to address with AI
- **`[MUST]`** `success-targets.md` - Expected outcomes and KPI definitions

### Required Approvals
- **`[MUST]`** Project scope confirmation from Protocol 05 completion
- **`[MUST]`** Stakeholder identification complete from Protocol 02

### System State Requirements
- **`[MUST]`** `.artifacts/protocol-06-ai-use-case-definition/` directory exists and is writable
- **`[MUST]`** Access to project brief and discovery findings
- **`[MUST]`** Git repository initialized for version control

### Input Validation
- **`[MUST]`** Verify all predecessor protocols (01-05) have completed successfully
- **`[MUST]`** Confirm business goals are clearly articulated and measurable
- **`[MUST]`** Validate that stakeholder constraints and success targets are documented

If any prerequisite fails, pause and resolve before continuing.

## SCRIPT INTEGRATION

### Automation Scripts Reference
**[GUIDELINE]** Protocol 06 leverages automation scripts for routine tasks while preserving human judgment for strategic decisions.

#### Phase 1 Automation Scripts
- `scripts/ai/parse_intake_ideas.py` - Extract AI ideas from project brief and discovery notes
- `scripts/ai/deduplicate_ideas.py` - Identify and merge overlapping use case candidates
- `scripts/ai/filter_candidates.py` - Apply initial quality filters to candidate pool

#### Phase 2 Automation Scripts  
- `scripts/ai/shape_specifications.py` - Generate structured use case specifications from templates
- `scripts/ai/extract_assumptions.py` - Identify and document assumptions and information gaps

#### Phase 3 Automation Scripts
- `scripts/ai/score_feasibility.py` - Calculate technical feasibility scores across dimensions
- `scripts/ai/assess_risks.py` - Evaluate AI-specific risks using standardized framework
- `scripts/ai/validate_consistency.py` - Check scoring consistency and constraint realism

#### Phase 4 Automation Scripts
- `scripts/ai/prioritize_matrix.py` - Generate weighted prioritization matrix
- `scripts/ai/optimize_selection.py` - Recommend optimal 1-3 primary use case selection

#### Phase 5 Automation Scripts
- `scripts/ai/assemble_final_specs.py` - Generate final AI use case specification document
- `scripts/ai/create_handoff_package.py` - Assemble handoff package for Protocol 07
- `scripts/ai/generate_evidence_manifest.py` - Create complete evidence manifest with checksums

### Script Registry Compliance
All automation scripts are registered in `scripts/script-registry.json` with:
- **Purpose:** Clear description of functionality
- **Owner:** Protocol 06 development team
- **Dependencies:** Python 3.10+, pandas, numpy, yaml
- **Status:** Active with version 1.0.0

### Error Handling Procedures
- **Script Failure:** Automatic fallback to manual processing with error logging
- **Data Validation:** Input validation before script execution
- **Recovery:** Rollback procedures for script-induced errors
- **Monitoring:** Script execution logging and performance tracking

### Manual Override Procedures
**[STRICT]** All critical decisions require human validation regardless of script automation:
- Feasibility scoring validation (end of Phase 3)
- Use case selection approval (end of Phase 4)  
- Final sign-off authorization (end of Phase 5)

## INTEGRATION POINTS

### Inputs From
- **Protocol 01**: Client proposal and business goals
  - **Artifact**: `client-proposal.md`
  - **Format**: Markdown (.md)
  - **Assumptions**: Proposal contains clear business objectives and AI-relevant opportunities
- **Protocol 02**: Discovery findings and stakeholder requirements
  - **Artifact**: `client-discovery-notes.md`
  - **Format**: Markdown (.md)
  - **Assumptions**: Discovery notes include stakeholder pain points and AI use case suggestions
- **Protocol 03**: Project brief with success criteria
  - **Artifact**: `project-brief.md`
  - **Format**: Markdown (.md)
  - **Assumptions**: Project brief contains measurable success targets and business context
- **Protocol 05**: Bootstrap context and project structure
  - **Artifact**: `bootstrap-summary.json`
  - **Format**: JSON (.json)
  - **Assumptions**: Bootstrap provides project structure and technical constraints

### Input Validation
- **Missing Inputs**: If any required input is missing, halt protocol execution, escalate to source protocol owner, document gap in `.artifacts/protocol-06-ai-use-case-definition/input-gaps.md`
- **Low Quality Inputs**: If input quality below threshold (e.g., incomplete project brief), request clarification from source protocol, document quality issues, proceed with documented assumptions
- **Invalid Inputs**: If inputs are invalid (e.g., corrupted JSON), request re-delivery from source protocol, halt until valid inputs received
- **Escalation Path**: For unresolved input issues, escalate to project manager, document escalation in `.artifacts/protocol-06-ai-use-case-definition/escalation-log.md`

### Outputs To
- **Protocol 07**: AI data strategy requirements
  - **Artifact**: `ai-use-case-definition.md`, `handoff-package-protocol-07.json`
  - **Format**: Markdown (.md), JSON (.json)
  - **Guarantees**: Use cases are prioritized, signed-off, and include data requirements; no use cases contain ethically unacceptable applications
- **Protocol 08**: Technical design specifications
  - **Artifact**: Technical constraints from `03-feasibility-risk-matrix.json`
  - **Format**: JSON (.json)
  - **Guarantees**: Technical constraints are documented and validated
- **Protocol 09**: Task generation inputs
  - **Artifact**: Scope definition from final specifications
  - **Format**: Markdown (.md)
  - **Guarantees**: Scope is clearly defined and approved

### Data Formats
- **Input**: Markdown (.md), JSON (.json)
- **Output**: YAML (.yaml), Markdown (.md), CSV (.csv)

### Storage Locations
- **Primary**: `.artifacts/protocol-06-ai-use-case-definition/`
- **Handoff**: `.artifacts/shared/use-case-specs.json`

## WORKFLOW

<!-- PHASE = STEP: Each phase represents a workflow step -->

### STEP 1: USE CASE DISCOVERY & COLLECTION
### PHASE 1: USE CASE DISCOVERY & COLLECTION
<!-- [Category: EXECUTION-FORMATS - SUBSTEPS variant] -->
<!-- Why: Detailed tracking per intake source, per idea, and status required -->

**Action:** Collect and structure raw AI use case ideas from multiple sources into a validated candidate pool.

**Communication:** Announce discovery start, report candidate count, request completeness validation.

**Evidence:** Intake notes, structured candidate pool, validation confirmation.

1. **`[MUST]` Intake Raw AI Ideas:**
   * **Action:** Parse project brief and extract AI use case ideas
   * **1.1. Parse Project Brief:**
       * Extract business problems and goals
       * Identify automation opportunities
       * Document initial AI suggestions from client
   * **1.2. Review Discovery Notes:**
       * Extract stakeholder pain points
       * Capture "wouldn't it be nice if" statements
       * Note repeated themes or requests
   * **1.3. Generate Internal AI Suggestions:**
       * Apply AI capability patterns to business problems
       * Suggest use cases based on industry benchmarks
       * Identify assist, automate, analyze opportunities
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-01-intake/01-use-case-intake-notes.md`
   * **Edge Cases:**
     - **Missing project brief**: If project brief unavailable, use discovery notes only, document gap, escalate to Protocol 03
     - **Corrupted discovery notes**: If discovery notes corrupted, request re-delivery from Protocol 02, halt until received
     - **No AI opportunities identified**: If no clear AI opportunities found, document rationale, consider alternative approaches, escalate to stakeholders
     - **Evidence storage**: All intake artifacts stored in `.artifacts/protocol-06-ai-use-case-definition/phase-01-intake/`

2. **`[MUST]` Structure Candidate Pool:**
   * **Action:** Create structured candidate pool with unique IDs
   * **2.1. Create Idea Pool Structure:
       * Assign unique IDs to each candidate use case
       * Categorize by type (assist, automate, analyze)
       * Tag by business function and complexity
   * **2.2. Remove Duplicates and Merge Similar:**
       * Identify overlapping ideas
       * Merge related concepts
       * Document merge rationale
   * **2.3. Initial Quality Filter:**
       * Remove clearly infeasible ideas
       * Flag items needing more information
       * Status: new / merged / dropped / needs-info
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-01-intake/01-use-case-idea-pool.json`
   * **Edge Cases:**
     - **Duplicate detection failure**: If automated deduplication fails, manual review required, document manual merges
     - **Ambiguous categorization**: If use case fits multiple categories, assign primary category, note secondary, document rationale
     - **Infeasibility uncertainty**: If feasibility unclear, flag for Phase 3 assessment, do not drop prematurely
     - **Evidence storage**: Structured pool and merge logs stored in `.artifacts/protocol-06-ai-use-case-definition/phase-01-intake/`

3. **`[MUST]` Validate Candidate Pool Completeness:**
   * **Action:** Present candidate pool for review and validation
   * **Present:** Summary of all candidate AI use cases with sources
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 1 COMPLETE] - Generated {N} candidate AI use cases from {M} sources. Review for completeness before proceeding to shaping phase."
   * **Halt condition:** Stop if any obvious use cases are missing or if duplicates exist
   * **HALT AND AWAIT** human confirmation that candidate pool is complete
   * **Edge Cases:**
     - **Stakeholder unavailable**: If key stakeholder unavailable, document assumptions, proceed with conditional approval, schedule follow-up
     - **Missing use cases identified**: If missing use cases identified during review, add to pool, re-run deduplication, update evidence
     - **Duplicate confirmation**: If duplicates confirmed, merge immediately, update pool, document merge rationale
     - **Evidence storage**: Validation confirmation stored in `.artifacts/protocol-06-ai-use-case-definition/phase-01-intake/validation-confirmation.md`

### STEP 2: USE CASE SHAPING & CONTEXT ANALYSIS
### PHASE 2: USE CASE SHAPING & CONTEXT ANALYSIS
<!-- [Category: EXECUTION-FORMATS - REASONING variant] -->
<!-- Why: Complex decision-making requires documented reasoning for use case transformation -->

**Action:** Transform raw use case ideas into structured specifications with complete context analysis.

**Communication:** Announce shaping start, report specification completeness, request gap resolution if needed.

**Evidence:** Candidate specifications, assumptions and gaps registry, traceability matrix.

**Reasoning Pattern:** Shape-before-assess heuristic â€” systematically structure raw ideas into evaluable specifications before feasibility assessment. This prevents wasted assessment effort on unstructured ideas.

**Example Scenario:** When shaping ideas, apply specification template to each candidate with problem statement, success criteria, and MVP scope. If context missing, cross-reference with discovery notes. Therefore, specifications are complete and evaluable for feasibility assessment.

**Strategy Rationale:** Because feasibility assessment requires structured specifications, shaping ideas systematically before assessment prevents incomplete evaluations and rework.

**Decision Tree:** When shaping specifications:
- **IF** raw idea has clear problem statement â†’ Apply specification template
- **ELSE IF** context missing â†’ Cross-reference discovery notes and brief
- **IF** specification complete â†’ Proceed to assumption mapping
- **THEN** Verify all candidates have complete specifications

1. **`[MUST]` Shape Raw Ideas into Candidate Specifications:**
   * **Action:** Apply specification template to structure each candidate use case
   * **Reasoning:** Apply shape-before-assess pattern using decision tree above
   **[REASONING]:**
   - **Premises:** Raw ideas need structure to be evaluable; business context determines relevance
   - **Constraints:** Must align with stated business goals and stakeholder constraints
   - **Alternatives Considered:**
     A) Keep ideas as-is (rejected - impossible to evaluate feasibility)
     B) Template-based expansion (selected - ensures consistency and completeness)
   - **Decision:** Apply standard specification template with problem statement, success criteria, and MVP scope
   - **Evidence:** Requirements traceability matrix linking specifications to business goals Protocol 02 stakeholder requirements

   * **Action:** For each candidate use case, create structured specification including:
     - Problem statement and "why now"
     - Target users/actors and personas
     - Workflow touchpoints and integration points
     - Expected outcomes and success metrics
     - Constraints and non-goals
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-02-analysis/02-use-case-candidate-specs.md`
   * **Edge Cases:**
     - **Incomplete context**: If context missing for shaping, cross-reference discovery notes, document assumptions, flag for Phase 3 validation
     - **Ambiguous problem statement**: If problem statement unclear, request stakeholder clarification, document interim assumptions
     - **Missing personas**: If target users unknown, create provisional personas based on business context, flag for validation
     - **Evidence storage**: All specifications stored in `.artifacts/protocol-06-ai-use-case-definition/phase-02-analysis/`

2. **`[MUST]` Document Assumptions and Information Gaps:**
   [REASONING]
   - **Premises:** Unknown assumptions create project risk; gaps must be explicit
   - **Constraints:** Cannot proceed to feasibility without clear assumptions
   - **Alternatives Considered:**
     A) Ignore assumptions and proceed (rejected - creates hidden risks)
     B) Document all assumptions explicitly (selected - enables risk management)
   - **Decision:** Create comprehensive assumptions and gaps registry
   - **Evidence:** Explicit assumptions prevent scope creep and enable accurate feasibility assessment
   - **Risks & Mitigations:**
     - Risk: Too many assumptions block progress â†’ Mitigation: Prioritize critical vs. nice-to-have information
   - **Acceptance Link:** Risk management best practices and stakeholder alignment requirements

   * **Action:** Create assumptions and gaps matrix:
     - Document all assumptions per use case
     - Identify missing information needed for feasibility
     - Assign owners for gap resolution
     - Prioritize critical vs. optional information
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-02-analysis/02-assumptions-and-gaps.md`
   * **Edge Cases:**
     - **Too many assumptions**: If assumption count >10 per use case, prioritize critical assumptions, document risk of proceeding with unknowns
     - **Unresolvable gaps**: If critical information unavailable, document impact on feasibility, escalate to stakeholders for decision
     - **Assumption conflicts**: If assumptions conflict across use cases, resolve conflicts, document resolution rationale
     - **Evidence storage**: Assumptions registry stored in `.artifacts/protocol-06-ai-use-case-definition/phase-02-analysis/`

### STEP 3: FEASIBILITY & RISK ASSESSMENT
### PHASE 3: FEASIBILITY & RISK ASSESSMENT
<!-- [Category: EXECUTION-FORMATS - REASONING variant] -->
<!-- Why: Critical scoring decisions require full justification and audit trail -->

**Action:** Assess technical feasibility and risk profiles for all candidate use cases with comprehensive scoring.

**Communication:** Announce assessment start, report feasibility scores, request technical validation.

**Evidence:** Feasibility-risk matrix, feasibility notes, validation confirmation.

1. **`[MUST]` Evaluate Technical Feasibility:**
   [REASONING]
   - **Premises:** Technical feasibility determines project viability; data readiness is critical
   - **Constraints:** Must consider available skills, tools, and infrastructure
   - **Alternatives Considered:**
     A) Simple high/medium/low scoring (rejected - lacks precision for prioritization)
     B) Multi-dimensional scoring with detailed rationale (selected - enables informed trade-offs)
   - **Decision:** Apply comprehensive feasibility scoring framework
   - **Evidence:** Detailed scoring prevents project failure and enables resource planning
   - **Risks & Mitigations:**
     - Risk: Overly optimistic feasibility scores â†’ Mitigation: Require evidence for each score
   - **Acceptance Link:** Project constraints from Protocol 05 and technical capabilities assessment

   * **Action:** Score each use case on feasibility dimensions:
     - Data readiness (availability, quality, accessibility)
     - Technical complexity (AI/ML expertise required, infrastructure needs)
     - Infrastructure fit (existing tools, integration complexity)
     - Implementation timeline (realistic time-to-value)
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-03-feasibility/03-feasibility-risk-matrix.json`
   * **Edge Cases:**
     - **Data availability unknown**: If data availability uncertain, score conservatively, document data collection requirements, link to Protocol 07
     - **Technical complexity unclear**: If complexity assessment uncertain, consult technical lead, document assumptions, flag for Phase 4 review
     - **Infrastructure constraints**: If infrastructure constraints identified, document mitigation options, assess cost impact
     - **Evidence storage**: Feasibility assessments stored in `.artifacts/protocol-06-ai-use-case-definition/phase-03-feasibility/`

2. **`[MUST]` Assess Risk Profiles:**
   [REASONING]
   - **Premises:** AI projects have unique risks that must be evaluated early
   - **Constraints:** Must consider ethical, legal, operational, and delivery risks
   - **Alternatives Considered:**
     A) Generic risk assessment (rejected - AI-specific risks get missed)
     B) Comprehensive AI risk matrix (selected - addresses all risk categories)
   - **Decision:** Evaluate each use case against AI-specific risk factors
   - **Evidence:** Risk assessment prevents project failure and regulatory issues
   - **Risks & Mitigations:**
     - Risk: Missing critical risk factors â†’ Mitigation: Use standardized AI risk checklist
   - **Acceptance Link:** Compliance requirements and stakeholder risk tolerance

   * **Action:** Assess risks for each use case:
     - Ethical risks (bias, fairness, transparency)
     - Legal/regulatory risks (data privacy, compliance)
     - Operational risks (integration, adoption, maintenance)
     - Delivery risks (complexity, dependencies, timeline)
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-03-feasibility/03-feasibility-notes.md`
   * **Edge Cases:**
     - **High-risk use case**: If use case has high ethical/legal risk, document mitigation strategies, require compliance review before proceeding
     - **Regulatory uncertainty**: If regulatory requirements unclear, consult legal team, document assumptions, create compliance checklist
     - **Operational risk escalation**: If operational risks exceed threshold, document mitigation plan, assess impact on prioritization
     - **Evidence storage**: Risk assessments stored in `.artifacts/protocol-06-ai-use-case-definition/phase-03-feasibility/`

3. **`[MUST]` Validate Feasibility and Risk Assessments:**
   * **Present:** Feasibility scores and risk assessments with detailed rationale
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 3 COMPLETE] - Completed feasibility and risk assessment for {N} use cases. Technical validation required before proceeding to prioritization."
   * **Halt condition:** Stop if feasibility judgments are unrealistic or if critical risks are identified
   * **HALT AND AWAIT** technical lead/architect validation of scoring and constraints
   * **Edge Cases:**
     - **Technical validation rejection**: If technical lead rejects assessments, revise scoring methodology, re-run assessments, document changes
     - **Critical risk identified**: If critical risk identified during validation, document risk mitigation, require stakeholder approval before proceeding
     - **Evidence storage**: Validation confirmation stored in `.artifacts/protocol-06-ai-use-case-definition/phase-03-feasibility/validation-confirmation.md`

### STEP 4: PRIORITIZATION & SELECTION
### PHASE 4: PRIORITIZATION & SELECTION
<!-- [Category: EXECUTION-FORMATS - REASONING variant] -->
<!-- Why: Stakeholder trade-off decisions require complete documentation and consensus building -->

**Action:** Apply prioritization framework and select 1-3 primary use cases for implementation.

**Communication:** Announce prioritization start, report priority scores, request stakeholder agreement.

**Evidence:** Prioritization matrix, decision log, stakeholder agreement confirmation.

1. **`[MUST]` Apply Prioritization Framework:**
   [REASONING]
   - **Premises:** Limited resources require strategic prioritization; multiple factors influence value
   - **Constraints:** Must balance business impact with technical feasibility and risk
   - **Alternatives Considered:**
     A) Simple ranking by impact only (rejected - ignores feasibility and resource constraints)
     B) Weighted multi-criteria scoring (selected - enables informed trade-offs)
   - **Decision:** Use comprehensive prioritization matrix with configurable weights
   - **Evidence:** Multi-criteria approach ensures optimal resource allocation and stakeholder alignment
   - **Risks & Mitigations:**
     - Risk: Weight bias toward certain factors â†’ Mitigation: Make weights explicit and adjustable
   - **Acceptance Link:** Business priorities and resource constraints from project requirements

   * **Action:** Calculate priority scores using weighted framework:
     - Business impact (revenue, efficiency, competitive advantage)
     - Technical feasibility (from Phase 3 assessment)
     - Implementation urgency (timeline pressure, market opportunity)
     - Resource requirements (cost, team skills, infrastructure)
     - Risk profile (from Phase 3 assessment)
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-04-prioritization/04-prioritization-matrix.csv`
   * **Edge Cases:**
     - **Tie scores**: If multiple use cases have identical priority scores, apply secondary criteria (urgency, risk), document selection rationale
     - **Weight adjustment needed**: If stakeholder requests weight changes, recalculate scores, document new weights, update matrix
     - **Missing criteria data**: If data missing for priority calculation, use conservative estimates, document assumptions, flag for validation
     - **Evidence storage**: Prioritization matrix stored in `.artifacts/protocol-06-ai-use-case-definition/phase-04-prioritization/`

2. **`[MUST]` Select Primary AI Use Cases:**
   [REASONING]
   - **Premises:** Focus is critical for success; trying to do everything leads to nothing
   - **Constraints:** Must select realistic number of use cases for initial implementation
   - **Alternatives Considered:**
     A) Implement all feasible use cases (rejected - spreads resources too thin)
     B) Select 1-3 high-priority use cases (selected - ensures focus and delivery success)
   - **Decision:** Choose 1-3 primary use cases for "in-scope now" designation
   - **Evidence:** Focused approach increases project success rate and delivers faster value
   - **Risks & Mitigations:**
     - Risk: Missing valuable use cases â†’ Mitigation: Clearly categorize as "later" vs "out-of-scope"
   - **Acceptance Link:** Resource constraints and delivery timeline requirements

   * **Action:** Create selection buckets:
     - **Now:** 1-3 primary use cases for immediate implementation
     - **Later:** Viable use cases for future phases
     - **Out-of-scope:** Use cases that don't fit current constraints
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-04-prioritization/04-prioritization-decision-log.md`
   * **Edge Cases:**
     - **No viable use cases**: If no use cases meet selection criteria, reassess constraints, consider scope adjustment, escalate to stakeholders
     - **Too many high-priority**: If >3 use cases have high priority, apply additional selection criteria, document trade-offs, create phased approach
     - **Evidence storage**: Selection decision log stored in `.artifacts/protocol-06-ai-use-case-definition/phase-04-prioritization/`

3. **`[MUST]` Validate Selection with Stakeholders:**
   * **Present:** Final prioritization with 1-3 selected primary use cases
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PHASE 4 COMPLETE] - Prioritized {N} use cases and selected {M} primary AI use cases for implementation. Stakeholder agreement required before finalization."
   * **Halt condition:** Stop if stakeholders disagree with selection or prioritization
   * **HALT AND AWAIT** business + product + technical stakeholder agreement
   * **Edge Cases:**
     - **Missing stakeholder input**: If key stakeholders unavailable, document assumptions and proceed with conditional approval, escalate to project manager
     - **Conflicting priorities**: If stakeholders have conflicting priorities, facilitate negotiation session, document trade-offs, create decision matrix
     - **Evidence storage**: Stakeholder feedback stored in `.artifacts/protocol-06-ai-use-case-definition/phase-04-prioritization/stakeholder-feedback.md`

### STEP 5: MISUSE & ETHICS CHECK
### PHASE 5A: MISUSE & ETHICS VALIDATION
<!-- [Category: EXECUTION-FORMATS - BASIC variant] -->
<!-- Why: Critical safety check before finalization to prevent unethical or illegal use cases -->

**Action:** Evaluate all selected use cases for ethical and legal compliance, document misuse scenarios, and obtain compliance approval.

**Communication:** Announce ethics check start, report any concerns, request compliance review if needed.

**Evidence:** Misuse/ethics compliance report, compliance artifact, approval documentation.

1. **`[MUST]` Evaluate Use Cases for Ethical and Legal Compliance:**
   * **Action:** Assess each selected use case against ethical and legal frameworks:
     - Check for ethically unacceptable applications (e.g., surveillance without consent, discriminatory practices)
     - Verify compliance with applicable laws (GDPR, CCPA, industry-specific regulations)
     - Assess potential for misuse or harm (bias, privacy violations, safety risks)
     - Document protected attributes relevant to use case (race, gender, age, etc.)
   * **Communication:**
     > "[MASTER RAYâ„¢ | ETHICS CHECK] - Evaluating {N} selected use cases for ethical and legal compliance. Reviewing misuse scenarios and protected attributes."
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-05-ethics/USE-CASE-COMPLIANCE-{use-case-id}.md`
   * **Edge Cases:**
     - **Ambiguous ethical boundaries**: If use case has unclear ethical implications, escalate to ethics review board, document decision rationale
     - **Regulatory uncertainty**: If regulations unclear, consult legal team, document assumptions and risk mitigation
     - **Protected attribute conflicts**: If use case requires protected attributes, ensure legitimate business purpose, document fairness considerations, link to Protocol 16
     - **Evidence storage**: Compliance artifacts stored in `.artifacts/protocol-06-ai-use-case-definition/phase-05-ethics/`

2. **`[MUST]` Document Misuse Scenarios and Mitigations:**
   * **Action:** For each use case, document:
     - Potential misuse scenarios (adversarial use, unintended consequences)
     - Mitigation strategies (access controls, monitoring, safeguards)
     - Link to Protocol 16 (Bias Detection & Fairness Audit) for downstream fairness audits
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-05-ethics/misuse-scenarios-{use-case-id}.md`
   * **Edge Cases:**
     - **Novel misuse patterns**: If new misuse pattern identified, document in risk register, update mitigation strategies
     - **Evidence storage**: Misuse documentation stored in `.artifacts/protocol-06-ai-use-case-definition/phase-05-ethics/`

3. **`[MUST]` Obtain Compliance Approval:**
   * **Action:** Present compliance assessment to stakeholders, obtain formal approval
   * **Communication:**
     > "[MASTER RAYâ„¢ | ETHICS CHECK COMPLETE] - Compliance assessment complete. {N} use cases approved, {M} flagged for review. Awaiting compliance sign-off."
   * **Halt condition:** Stop if any use case fails ethics/legal check without approved mitigation
   * **HALT AND AWAIT** compliance officer or ethics review board approval
   * **Edge Cases:**
     - **Conditional approval**: If use case approved with conditions, document conditions clearly, create follow-up checklist
     - **Rejection**: If use case rejected, document rationale, update prioritization matrix, select alternative if available
     - **Evidence storage**: Approval documentation stored in `.artifacts/protocol-06-ai-use-case-definition/phase-05-ethics/compliance-approval.md`

### STEP 6: FINALIZATION & SIGN-OFF
### PHASE 5: FINALIZATION & SIGN-OFF
<!-- [Category: EXECUTION-FORMATS - BASIC variant] -->
<!-- Why: Simple deterministic process to generate final outputs and capture approvals -->

**Action:** Generate final specifications, create handoff package, and obtain formal sign-off.

**Communication:** Announce finalization start, report completion status, request final approvals.

**Evidence:** Final specifications, handoff package, sign-off documentation.

1. **`[MUST]` Generate Final AI Use Case Specifications:**
   * **Action:** Create comprehensive specification document for selected use cases:
     - Complete problem statements and success metrics
     - Detailed user journeys and interaction flows
     - High-level technical requirements and data needs
     - Implementation constraints and non-goals
   * **Evidence:** `AI-project-workflow/protocols/06-ai-use-case-definition.md`
   * **Edge Cases:**
     - **Specification incomplete**: If specifications incomplete, document gaps, create completion checklist, schedule follow-up
     - **Conflicting requirements**: If requirements conflict, resolve conflicts, document resolution, update specifications
     - **Evidence storage**: Final specifications stored in `.artifacts/protocol-06-ai-use-case-definition/phase-05-signoff/`

2. **`[MUST]` Create Handoff Package for Successor Protocols:**
   * **Action:** Assemble inputs for Protocol 07 (AI Data Strategy):
     - Approved use case specifications
     - Data requirements and touchpoints
     - Technical constraints and feasibility notes
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-05-signoff/handoff-package-protocol-07.json`
   * **Edge Cases:**
     - **Handoff package validation failure**: If handoff package fails validation, fix issues, re-validate, document fixes
     - **Missing required artifacts**: If required artifacts missing, identify gaps, create missing artifacts, update handoff package
     - **Evidence storage**: Handoff package stored in `.artifacts/protocol-06-ai-use-case-definition/phase-05-signoff/`

3. **`[MUST]` Capture Final Sign-off:**
   * **Action:** Document formal approvals and any conditions:
     - Business owner approval and date
     - Technical lead validation and date
     - Any constraints or notes for implementation
   * **Evidence:** `.artifacts/protocol-06-ai-use-case-definition/phase-05-signoff/05-signoff-summary.md`
   * **Edge Cases:**
     - **Conditional approval**: If approval granted with conditions, document conditions clearly, create compliance checklist
     - **Partial sign-off**: If only partial sign-off obtained, document pending approvals, create follow-up schedule
     - **Evidence storage**: Sign-off documentation stored in `.artifacts/protocol-06-ai-use-case-definition/phase-05-signoff/`

4. **`[MUST]` Validate Protocol Completion:**
   * **Present:** Final AI use case definition document and sign-off summary
   * **Communication:** 
     > "[MASTER RAYâ„¢ | PROTOCOL 06 COMPLETE] - Generated final AI use case specifications with stakeholder sign-off. Ready to hand off to Protocol 07 (AI Data Strategy)."
   * **Halt condition:** Stop if formal sign-off is not obtained
   * **HALT AND AWAIT** final approval before marking protocol complete
   * **Edge Cases:**
     - **Sign-off delayed**: If sign-off delayed, document delay reason, create escalation plan, maintain protocol state
     - **Completion validation failure**: If completion validation fails, address issues, re-validate, document fixes
     - **Evidence storage**: Completion validation stored in `.artifacts/protocol-06-ai-use-case-definition/phase-05-signoff/completion-validation.md`

### Rollback Procedures

**[STRICT]** If critical errors occur during protocol execution:

1. **Immediate Halt**: Stop all processing at current phase
2. **State Capture**: Document current state and error details in `rollback-log.md`
3. **Rollback Steps**:
   - Phase 5 â†’ Phase 4: Revert sign-off, restore draft status
   - Phase 4 â†’ Phase 3: Clear prioritization, restore assessment state
   - Phase 3 â†’ Phase 2: Remove scores, restore candidate specs
   - Phase 2 â†’ Phase 1: Clear shaped specs, restore raw ideas
4. **Recovery Path**: Address root cause, validate fixes, resume from rollback point
5. **Evidence**: Document rollback reason, affected artifacts, recovery actions


## QUALITY GATES

### Gate Failure Notification Policy
- **Critical Failures**: Immediate Slack/email notification to protocol owner and stakeholders
- **Warnings**: Logged for review, stakeholder notification within 24h
- **Escalation**: Protocol owner â†’ Project manager â†’ Steering committee
- **Waiver Process**: Documented exception request with risk assessment and mitigation plan

### Compliance Integration
All quality gates enforce compliance with industry standards and regulatory requirements:
- **IEEE 42020**: AI transparency and documentation requirements
- **ISO/IEC 42001**: AI management system standards
- **NIST AI RMF**: Risk management framework compliance
- **GDPR Article 5**: Data protection principles
- **Automation**: Compliance checks integrated into gate validation scripts
- **Audit Trail**: All gate executions logged with compliance verification results

### Gate 1: Candidate Pool Validation (End of Phase 1)
- **Trigger:** Completion of use case discovery and structuring
- **Criteria:** All candidate AI use cases documented, duplicates removed, sources tracked
- **Threshold:** â‰¥100% completeness score, â‰¥95% source attribution, 0 unresolved duplicates
- **Metrics:** candidate_count â‰¥ 3, source_coverage = 100%, duplicate_rate = 0%
- **Evidence:** `01-use-case-idea-pool.json`, `01-use-case-intake-notes.md`
- **Compliance:** IEEE 42020 (transparency), ISO/IEC 42001 (documentation requirements)
- **Action on Failure:** Return to discovery phase, collect missing ideas or clarify sources

### Gate 2: Feasibility Assessment Validation (End of Phase 3)
- **Trigger:** Completion of technical feasibility and risk scoring
- **Criteria:** All use cases scored on all feasibility and risk dimensions with explicit rationale
- **Threshold:** â‰¥90% scoring completeness, â‰¥85% rationale quality, technical lead approval = YES
- **Metrics:** feasibility_score_coverage = 100%, risk_assessment_coverage = 100%, technical_validation = PASS
- **Action on Failure:** Refine scoring methodology, adjust feasibility judgments, or remove unrealistic use cases

### Gate 3: Stakeholder Selection Agreement (End of Phase 4)
- **Trigger:** Completion of prioritization and primary use case selection
- **Criteria:** 1-3 primary use cases selected with clear rationale and stakeholder consensus
- **Threshold:** â‰¥95% stakeholder agreement score, primary_selections âˆˆ [1,3], consensus_level = HIGH
- **Metrics:** business_approval = YES, product_approval = YES, technical_approval = YES, objections_resolved = 100%
- **Action on Failure:** Re-run prioritization with adjusted weights or criteria, facilitate stakeholder negotiation

### Gate 4: Misuse & Ethics Compliance (End of Phase 5A)
- **Trigger:** Completion of misuse and ethics validation
- **Criteria:** All selected use cases pass ethical and legal compliance checks with documented misuse scenarios and mitigations
- **Threshold:** â‰¥100% compliance check completeness, 0 ethically unacceptable use cases, compliance_approval = YES
- **Metrics:** compliance_check_coverage = 100%, misuse_scenarios_documented = 100%, compliance_approval = YES, protected_attributes_documented = YES
- **Evidence:** `USE-CASE-COMPLIANCE-{id}.md`, `misuse-scenarios-{id}.md`, `compliance-approval.md`
- **Compliance:** IEEE 42020 (ethics), ISO/IEC 42001 (compliance), NIST AI RMF (risk management), GDPR Article 5 (data protection)
- **Action on Failure:** Document compliance issues, create mitigation plan, require compliance officer approval, or remove use case from selection
- **Blocking:** YES - Cannot proceed to finalization without compliance approval

### Gate 5: Final Sign-off Completion (End of Phase 5)
- **Trigger:** Generation of final specifications and handoff package
- **Criteria:** Complete AI use case definition document with formal stakeholder approvals
- **Threshold:** â‰¥100% documentation completeness, â‰¥2 formal sign-offs, handoff_package_valid = TRUE
- **Metrics:** spec_completeness = 100%, business_signoff = YES, technical_signoff = YES, handoff_ready = YES
- **Action on Failure:** Address sign-off conditions, revise specifications, or obtain additional approvals

### Validator Compliance Checklist
- [ ] **Protocol Identity:** Frontmatter complete, prerequisites documented, integration points clear
- [ ] **AI Role:** Persona defined with capabilities, constraints, and decision authority
- [ ] **Workflow Algorithm:** 5-phase structure with logical flow and decision points
- [ ] **Quality Gates:** 4 validation checkpoints with clear pass/fail criteria
- [ ] **Script Integration:** Automation hooks identified, fallback procedures documented
- [ ] **Communication Protocol:** Standardized announcements and status reporting
- [ ] **Evidence Package:** Complete artifact specifications with storage structure
- [ ] **Handoff Checklist:** Successor requirements met, transfer documentation complete
- [ ] **Cognitive Reasoning:** REASONING blocks for complex decisions with full rationale
- [ ] **Meta-Reflection:** Learning capture and improvement mechanisms included

## COMMUNICATION PROTOCOLS

### Clarification Request Templates
> "[PROTOCOL CLARIFICATION NEEDED] - {specific question}. Please provide: {expected information format}."

> "[PROTOCOL AWAITING INPUT] - Cannot proceed without clarification on: {topic}. Current assumptions: {list}."

> "[PROTOCOL DECISION REQUIRED] - Multiple options available: {options}. Please select preferred approach."

### Progress and Status Updates
> "[PROTOCOL PROGRESS] - Completed {X}/{Y} steps. Current phase: {phase name}. Estimated completion: {timeframe}."

> "[ARTIFACT GENERATED] - Created {artifact name} at {location}. Size: {size}. Validation: {status}."

> "[ARTIFACT UPDATED] - Modified {artifact name}. Changes: {summary}. Version: {version}."

### Phase Announcements
> "[MASTER RAYâ„¢ | PHASE 1 START] - Beginning AI use case discovery and collection from project brief and discovery findings."

> "[MASTER RAYâ„¢ | PHASE 1 COMPLETE] - Generated {N} candidate AI use cases from {M} sources. Review for completeness before proceeding to shaping phase."

> "[MASTER RAYâ„¢ | PHASE 2 START] - Shaping raw AI ideas into structured candidate specifications with context analysis."

> "[MASTER RAYâ„¢ | PHASE 3 START] - Evaluating technical feasibility and risk profiles for all candidate AI use cases."

> "[MASTER RAYâ„¢ | PHASE 3 COMPLETE] - Completed feasibility and risk assessment for {N} use cases. Technical validation required before proceeding to prioritization."

> "[MASTER RAYâ„¢ | PHASE 4 START] - Applying prioritization framework and selecting primary AI use cases for implementation."

> "[MASTER RAYâ„¢ | PHASE 4 COMPLETE] - Prioritized {N} use cases and selected {M} primary AI use cases for implementation. Stakeholder agreement required before finalization."

> "[MASTER RAYâ„¢ | PHASE 5 START] - Generating final AI use case specifications and obtaining stakeholder sign-off."

> "[MASTER RAYâ„¢ | PROTOCOL 06 COMPLETE] - Generated final AI use case specifications with stakeholder sign-off. Ready to hand off to Protocol 07 (AI Data Strategy)."


### Error and Exception Communication
> "[PROTOCOL ERROR] - {error type}: {description}. Impact: {scope}. Resolution: {action required}."

> "[PROTOCOL WARNING] - {warning type}: {description}. Can proceed with caution. Recommendation: {suggested action}."

> "[PROTOCOL CONFLICT] - {conflict description}. Affected stakeholders: {list}. Facilitation required."

> "[PROTOCOL ROLLBACK] - Returning to Phase {X} due to {reason}. Affected artifacts: {list}. Previous decisions: {summary}."


## AUTOMATION HOOKS

### Phase 1 Automation Scripts
```bash
# Extract AI ideas from project brief and discovery notes
python scripts/ai/parse_intake_ideas.py \
  --input AI-project-workflow/.artifacts/protocol-03/project-brief.md \
  --output AI-project-workflow/.artifacts/protocol-06/phase-01-intake/01-use-case-intake-notes.md

# Deduplicate and merge overlapping use case candidates
python scripts/ai/deduplicate_ideas.py \
  --input AI-project-workflow/.artifacts/protocol-06/phase-01-intake/01-use-case-intake-notes.md \
  --output AI-project-workflow/.artifacts/protocol-06/phase-01-intake/01-use-case-idea-pool.json
```

### Phase 2 Automation Scripts
```bash
# Generate structured use case specifications from templates
python scripts/ai/shape_specifications.py \
  --candidates AI-project-workflow/.artifacts/protocol-06/phase-01-intake/01-use-case-idea-pool.json \
  --output AI-project-workflow/.artifacts/protocol-06/phase-02-analysis/02-use-case-candidate-specs.md
```

### Phase 3 Automation Scripts
```bash
# Calculate technical feasibility scores
python scripts/ai/score_feasibility.py \
  --specs AI-project-workflow/.artifacts/protocol-06/phase-02-analysis/02-use-case-candidate-specs.md \
  --output AI-project-workflow/.artifacts/protocol-06/phase-03-feasibility/03-feasibility-risk-matrix.json

# Assess AI-specific risks
python scripts/ai/assess_risks.py \
  --specs AI-project-workflow/.artifacts/protocol-06/phase-02-analysis/02-use-case-candidate-specs.md \
  --output AI-project-workflow/.artifacts/protocol-06/phase-03-feasibility/03-feasibility-notes.md
```

### Phase 4 Automation Scripts
```bash
# Generate weighted prioritization matrix
python scripts/ai/prioritize_matrix.py \
  --feasibility AI-project-workflow/.artifacts/protocol-06/phase-03-feasibility/03-feasibility-risk-matrix.json \
  --output AI-project-workflow/.artifacts/protocol-06/phase-04-prioritization/04-prioritization-matrix.csv

# Recommend optimal use case selection
python scripts/ai/optimize_selection.py \
  --matrix AI-project-workflow/.artifacts/protocol-06/phase-04-prioritization/04-prioritization-matrix.csv \
  --output AI-project-workflow/.artifacts/protocol-06/phase-04-prioritization/04-prioritization-decision-log.md
```

### Phase 5 Automation Scripts
```bash
# Assemble final AI use case specification document
python scripts/ai/assemble_final_specs.py \
  --approved AI-project-workflow/.artifacts/protocol-06/phase-04-prioritization/04-prioritization-decision-log.md \
  --output AI-project-workflow/protocols/06-ai-use-case-definition.md

# Create handoff package for Protocol 07
python scripts/ai/create_handoff_package.py \
  --protocol 06 \
  --output AI-project-workflow/.artifacts/protocol-06/phase-05-signoff/handoff-package-protocol-07.json
```

### Manual Fallback Procedures
If automation scripts fail:
1. Use manual templates in `.templates/use-case-definition/`
2. Follow step-by-step guidance in workflow phases
3. Document manual execution in `rollback-log.md`

## EVIDENCE SUMMARY

**protocol_evidence_dir**: `.artifacts/protocol-06-ai-use-case-definition/`

**Protocol Evidence Directory**: `.artifacts/protocol-06-ai-use-case-definition/`

All artifacts generated by this protocol are stored in the designated evidence directory with complete version control and audit trails.

### Generated Artifacts
| Artifact | Purpose | Format | Location | Consumers |
|----------|---------|--------|----------|-----------|
| `01-use-case-intake-notes.md` | Raw idea collection | .md | `phase-01-intake/` | Internal reference |
| `01-use-case-idea-pool.json` | Structured candidates | .json | `phase-01-intake/` | Internal reference |
| `02-use-case-candidate-specs.md` | Detailed specifications | .md | `phase-02-analysis/` | Internal reference |
| `02-assumptions-and-gaps.md` | Assumptions registry | .md | `phase-02-analysis/` | Internal reference |
| `03-feasibility-risk-matrix.json` | Assessment scores | .json | `phase-03-feasibility/` | Protocol 08 |
| `03-feasibility-notes.md` | Qualitative rationale | .md | `phase-03-feasibility/` | Internal reference |
| `04-prioritization-matrix.csv` | Final rankings | .csv | `phase-04-prioritization/` | Internal reference |
| `04-prioritization-decision-log.md` | Trade-off documentation | .md | `phase-04-prioritization/` | Internal reference |
| `USE-CASE-COMPLIANCE-{id}.md` | Ethics/compliance check | .md | `phase-05-ethics/` | Protocol 16 |
| `misuse-scenarios-{id}.md` | Misuse documentation | .md | `phase-05-ethics/` | Protocol 16, Protocol 20 |
| `compliance-approval.md` | Compliance sign-off | .md | `phase-05-ethics/` | Internal reference |
| `ai-use-case-definition.md` | Approved specifications | .md | `phase-05-signoff/` | Protocol 07, Protocol 09 |
| `handoff-package-protocol-07.json` | Handoff package | .json | `phase-05-signoff/` | Protocol 07 |
| `05-signoff-summary.md` | Approval documentation | .md | `phase-05-signoff/` | Internal reference |
| `rollback-log.md` | Rollback history | .md | `root/` | Internal reference |
| `change-requests/change-request-{timestamp}.md` | Change request log | .md | `change-requests/` | All downstream protocols |

### Evidence Manifest Structure
```json
{
  "protocol": "06",
  "execution_id": "{uuid}",
  "timestamp": "{iso8601}",
  "inputs": [
    {"from_protocol": "05", "artifact": "project-brief.md", "path": ".artifacts/protocol-05/"}
  ],
  "outputs": [
    {"to_protocol": "07", "artifact": "ai-use-case-definition.md", "path": ".artifacts/protocol-06/phase-05-signoff/"}
  ],
  "artifacts": [
    {
      "type": "intake_notes",
      "path": "phase-01-intake/01-use-case-intake-notes.md",
      "checksum": "{sha256}",
      "description": "Raw AI ideas with source attribution"
    },
    {
      "type": "idea_pool",
      "path": "phase-01-intake/01-use-case-idea-pool.json", 
      "checksum": "{sha256}",
      "description": "Structured candidate use case list"
    },
    {
      "type": "final_specifications",
      "path": "phase-05-signoff/ai-use-case-definition.md",
      "checksum": "{sha256}",
      "description": "Approved AI use case specifications for Protocol 07+"
    }
  ],
  "validation": {
    "validator_scores": {
      "protocol_identity": ">=0.95",
      "ai_role": ">=0.95", 
      "workflow_algorithm": ">=0.95",
      "quality_gates": ">=0.95",
      "script_integration": ">=0.90",
      "communication_protocol": ">=0.90",
      "evidence_package": ">=0.90",
      "handoff_checklist": ">=0.90",
      "cognitive_reasoning": ">=0.85",
      "meta_reflection": ">=0.85"
    },
    "overall_score": ">=0.95",
    "status": "{pass|warning|fail}"
  }
}
```

### Downstream Consumer Mapping
- **Protocol 07**: Consumes `ai-use-case-definition.md` for data strategy planning
  - **Artifact**: `ai-use-case-definition.md`, `handoff-package-protocol-07.json`
  - **Purpose**: Data requirements and touchpoints for data strategy planning
  - **Baseline**: Use case specifications baseline for data strategy validation
- **Protocol 08**: Consumes technical constraints from `03-feasibility-risk-matrix.json`
  - **Artifact**: `03-feasibility-risk-matrix.json`
  - **Purpose**: Technical constraints and feasibility notes for technical design
  - **Baseline**: Technical feasibility baseline for design validation
- **Protocol 09**: Consumes scope definition for task generation
  - **Artifact**: Final specifications from `phase-05-signoff/`
  - **Purpose**: Scope definition and priorities for task breakdown
  - **Baseline**: Scope baseline for task generation validation
- **Protocol 16**: Consumes fairness considerations from `phase-05-ethics/`
  - **Artifact**: `USE-CASE-COMPLIANCE-{id}.md`, protected attributes documentation
  - **Purpose**: Protected attributes and fairness considerations for bias detection audits
  - **Baseline**: Fairness baseline for Protocol 16 validation

### Retention Policy
- **Active Project:** Keep all versions for full project lifecycle
- **Archive Phase:** Maintain in project retrospective for continuous improvement
- **Compliance:** Never delete evidence; mark superseded versions with status flags
- **Access Control:** Read-only for downstream protocols, write-only for Protocol 06 execution

### Drift Baselines and Monitoring Hooks
- **Use Case Specification Baseline**: Baseline version of approved use case specifications stored in `.artifacts/protocol-06-ai-use-case-definition/baselines/use-case-specs-baseline-v{version}.md`
  - **Purpose**: Track changes to use case specifications over time
  - **Monitoring**: If use case specifications change significantly (>20% scope change), trigger change request process
  - **Consumer**: Protocol 23 (Data Drift & Concept Drift Detection) for monitoring specification drift
- **Fairness Baseline**: Baseline of protected attributes and fairness considerations stored in `.artifacts/protocol-06-ai-use-case-definition/baselines/fairness-baseline-v{version}.json`
  - **Purpose**: Track protected attributes and fairness requirements for downstream bias detection
  - **Monitoring**: If protected attributes change, notify Protocol 16 (Bias Detection & Fairness Audit)
  - **Consumer**: Protocol 16, Protocol 23
- **Compliance Baseline**: Baseline of compliance requirements stored in `.artifacts/protocol-06-ai-use-case-definition/baselines/compliance-baseline-v{version}.json`
  - **Purpose**: Track compliance requirements and regulatory constraints
  - **Monitoring**: If regulatory requirements change, trigger change request process
  - **Consumer**: All downstream protocols for compliance validation

## HANDOFF CHECKLIST

### Predecessor Validation 
- [ ] All required inputs from Protocols 01-05 received and validated
- [ ] Project brief contains clear business goals and success targets
- [ ] Discovery notes include stakeholder requirements and constraints
- [ ] Bootstrap outputs provide project structure and context
- [ ] Input quality meets Protocol 06 processing requirements

### Successor Preparation âœ…  
- [ ] Final AI use case specifications generated and validated
- [ ] Specifications formatted for Protocol 07 (AI Data Strategy) consumption
- [ ] Data requirements and touchpoints clearly documented
- [ ] Technical constraints and feasibility notes included
- [ ] Implementation priorities and sequencing established

### Knowledge Transfer âœ…
- [ ] Decision rationale for use case selection documented
- [ ] Assumptions and constraints explicitly stated
- [ ] Risk assessments and mitigation strategies captured
- [ ] Lessons learned from discovery and analysis process recorded
- [ ] Open issues and future considerations identified

### Stakeholder Coordination âœ…
- [ ] Business owner approval and sign-off obtained for final specifications
- [ ] Technical lead validation and approval completed for feasibility assessments
- [ ] Product owner agreement and authorization confirmed for prioritization decisions
- [ ] All stakeholder conditions and constraints documented
- [ ] Support commitment established for implementation phase
- [ ] Formal approval process completed with documented evidence

### Continuity Planning âœ…
- [ ] Rollback procedures documented if implementation issues arise
- [ ] Change process defined if use case scope needs adjustment
- [ ] Monitoring setup planned for use case development progress
- [ ] Feedback loops established with Protocol 07+ teams
- [ ] Success criteria defined for handoff validation

### Change Request Hook
- [ ] **Change Request Triggers**: Document conditions that require triggering change request back to Protocol 06:
  - New use case discovered during Protocol 07-15 execution
  - Ethical concerns raised during Protocol 16 (Bias Detection & Fairness Audit)
  - Scope change identified during Protocol 08-09 (Technical Design/Task Generation)
  - Regulatory changes affecting approved use cases
- [ ] **Change Request Process**: When change request triggered:
  1. Document change reason and impact in `.artifacts/protocol-06-ai-use-case-definition/change-requests/change-request-{timestamp}.md`
  2. Assess impact on approved use cases and downstream protocols
  3. Re-run relevant Protocol 06 phases (e.g., ethics check if ethical concern raised)
  4. Update use case specifications and compliance artifacts
  5. Notify downstream protocols (07-15) of changes via handoff package updates
- [ ] **Evidence**: Change request log maintained in `.artifacts/protocol-06-ai-use-case-definition/change-requests/`
- [ ] **Integration**: Later protocols (07-15) must re-check Protocol 06 outputs if conditions change (new data discovered, ethical concerns, scope changes)

### Integration Readiness âœ…
- [ ] Protocol 07 can consume ai-use-case-definition.md without restructuring
- [ ] Data strategy team has complete requirements for planning
- [ ] Architecture team understands technical constraints and requirements
- [ ] Task generation team has clear scope for work breakdown
- [ ] Quality assurance criteria established for downstream validation

### Final Sign-Off and Readiness âœ…
- [ ] **Protocol Owner Approval**: Protocol 06 owner confirms completion with evidence reference
- [ ] **Evidence Package Complete**: All artifacts in `.artifacts/protocol-06-ai-use-case-definition/` validated
- [ ] **Handoff Package Ready**: Complete handoff-package-protocol-07.json generated
- [ ] **Ready for Next Protocol**: This protocol is complete and READY FOR PROTOCOL 07 (AI Data Strategy & Requirements Planning)

---

**PROTOCOL 06 COMPLETE - Ready for validator execution and handoff to Protocol 07**


---

## META-REFLECTION & CONTINUOUS IMPROVEMENT

### Lessons Learned Capture
**[STRICT]** At protocol completion, capture lessons learned for future improvement:

1. **Process Effectiveness:**
   - Document what worked well and should be repeated
   - Identify bottlenecks or inefficiencies discovered
   - Note stakeholder feedback and satisfaction levels

2. **Quality and Accuracy:**
   - Track accuracy of estimates vs actuals
   - Document quality issues and root causes
   - Record effectiveness of validation approaches

3. **Collaboration and Communication:**
   - Assess stakeholder engagement effectiveness
   - Document communication challenges and resolutions
   - Note team coordination successes and improvements needed

### Continuous Improvement Loop
**[GUIDELINE]** Implement ongoing improvement mechanisms:

1. **Real-time Learning:**
   - Create `improvement-log.md` during execution for issues discovered
   - Track process deviations and their effectiveness
   - Document stakeholder feedback and requested changes

2. **Post-Execution Review:**
   - **Action:** Schedule review within 1 week of protocol completion
   - **Evidence:** `protocol-retrospective-{timestamp}.md`
   - **Participants:** Protocol owner, key stakeholders, technical team
   - **Topics:** What worked, what didn't, improvement priorities

3. **Knowledge Transfer:**
   - **Action:** Update protocol templates based on lessons learned
   - **Evidence:** `lessons-learned-{protocol-id}.md`
   - **Review:** Incorporate into next protocol iteration

### Adaptation Mechanisms
**[STRICT]** Build in adaptation capabilities:

1. **Dynamic Adjustment:**
   - **Trigger:** Significant requirement changes (>20% scope change)
   - **Process:** Impact assessment â†’ Stakeholder review â†’ Protocol adjustment
   - **Evidence:** `protocol-adjustment-{timestamp}.md`

2. **Rollback and Recovery:**
   - **Rollback Triggers:** Quality gate failures, stakeholder veto, technical blockers
   - **Recovery Procedures:** Step-by-step rollback to last stable checkpoint
   - **Evidence:** `rollback-log.md` with decisions and recovery steps

### Future Protocol Considerations
**[GUIDELINE]** Document insights for successor protocols:

1. **Downstream Impact Analysis:**
   - Data quality standards for next protocols
   - Process improvements to incorporate
   - Risk factors to monitor

2. **Scaling Considerations:**
   - Infrastructure scaling needs identified
   - Process scaling for additional complexity
   - Governance scaling for expanded scope

---
