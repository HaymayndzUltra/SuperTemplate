# Protocol Generation System - Stress Testing

**Purpose**: Comprehensive stress testing suite to validate the protocol generation system  
**Status**: âœ… Ready for Execution  
**Last Updated**: 2025-01-10

---

## ğŸ¯ OVERVIEW

This test suite validates the complete protocol generation pipeline through:
- **10 Test Scenarios** covering happy paths, edge cases, and stress conditions
- **7 Automated Tests** in `run_stress_tests.sh`
- **3 Test Data Files** representing different project types

---

## ğŸ“ TEST FILES

```
tests/protocol-generation/
â”œâ”€â”€ README.md (this file)
â”œâ”€â”€ test_scenarios.md (detailed scenario descriptions)
â”œâ”€â”€ run_stress_tests.sh (automated test runner)
â”œâ”€â”€ test-project-brief-simple.md (simple web app)
â”œâ”€â”€ test-project-brief-enterprise.md (complex enterprise app)
â”œâ”€â”€ test-project-brief-minimal.md (minimal edge case)
â””â”€â”€ results/ (generated during test execution)
```

---

## ğŸš€ QUICK START

### Run All Tests

```bash
cd /home/haymayndz/SuperTemplate
./tests/protocol-generation/run_stress_tests.sh
```

### Run Individual Scenario

```bash
# Scenario 1: Simple Web App
python scripts/orchestration/generate_project_protocols.py \
  --protocol-ids 06,07,08,09,10 \
  --project-brief tests/protocol-generation/test-project-brief-simple.md \
  --execution-plan PROTOCOL-EXECUTION-PLAN.md \
  --output-dir /tmp/test-simple \
  --verbose
```

---

## ğŸ“‹ TEST SCENARIOS

### âœ… **Scenario 1: Simple Web App** (Happy Path)
- **Tech Stack**: Next.js + FastAPI + PostgreSQL
- **Complexity**: Standard
- **Expected**: All protocols generated, validations injected
- **Duration**: ~5 seconds

### âœ… **Scenario 2: Enterprise App** (Complex)
- **Tech Stack**: React + Django + MongoDB
- **Complexity**: Enterprise
- **Expected**: Enterprise workflows, compliance checks
- **Duration**: ~8 seconds

### âš ï¸ **Scenario 3: Minimal Brief** (Edge Case)
- **Input**: Minimal project information
- **Expected**: Graceful handling with defaults
- **Duration**: ~3 seconds

### âš ï¸ **Scenario 4: Missing Templates** (Error Handling)
- **Input**: Include non-existent protocol ID (99)
- **Expected**: Partial success, clear warnings
- **Duration**: ~2 seconds

### âŒ **Scenario 5: Invalid Brief** (Error Handling)
- **Input**: Non-existent file path
- **Expected**: Graceful failure with clear error
- **Duration**: <1 second

### âœ… **Scenario 6: Performance Test** (Stress)
- **Input**: 8 protocols at once
- **Expected**: Complete in <30 seconds
- **Duration**: ~18 seconds

### âœ… **Scenario 7: Idempotency Test** (Consistency)
- **Input**: Run twice with same inputs
- **Expected**: Identical output (same checksums)
- **Duration**: ~10 seconds

---

## âœ… SUCCESS CRITERIA

### Must Pass (7 tests)
1. âœ… Simple Web App generates correctly
2. âœ… Enterprise App handles complexity
3. âœ… Minimal Brief uses defaults
4. âœ… Missing Templates handled gracefully
5. âœ… Invalid Brief fails with clear error
6. âœ… Performance meets <30s threshold
7. âœ… Idempotency maintained

### Validation Requirements
- âœ… All generated protocols score â‰¥0.95
- âœ… No placeholders remain (`{PROJECT_NAME}`, etc.)
- âœ… Artifact paths customized correctly
- âœ… Tech stack validations injected
- âœ… Project name used consistently
- âœ… README.md and manifest created

---

## ğŸ“Š EXPECTED RESULTS

```
==========================================
TEST SUMMARY
==========================================
Passed: 7
Failed: 0
Warnings: 0
Total: 7

End Time: 2025-01-10 14:30:00
Results saved to: tests/protocol-generation/results
==========================================
```

---

## ğŸ” VALIDATION CHECKS

### Structural Validation
- âœ… All required sections present
- âœ… Proper markdown formatting
- âœ… Code blocks for automation scripts
- âœ… Integration points defined

### Customization Validation
- âœ… Placeholders replaced with actual values
- âœ… Project name appears in content
- âœ… Artifact paths use project-specific location
- âœ… Tech stack-specific validations injected

### Integration Validation
- âœ… Input/output definitions present
- âœ… Artifact storage defined
- âœ… Dependencies documented

---

## ğŸ› TROUBLESHOOTING

### Test Fails: "Template not found"
**Cause**: Foundation templates missing  
**Solution**: Ensure `.cursor/ai-driven-workflow/` contains protocol templates

### Test Fails: "Module not found"
**Cause**: Python dependencies missing  
**Solution**: Install required packages (if any)

### Test Fails: "Permission denied"
**Cause**: Script not executable  
**Solution**: `chmod +x tests/protocol-generation/run_stress_tests.sh`

### Test Slow: >30 seconds
**Cause**: System resources constrained  
**Solution**: Close other applications, check CPU/memory usage

---

## ğŸ“ˆ PERFORMANCE BENCHMARKS

| Scenario | Protocols | Expected Duration | Threshold |
|----------|-----------|-------------------|-----------|
| Simple Web App | 5 | ~5s | <10s |
| Enterprise App | 3 | ~8s | <15s |
| Minimal Brief | 2 | ~3s | <5s |
| Missing Templates | 2 | ~2s | <5s |
| Invalid Brief | 1 | <1s | <2s |
| Performance Test | 8 | ~18s | <30s |
| Idempotency | 2Ã—2 | ~10s | <15s |

---

## ğŸ”„ CONTINUOUS TESTING

### Run Before Commits
```bash
# Quick smoke test
./tests/protocol-generation/run_stress_tests.sh

# If all pass, safe to commit
git add .
git commit -m "feat: protocol generation system"
```

### Run in CI/CD
```yaml
# .github/workflows/test.yml
- name: Run Protocol Generation Tests
  run: ./tests/protocol-generation/run_stress_tests.sh
```

---

## ğŸ“ TEST RESULTS LOCATION

After running tests, results are saved to:
```
tests/protocol-generation/results/
â”œâ”€â”€ scenario1-simple/ (generated protocols)
â”œâ”€â”€ scenario1-artifacts/ (intermediate files)
â”œâ”€â”€ scenario1.log (execution log)
â”œâ”€â”€ scenario2-enterprise/
â”œâ”€â”€ scenario2-artifacts/
â”œâ”€â”€ scenario2.log
â””â”€â”€ ... (all scenarios)
```

---

## ğŸ¯ NEXT STEPS

### After Tests Pass
1. âœ… Review generated protocols manually
2. âœ… Verify validation reports
3. âœ… Check generation reports
4. âœ… Test with real PROJECT-BRIEF.md
5. âœ… Execute generated Protocol 06

### If Tests Fail
1. âŒ Review failure logs in `results/*.log`
2. âŒ Check error messages for root cause
3. âŒ Fix identified issues
4. âŒ Re-run tests
5. âŒ Document any gaps found

---

## ğŸ“š REFERENCES

- **Test Scenarios**: `test_scenarios.md` - Detailed scenario descriptions
- **Test Runner**: `run_stress_tests.sh` - Automated test execution
- **Implementation**: `../../IMPLEMENTATION-SUMMARY.md` - Complete system documentation
- **Generation Scripts**: `../../scripts/orchestration/` - Core implementation

---

**Status**: âœ… Ready for Execution  
**Maintainer**: Protocol Generation Team  
**Last Test Run**: Not yet executed
